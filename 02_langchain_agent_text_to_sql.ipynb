{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6d6b161",
   "metadata": {},
   "source": [
    "# 02. LangChain Agent ê¸°ë°˜ Text-to-SQL ì‹œìŠ¤í…œ\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ **LangChain Agent**ì™€ **Function Tools**ë¥¼ í™œìš©í•˜ì—¬ ìì—°ì–´ë¥¼ SQLë¡œ ë³€í™˜í•˜ëŠ” ì§€ëŠ¥í˜• ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ğŸ¯ ëª©í‘œ\n",
    "- **LangChain Agent ì•„í‚¤í…ì²˜** ì„¤ê³„ ë° êµ¬í˜„\n",
    "- **Function Tools** ê°œë°œ (ìŠ¤í‚¤ë§ˆ ì¡°íšŒ, SQL ì‹¤í–‰, ê²°ê³¼ ê²€ì¦)\n",
    "- **Databricks Foundation Models** ì—°ë™\n",
    "- **ë™ì  ì¶”ë¡  ë° ë„êµ¬ ì„ íƒ** ê¸°ëŠ¥\n",
    "- **ì•ˆì „í•œ SQL ì‹¤í–‰** ë° ì˜¤ë¥˜ ì²˜ë¦¬\n",
    "\n",
    "## ğŸ—ï¸ LangChain Agent ì•„í‚¤í…ì²˜\n",
    "```\n",
    "ì‚¬ìš©ì ì§ˆë¬¸\n",
    "    â†“\n",
    "LangChain Agent (ì¶”ë¡  ì—”ì§„)\n",
    "    â†“\n",
    "Function Tools ì„ íƒ ë° ì‹¤í–‰\n",
    "- schema_search_tool: ê´€ë ¨ í…Œì´ë¸” ê²€ìƒ‰\n",
    "- sql_generation_tool: SQL ì¿¼ë¦¬ ìƒì„±\n",
    "- sql_execution_tool: ì•ˆì „í•œ SQL ì‹¤í–‰\n",
    "- result_analysis_tool: ê²°ê³¼ ë¶„ì„ ë° ìš”ì•½\n",
    "    â†“\n",
    "ìµœì¢… ì‘ë‹µ ìƒì„±\n",
    "```\n",
    "\n",
    "## ğŸ“‹ ì „ì œì¡°ê±´\n",
    "- `01_databricks_setup_northwind.ipynb` ì™„ë£Œ\n",
    "- Northwind ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•ë¨\n",
    "- Databricks Foundation Models ì ‘ê·¼ ê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18a8ee1",
   "metadata": {},
   "source": [
    "## 1. LangChain Agent ë° í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15d925ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Databricks LangChain ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ê°€ëŠ¥\n",
      "âœ… PySpark ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\n",
      "ğŸ“¦ LangChain Agent ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\n",
      "ğŸ”§ Text-to-SQL Agent ì‹œìŠ¤í…œ ì¤€ë¹„ ì¤‘...\n"
     ]
    }
   ],
   "source": [
    "# LangChain Core ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "from langchain.agents import AgentType, initialize_agent, Tool\n",
    "# from langchain.agents.agent_toolkits import create_python_agent  # í˜¸í™˜ì„± ë¬¸ì œë¡œ ì œê±°\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "from langchain.callbacks.manager import CallbackManagerForToolRun\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# LangChain Databricks ì—°ë™\n",
    "try:\n",
    "    from langchain_community.chat_models import ChatDatabricks\n",
    "    from langchain_community.embeddings import DatabricksEmbeddings\n",
    "    DATABRICKS_LANGCHAIN = True\n",
    "    print(\"âœ… Databricks LangChain ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ê°€ëŠ¥\")\n",
    "except ImportError:\n",
    "    DATABRICKS_LANGCHAIN = False\n",
    "    print(\"âš ï¸ Databricks LangChain ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ í•„ìš”: pip install langchain-databricks\")\n",
    "\n",
    "# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import Optional, List, Dict, Any, Union\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Databricks/Spark (ì´ì „ ë…¸íŠ¸ë¶ì—ì„œ ì´ì–´ë°›ê¸°)\n",
    "try:\n",
    "    from pyspark.sql import SparkSession\n",
    "    from pyspark.sql.functions import *\n",
    "    SPARK_AVAILABLE = True\n",
    "    print(\"âœ… PySpark ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\")\n",
    "except ImportError:\n",
    "    SPARK_AVAILABLE = False\n",
    "    print(\"âš ï¸ PySpark ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ í•„ìš”\")\n",
    "\n",
    "print(\"ğŸ“¦ LangChain Agent ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\")\n",
    "print(\"ğŸ”§ Text-to-SQL Agent ì‹œìŠ¤í…œ ì¤€ë¹„ ì¤‘...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d54a548",
   "metadata": {},
   "source": [
    "## 2. ì´ì „ ë…¸íŠ¸ë¶ ìƒíƒœ í™•ì¸ ë° ì—°ê²°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf4c4ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Spark ì„¸ì…˜ í™•ì¸\n",
      "âœ… Northwind ë°ì´í„°ë² ì´ìŠ¤ í™•ì¸\n",
      "âœ… Northwind ë°ì´í„°ë² ì´ìŠ¤ í™•ì¸\n",
      "   ğŸ“‹ í…Œì´ë¸”: 8ê°œ (categories, customers, employees...)\n",
      "âœ… ìŠ¤í‚¤ë§ˆ ì •ë³´ ì™„ë£Œ\n",
      "\n",
      "ğŸš€ LangChain Agent êµ¬í˜„ ì¤€ë¹„ ì™„ë£Œ!\n",
      "   ğŸ“‹ í…Œì´ë¸”: 8ê°œ (categories, customers, employees...)\n",
      "âœ… ìŠ¤í‚¤ë§ˆ ì •ë³´ ì™„ë£Œ\n",
      "\n",
      "ğŸš€ LangChain Agent êµ¬í˜„ ì¤€ë¹„ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# ì´ì „ ë…¸íŠ¸ë¶ì—ì„œ ì„¤ì •ëœ í™˜ê²½ í™•ì¸\n",
    "def check_previous_setup():\n",
    "    \"\"\"ì´ì „ ë…¸íŠ¸ë¶ ì„¤ì • ìƒíƒœ í™•ì¸\"\"\"\n",
    "    \n",
    "    status = {\n",
    "        \"spark_session\": False,\n",
    "        \"northwind_database\": False,\n",
    "        \"schema_info\": False,\n",
    "        \"ready_for_agent\": False\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Spark ì„¸ì…˜ í™•ì¸\n",
    "        global spark\n",
    "        spark = SparkSession.getActiveSession()\n",
    "        if spark is None:\n",
    "            spark = SparkSession.builder.appName(\"LangChain-Agent-TextToSQL\").getOrCreate()\n",
    "        \n",
    "        status[\"spark_session\"] = True\n",
    "        print(\"âœ… Spark ì„¸ì…˜ í™•ì¸\")\n",
    "        \n",
    "        # Northwind ë°ì´í„°ë² ì´ìŠ¤ í™•ì¸\n",
    "        databases = [row.databaseName for row in spark.sql(\"SHOW DATABASES\").collect()]\n",
    "        if \"northwind\" in databases:\n",
    "            status[\"northwind_database\"] = True\n",
    "            print(\"âœ… Northwind ë°ì´í„°ë² ì´ìŠ¤ í™•ì¸\")\n",
    "            \n",
    "            # í…Œì´ë¸” í™•ì¸\n",
    "            tables = spark.sql(\"SHOW TABLES IN northwind\").collect()\n",
    "            table_names = [row.tableName for row in tables]\n",
    "            print(f\"   ğŸ“‹ í…Œì´ë¸”: {len(table_names)}ê°œ ({', '.join(table_names[:3])}...)\")\n",
    "            \n",
    "            if len(table_names) >= 8:  # ì˜ˆìƒë˜ëŠ” Northwind í…Œì´ë¸” ìˆ˜\n",
    "                status[\"schema_info\"] = True\n",
    "                print(\"âœ… ìŠ¤í‚¤ë§ˆ ì •ë³´ ì™„ë£Œ\")\n",
    "        else:\n",
    "            print(\"âŒ Northwind ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            print(\"   01_databricks_setup_northwind.ipynbë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ í™˜ê²½ í™•ì¸ ì‹¤íŒ¨: {str(e)}\")\n",
    "    \n",
    "    # ì „ì²´ ì¤€ë¹„ ìƒíƒœ\n",
    "    status[\"ready_for_agent\"] = all([\n",
    "        status[\"spark_session\"],\n",
    "        status[\"northwind_database\"], \n",
    "        status[\"schema_info\"]\n",
    "    ])\n",
    "    \n",
    "    return status\n",
    "\n",
    "# í™˜ê²½ ìƒíƒœ í™•ì¸\n",
    "setup_status = check_previous_setup()\n",
    "\n",
    "if setup_status[\"ready_for_agent\"]:\n",
    "    print(\"\\nğŸš€ LangChain Agent êµ¬í˜„ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ ì„ í–‰ ì‘ì—…ì´ í•„ìš”í•©ë‹ˆë‹¤:\")\n",
    "    for key, value in setup_status.items():\n",
    "        if not value:\n",
    "            print(f\"   âŒ {key}\")\n",
    "    \n",
    "    if not setup_status[\"northwind_database\"]:\n",
    "        print(\"\\nğŸ‘‰ í•´ê²°ë°©ë²•: 01_databricks_setup_northwind.ipynbë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2682c44f",
   "metadata": {},
   "source": [
    "## 3. Databricks Foundation Models ì´ˆê¸°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80c59964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âš ï¸ databricks-meta-llama-3-1-70b-instruct ì‹¤íŒ¨: 404 Client Error: The given endpoint does not exist, please retry after checking the specified model...\n",
      "   âš ï¸ databricks-llama-2-70b-chat ì‹¤íŒ¨: 404 Client Error: The given endpoint does not exist, please retry after checking the specified model...\n",
      "   âš ï¸ databricks-mixtral-8x7b-instruct ì‹¤íŒ¨: 404 Client Error: The given endpoint does not exist, please retry after checking the specified model...\n",
      "âš ï¸ ëª¨ë“  Databricks ì—”ë“œí¬ì¸íŠ¸ ì—°ê²° ì‹¤íŒ¨\n",
      "ğŸ”„ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ì „í™˜ (ê°œë°œ/í…ŒìŠ¤íŠ¸ìš©)\n",
      "   ğŸ“ ëª¨ì˜ SQL ìƒì„± ê¸°ëŠ¥ í™œì„±í™”\n",
      "   ğŸ” ê¸°ë³¸ ìŠ¤í‚¤ë§ˆ ê²€ìƒ‰ ê¸°ëŠ¥ í™œì„±í™”\n",
      "   âš ï¸ ì‹¤ì œ AI ëª¨ë¸ì´ ì•„ë‹Œ ì‹œë®¬ë ˆì´ì…˜ì…ë‹ˆë‹¤\n",
      "\n",
      "ğŸ§ª ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ LangChain Agent ì¤€ë¹„ ì™„ë£Œ!\n",
      "   ğŸ“ ê¸°ë³¸ì ì¸ SQL ìƒì„± íŒ¨í„´ ì§€ì›\n",
      "   ğŸ”§ ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ë” ê³ ë„í™”ëœ AI ëª¨ë¸ ì‚¬ìš©\n",
      "   âš ï¸ databricks-llama-2-70b-chat ì‹¤íŒ¨: 404 Client Error: The given endpoint does not exist, please retry after checking the specified model...\n",
      "   âš ï¸ databricks-mixtral-8x7b-instruct ì‹¤íŒ¨: 404 Client Error: The given endpoint does not exist, please retry after checking the specified model...\n",
      "âš ï¸ ëª¨ë“  Databricks ì—”ë“œí¬ì¸íŠ¸ ì—°ê²° ì‹¤íŒ¨\n",
      "ğŸ”„ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ì „í™˜ (ê°œë°œ/í…ŒìŠ¤íŠ¸ìš©)\n",
      "   ğŸ“ ëª¨ì˜ SQL ìƒì„± ê¸°ëŠ¥ í™œì„±í™”\n",
      "   ğŸ” ê¸°ë³¸ ìŠ¤í‚¤ë§ˆ ê²€ìƒ‰ ê¸°ëŠ¥ í™œì„±í™”\n",
      "   âš ï¸ ì‹¤ì œ AI ëª¨ë¸ì´ ì•„ë‹Œ ì‹œë®¬ë ˆì´ì…˜ì…ë‹ˆë‹¤\n",
      "\n",
      "ğŸ§ª ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ LangChain Agent ì¤€ë¹„ ì™„ë£Œ!\n",
      "   ğŸ“ ê¸°ë³¸ì ì¸ SQL ìƒì„± íŒ¨í„´ ì§€ì›\n",
      "   ğŸ”§ ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ë” ê³ ë„í™”ëœ AI ëª¨ë¸ ì‚¬ìš©\n"
     ]
    }
   ],
   "source": [
    "# Databricks Foundation Models ì„¤ì •\n",
    "class DatabricksModelManager:\n",
    "    \"\"\"Databricks Foundation Models ê´€ë¦¬ í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.chat_model = None\n",
    "        self.embedding_model = None\n",
    "        self.is_available = False\n",
    "        self.simulation_mode = False\n",
    "    \n",
    "    def initialize_models(self):\n",
    "        \"\"\"ëª¨ë¸ ì´ˆê¸°í™”\"\"\"\n",
    "        \n",
    "        try:\n",
    "            if DATABRICKS_LANGCHAIN:\n",
    "                # LLM ëª¨ë¸ (ì¶”ë¡ ìš©) - ë‹¤ì–‘í•œ ì—”ë“œí¬ì¸íŠ¸ ì‹œë„\n",
    "                endpoints_to_try = [\n",
    "                    \"databricks-meta-llama-3-1-70b-instruct\",\n",
    "                    \"databricks-llama-2-70b-chat\",\n",
    "                    \"databricks-mixtral-8x7b-instruct\"\n",
    "                ]\n",
    "                \n",
    "                for endpoint in endpoints_to_try:\n",
    "                    try:\n",
    "                        self.chat_model = ChatDatabricks(\n",
    "                            endpoint=endpoint,\n",
    "                            temperature=0.1,\n",
    "                            max_tokens=4000\n",
    "                        )\n",
    "                        \n",
    "                        # ì—°ê²° í…ŒìŠ¤íŠ¸\n",
    "                        test_response = self.chat_model.predict(\"Hello, respond with 'OK'\")\n",
    "                        if \"OK\" in test_response:\n",
    "                            self.is_available = True\n",
    "                            print(f\"âœ… Databricks Foundation Models ì—°ê²° ì„±ê³µ\")\n",
    "                            print(f\"   LLM: {endpoint}\")\n",
    "                            \n",
    "                            # ì„ë² ë”© ëª¨ë¸\n",
    "                            self.embedding_model = DatabricksEmbeddings(\n",
    "                                endpoint=\"databricks-bge-large-en\"\n",
    "                            )\n",
    "                            print(f\"   Embedding: databricks-bge-large-en\")\n",
    "                            return\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(f\"   âš ï¸ {endpoint} ì‹¤íŒ¨: {str(e)[:100]}...\")\n",
    "                        continue\n",
    "                \n",
    "                print(\"âš ï¸ ëª¨ë“  Databricks ì—”ë“œí¬ì¸íŠ¸ ì—°ê²° ì‹¤íŒ¨\")\n",
    "                        \n",
    "            else:\n",
    "                print(\"âš ï¸ Databricks LangChain ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Databricks Models ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}\")\n",
    "            \n",
    "        # ëŒ€ì•ˆ ì„¤ì • ì‹œë„\n",
    "        self._setup_alternative_models()\n",
    "    \n",
    "    def _setup_alternative_models(self):\n",
    "        \"\"\"ëŒ€ì•ˆ ëª¨ë¸ ì„¤ì • (OpenAI ë“±)\"\"\"\n",
    "        try:\n",
    "            # OpenAI ì‚¬ìš© (API í‚¤ê°€ ìˆëŠ” ê²½ìš°)\n",
    "            if os.getenv(\"OPENAI_API_KEY\"):\n",
    "                from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "                \n",
    "                self.chat_model = ChatOpenAI(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    temperature=0.1\n",
    "                )\n",
    "                self.embedding_model = OpenAIEmbeddings()\n",
    "                self.is_available = True\n",
    "                print(\"âœ… OpenAI ëª¨ë¸ë¡œ ëŒ€ì²´ ì„¤ì • ì™„ë£Œ\")\n",
    "                return\n",
    "                \n",
    "        except ImportError:\n",
    "            print(\"âš ï¸ OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ í•„ìš”: pip install langchain-openai\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ OpenAI ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}\")\n",
    "        \n",
    "        # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ í™œì„±í™”\n",
    "        print(\"ğŸ”„ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ì „í™˜ (ê°œë°œ/í…ŒìŠ¤íŠ¸ìš©)\")\n",
    "        self._setup_simulation_mode()\n",
    "    \n",
    "    def _setup_simulation_mode(self):\n",
    "        \"\"\"ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ ì„¤ì • (ê°œë°œ/í…ŒìŠ¤íŠ¸ìš©)\"\"\"\n",
    "        \n",
    "        class MockChatModel:\n",
    "            \"\"\"ëª¨ì˜ ì±„íŒ… ëª¨ë¸\"\"\"\n",
    "            \n",
    "            def predict(self, prompt: str) -> str:\n",
    "                \"\"\"ê°„ë‹¨í•œ SQL ìƒì„± ì‹œë®¬ë ˆì´ì…˜\"\"\"\n",
    "                \n",
    "                prompt_lower = prompt.lower()\n",
    "                \n",
    "                # ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ SQL ìƒì„±\n",
    "                if \"ê³ ê°\" in prompt_lower or \"customer\" in prompt_lower:\n",
    "                    if \"ìˆ˜\" in prompt_lower or \"count\" in prompt_lower:\n",
    "                        return \"SELECT COUNT(*) as customer_count FROM northwind.customers\"\n",
    "                    else:\n",
    "                        return \"SELECT * FROM northwind.customers LIMIT 10\"\n",
    "                \n",
    "                elif \"ìƒí’ˆ\" in prompt_lower or \"product\" in prompt_lower:\n",
    "                    if \"ë¹„ì‹¼\" in prompt_lower or \"expensive\" in prompt_lower or \"ê°€ê²©\" in prompt_lower:\n",
    "                        return \"SELECT product_name, unit_price FROM northwind.products ORDER BY unit_price DESC LIMIT 5\"\n",
    "                    elif \"ì¹´í…Œê³ ë¦¬\" in prompt_lower or \"category\" in prompt_lower:\n",
    "                        return \"\"\"SELECT c.category_name, COUNT(p.product_id) as product_count, \n",
    "                               AVG(p.unit_price) as avg_price \n",
    "                               FROM northwind.products p \n",
    "                               JOIN northwind.categories c ON p.categoryid = c.categoryid \n",
    "                               GROUP BY c.category_name \n",
    "                               ORDER BY product_count DESC\"\"\"\n",
    "                    else:\n",
    "                        return \"SELECT * FROM northwind.products LIMIT 10\"\n",
    "                \n",
    "                elif \"ì£¼ë¬¸\" in prompt_lower or \"order\" in prompt_lower:\n",
    "                    if \"ì›”ë³„\" in prompt_lower or \"monthly\" in prompt_lower:\n",
    "                        return \"\"\"SELECT DATE_FORMAT(order_date, 'yyyy-MM') as month, \n",
    "                               COUNT(*) as order_count \n",
    "                               FROM northwind.orders \n",
    "                               GROUP BY DATE_FORMAT(order_date, 'yyyy-MM') \n",
    "                               ORDER BY month DESC \n",
    "                               LIMIT 12\"\"\"\n",
    "                    else:\n",
    "                        return \"SELECT * FROM northwind.orders LIMIT 10\"\n",
    "                \n",
    "                elif \"ë¶„ì„\" in prompt_lower or \"analysis\" in prompt_lower:\n",
    "                    return \"\"\"ì´ ê²°ê³¼ëŠ” Northwind ë°ì´í„°ë² ì´ìŠ¤ì˜ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤. \n",
    "                           ì‹¤ì œ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” ë” ì •í™•í•˜ê³  ìƒì„¸í•œ ë¶„ì„ì´ ì œê³µë©ë‹ˆë‹¤.\"\"\"\n",
    "                \n",
    "                else:\n",
    "                    # ê¸°ë³¸ ì¿¼ë¦¬\n",
    "                    return \"SELECT 'simulation_mode' as status, 'Mock response for development' as message\"\n",
    "        \n",
    "        class MockEmbedding:\n",
    "            \"\"\"ëª¨ì˜ ì„ë² ë”© ëª¨ë¸\"\"\"\n",
    "            \n",
    "            def embed_query(self, text: str) -> list:\n",
    "                # ê°„ë‹¨í•œ í•´ì‹œ ê¸°ë°˜ ê°€ì§œ ì„ë² ë”©\n",
    "                import hashlib\n",
    "                hash_obj = hashlib.md5(text.encode())\n",
    "                hash_hex = hash_obj.hexdigest()\n",
    "                # 768ì°¨ì› ê°€ì§œ ë²¡í„° ìƒì„±\n",
    "                return [float(int(hash_hex[i:i+2], 16)) / 255.0 for i in range(0, min(len(hash_hex), 32), 2)]\n",
    "        \n",
    "        self.chat_model = MockChatModel()\n",
    "        self.embedding_model = MockEmbedding()\n",
    "        self.is_available = True\n",
    "        self.simulation_mode = True\n",
    "        \n",
    "        print(\"   ğŸ“ ëª¨ì˜ SQL ìƒì„± ê¸°ëŠ¥ í™œì„±í™”\")\n",
    "        print(\"   ğŸ” ê¸°ë³¸ ìŠ¤í‚¤ë§ˆ ê²€ìƒ‰ ê¸°ëŠ¥ í™œì„±í™”\")\n",
    "        print(\"   âš ï¸ ì‹¤ì œ AI ëª¨ë¸ì´ ì•„ë‹Œ ì‹œë®¬ë ˆì´ì…˜ì…ë‹ˆë‹¤\")\n",
    "    \n",
    "    def get_models(self):\n",
    "        \"\"\"ì„¤ì •ëœ ëª¨ë¸ë“¤ ë°˜í™˜\"\"\"\n",
    "        return self.chat_model, self.embedding_model\n",
    "\n",
    "# ëª¨ë¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”\n",
    "model_manager = DatabricksModelManager()\n",
    "model_manager.initialize_models()\n",
    "\n",
    "# ì „ì—­ ë³€ìˆ˜ë¡œ ì„¤ì •\n",
    "llm, embedding_model = model_manager.get_models()\n",
    "\n",
    "if model_manager.is_available:\n",
    "    if model_manager.simulation_mode:\n",
    "        print(\"\\nğŸ§ª ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ LangChain Agent ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "        print(\"   ğŸ“ ê¸°ë³¸ì ì¸ SQL ìƒì„± íŒ¨í„´ ì§€ì›\")\n",
    "        print(\"   ğŸ”§ ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ë” ê³ ë„í™”ëœ AI ëª¨ë¸ ì‚¬ìš©\")\n",
    "    else:\n",
    "        print(\"\\nğŸ¤– LangChain Agentìš© ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "else:\n",
    "    print(\"\\nâŒ ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨. Agent êµ¬í˜„ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d770db",
   "metadata": {},
   "source": [
    "## 4. Function Tools êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e256426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Function Tools êµ¬í˜„ ì™„ë£Œ\n",
      "   ğŸ“‹ schema_search_tool: ìŠ¤í‚¤ë§ˆ ê²€ìƒ‰\n",
      "   ğŸ”§ sql_generation_tool: SQL ìƒì„±\n",
      "   âš¡ sql_execution_tool: SQL ì‹¤í–‰\n",
      "   ğŸ“Š result_analysis_tool: ê²°ê³¼ ë¶„ì„\n"
     ]
    }
   ],
   "source": [
    "# Function Tools êµ¬í˜„\n",
    "\n",
    "@tool\n",
    "def schema_search_tool(query: str) -> str:\n",
    "    \"\"\"ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆì—ì„œ ê´€ë ¨ í…Œì´ë¸” ë° ì»¬ëŸ¼ ê²€ìƒ‰\n",
    "    \n",
    "    Args:\n",
    "        query: ê²€ìƒ‰í•  í‚¤ì›Œë“œë‚˜ ì§ˆë¬¸\n",
    "        \n",
    "    Returns:\n",
    "        ê´€ë ¨ í…Œì´ë¸”ë“¤ì˜ ìŠ¤í‚¤ë§ˆ ì •ë³´\n",
    "    \"\"\"\n",
    "    \n",
    "    if not spark:\n",
    "        return \"Error: Spark ì„¸ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    try:\n",
    "        # Northwind í…Œì´ë¸” ëª©ë¡ ê°€ì ¸ì˜¤ê¸°\n",
    "        tables = spark.sql(\"SHOW TABLES IN northwind\").collect()\n",
    "        \n",
    "        query_lower = query.lower()\n",
    "        relevant_tables = []\n",
    "        \n",
    "        # ê° í…Œì´ë¸”ì— ëŒ€í•´ ê´€ë ¨ì„± ê²€ì‚¬\n",
    "        for table_row in tables:\n",
    "            table_name = table_row.tableName\n",
    "            \n",
    "            # í…Œì´ë¸”ëª… ë§¤ì¹­\n",
    "            relevance_score = 0\n",
    "            if query_lower in table_name.lower():\n",
    "                relevance_score += 10\n",
    "            \n",
    "            # ì»¬ëŸ¼ëª… ë° ë°ì´í„° ë§¤ì¹­\n",
    "            try:\n",
    "                # í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì¡°íšŒ\n",
    "                describe_result = spark.sql(f\"DESCRIBE TABLE northwind.{table_name}\").collect()\n",
    "                \n",
    "                column_info = []\n",
    "                for row in describe_result:\n",
    "                    if row.col_name and not row.col_name.startswith('#'):\n",
    "                        col_name = row.col_name\n",
    "                        col_type = row.data_type\n",
    "                        \n",
    "                        # ì»¬ëŸ¼ëª… ë§¤ì¹­\n",
    "                        if query_lower in col_name.lower():\n",
    "                            relevance_score += 5\n",
    "                        \n",
    "                        column_info.append(f\"{col_name} ({col_type})\")\n",
    "                \n",
    "                # í‚¤ì›Œë“œë³„ ì¶”ê°€ ì ìˆ˜\n",
    "                keyword_mapping = {\n",
    "                    \"ê³ ê°\": [\"customers\"],\n",
    "                    \"customer\": [\"customers\"],\n",
    "                    \"ì£¼ë¬¸\": [\"orders\", \"order_details\"],\n",
    "                    \"order\": [\"orders\", \"order_details\"],\n",
    "                    \"ìƒí’ˆ\": [\"products\"],\n",
    "                    \"product\": [\"products\"],\n",
    "                    \"ì¹´í…Œê³ ë¦¬\": [\"categories\"],\n",
    "                    \"category\": [\"categories\"],\n",
    "                    \"ì§ì›\": [\"employees\"],\n",
    "                    \"employee\": [\"employees\"],\n",
    "                    \"ê³µê¸‰ì—…ì²´\": [\"suppliers\"],\n",
    "                    \"supplier\": [\"suppliers\"],\n",
    "                    \"ë°°ì†¡\": [\"shippers\", \"orders\"],\n",
    "                    \"ship\": [\"shippers\", \"orders\"],\n",
    "                    \"ê°€ê²©\": [\"products\", \"order_details\"],\n",
    "                    \"price\": [\"products\", \"order_details\"],\n",
    "                    \"ë§¤ì¶œ\": [\"order_details\", \"orders\"],\n",
    "                    \"sales\": [\"order_details\", \"orders\"]\n",
    "                }\n",
    "                \n",
    "                for keyword, related_tables in keyword_mapping.items():\n",
    "                    if keyword in query_lower and table_name in related_tables:\n",
    "                        relevance_score += 8\n",
    "                \n",
    "                # ê´€ë ¨ì„±ì´ ìˆëŠ” í…Œì´ë¸”ë§Œ í¬í•¨\n",
    "                if relevance_score > 0:\n",
    "                    # ìƒ˜í”Œ ë°ì´í„° ì¡°íšŒ\n",
    "                    sample_df = spark.table(f\"northwind.{table_name}\").limit(2).toPandas()\n",
    "                    sample_data = sample_df.to_dict('records') if len(sample_df) > 0 else []\n",
    "                    \n",
    "                    relevant_tables.append({\n",
    "                        \"table_name\": table_name,\n",
    "                        \"relevance_score\": relevance_score,\n",
    "                        \"columns\": column_info,\n",
    "                        \"sample_data\": sample_data[:1]  # 1ê°œë§Œ\n",
    "                    })\n",
    "                    \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        # ê´€ë ¨ì„± ì ìˆ˜ë¡œ ì •ë ¬\n",
    "        relevant_tables.sort(key=lambda x: x[\"relevance_score\"], reverse=True)\n",
    "        \n",
    "        # ê²°ê³¼ í¬ë§·íŒ…\n",
    "        if not relevant_tables:\n",
    "            return \"ê´€ë ¨ëœ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.\"\n",
    "        \n",
    "        result = f\"ì§ˆì˜ '{query}'ì™€ ê´€ë ¨ëœ í…Œì´ë¸”ë“¤:\\n\\n\"\n",
    "        \n",
    "        for i, table in enumerate(relevant_tables[:3], 1):  # ìƒìœ„ 3ê°œë§Œ\n",
    "            result += f\"{i}. {table['table_name']} (ê´€ë ¨ë„: {table['relevance_score']})\\n\"\n",
    "            result += f\"   ì»¬ëŸ¼: {', '.join(table['columns'][:5])}\\n\"  # ì²˜ìŒ 5ê°œ ì»¬ëŸ¼ë§Œ\n",
    "            if table['sample_data']:\n",
    "                sample_str = ', '.join([f\"{k}={v}\" for k, v in list(table['sample_data'][0].items())[:3]])\n",
    "                result += f\"   ìƒ˜í”Œ: {sample_str}\\n\"\n",
    "            result += \"\\n\"\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error: ìŠ¤í‚¤ë§ˆ ê²€ìƒ‰ ì‹¤íŒ¨ - {str(e)}\"\n",
    "\n",
    "@tool  \n",
    "def sql_generation_tool(question: str, schema_context: str = \"\") -> str:\n",
    "    \"\"\"ìì—°ì–´ ì§ˆë¬¸ì„ SQL ì¿¼ë¦¬ë¡œ ë³€í™˜\n",
    "    \n",
    "    Args:\n",
    "        question: ìì—°ì–´ ì§ˆë¬¸\n",
    "        schema_context: ê´€ë ¨ ìŠ¤í‚¤ë§ˆ ì •ë³´ (schema_search_tool ê²°ê³¼)\n",
    "        \n",
    "    Returns:\n",
    "        SQL ì¿¼ë¦¬\n",
    "    \"\"\"\n",
    "    \n",
    "    if not llm:\n",
    "        return \"Error: ì–¸ì–´ ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    try:\n",
    "        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "        prompt = f\"\"\"ë‹¹ì‹ ì€ SQL ì „ë¬¸ê°€ì…ë‹ˆë‹¤. Northwind ë°ì´í„°ë² ì´ìŠ¤ì— ëŒ€í•œ ìì—°ì–´ ì§ˆë¬¸ì„ SQL ì¿¼ë¦¬ë¡œ ë³€í™˜í•˜ì„¸ìš”.\n",
    "\n",
    "ë°ì´í„°ë² ì´ìŠ¤: northwind (Databricks/Spark SQL ë¬¸ë²• ì‚¬ìš©)\n",
    "\n",
    "ê´€ë ¨ ìŠ¤í‚¤ë§ˆ ì •ë³´:\n",
    "{schema_context}\n",
    "\n",
    "ê·œì¹™:\n",
    "1. ì •í™•í•œ í…Œì´ë¸”ëª…ê³¼ ì»¬ëŸ¼ëª…ì„ ì‚¬ìš©í•˜ì„¸ìš” (northwind.í…Œì´ë¸”ëª…)\n",
    "2. Databricks/Spark SQL ë¬¸ë²•ì„ ì‚¬ìš©í•˜ì„¸ìš”\n",
    "3. ì ì ˆí•œ JOIN, WHERE, GROUP BY, ORDER BYë¥¼ í™œìš©í•˜ì„¸ìš”\n",
    "4. í•œêµ­ì–´ ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ì •í™•íˆ íŒŒì•…í•˜ì„¸ìš”\n",
    "5. LIMITì„ ì ì ˆíˆ ì‚¬ìš©í•˜ì—¬ ê³¼ë„í•œ ê²°ê³¼ë¥¼ ë°©ì§€í•˜ì„¸ìš”\n",
    "6. SQL ì¿¼ë¦¬ë§Œ ë°˜í™˜í•˜ê³  ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”\n",
    "\n",
    "ì§ˆë¬¸: {question}\n",
    "\n",
    "SQL ì¿¼ë¦¬:\n",
    "\"\"\"\n",
    "        \n",
    "        response = llm.predict(prompt)\n",
    "        \n",
    "        # SQL ì¶”ì¶œ (ì½”ë“œ ë¸”ë¡ì´ ìˆë‹¤ë©´ ì œê±°)\n",
    "        sql_query = response.strip()\n",
    "        if \"```\" in sql_query:\n",
    "            sql_lines = sql_query.split(\"\\n\")\n",
    "            sql_lines = [line for line in sql_lines if not line.strip().startswith(\"```\")]\n",
    "            sql_query = \"\\n\".join(sql_lines).strip()\n",
    "        \n",
    "        return sql_query\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error: SQL ìƒì„± ì‹¤íŒ¨ - {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def sql_execution_tool(sql_query: str) -> str:\n",
    "    \"\"\"SQL ì¿¼ë¦¬ë¥¼ ì•ˆì „í•˜ê²Œ ì‹¤í–‰\n",
    "    \n",
    "    Args:\n",
    "        sql_query: ì‹¤í–‰í•  SQL ì¿¼ë¦¬\n",
    "        \n",
    "    Returns:\n",
    "        ì‹¤í–‰ ê²°ê³¼ ë˜ëŠ” ì˜¤ë¥˜ ë©”ì‹œì§€\n",
    "    \"\"\"\n",
    "    \n",
    "    if not spark:\n",
    "        return \"Error: Spark ì„¸ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    try:\n",
    "        # ì•ˆì „ì„± ê²€ì‚¬\n",
    "        sql_upper = sql_query.upper().strip()\n",
    "        \n",
    "        # ìœ„í—˜í•œ í‚¤ì›Œë“œ í™•ì¸\n",
    "        dangerous_keywords = ['DROP', 'DELETE', 'TRUNCATE', 'ALTER', 'CREATE', 'INSERT', 'UPDATE']\n",
    "        for keyword in dangerous_keywords:\n",
    "            if keyword in sql_upper:\n",
    "                return f\"Error: ì•ˆì „í•˜ì§€ ì•Šì€ SQL í‚¤ì›Œë“œ '{keyword}'ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\"\n",
    "        \n",
    "        # SELECT ì¿¼ë¦¬ë§Œ í—ˆìš©\n",
    "        if not sql_upper.startswith('SELECT') and not sql_upper.startswith('WITH'):\n",
    "            return \"Error: SELECT ì¿¼ë¦¬ë§Œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"\n",
    "        \n",
    "        # LIMIT í™•ì¸ ë° ì¶”ê°€\n",
    "        if 'LIMIT' not in sql_upper:\n",
    "            sql_query += \" LIMIT 100\"\n",
    "        \n",
    "        # ì¿¼ë¦¬ ì‹¤í–‰\n",
    "        start_time = datetime.now()\n",
    "        result_df = spark.sql(sql_query)\n",
    "        results = result_df.collect()\n",
    "        execution_time = (datetime.now() - start_time).total_seconds()\n",
    "        \n",
    "        # ê²°ê³¼ í¬ë§·íŒ…\n",
    "        if not results:\n",
    "            return \"ì¿¼ë¦¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆì§€ë§Œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "        \n",
    "        # íŒë‹¤ìŠ¤ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜\n",
    "        pandas_df = result_df.toPandas()\n",
    "        \n",
    "        result_text = f\"ì‹¤í–‰ ì™„ë£Œ ({len(results)}ê°œ í–‰, {execution_time:.3f}ì´ˆ):\\n\\n\"\n",
    "        \n",
    "        # ê²°ê³¼ í‘œì‹œ (ìµœëŒ€ 10ê°œ í–‰)\n",
    "        display_df = pandas_df.head(10)\n",
    "        result_text += display_df.to_string(index=False)\n",
    "        \n",
    "        if len(results) > 10:\n",
    "            result_text += f\"\\n\\n... ê·¸ ì™¸ {len(results) - 10}ê°œ í–‰\"\n",
    "        \n",
    "        return result_text\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error: SQL ì‹¤í–‰ ì‹¤íŒ¨ - {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def result_analysis_tool(sql_result: str, original_question: str) -> str:\n",
    "    \"\"\"SQL ì‹¤í–‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ì‚¬ìš©ì ì¹œí™”ì ìœ¼ë¡œ ìš”ì•½\n",
    "    \n",
    "    Args:\n",
    "        sql_result: SQL ì‹¤í–‰ ê²°ê³¼\n",
    "        original_question: ì›ë˜ ì‚¬ìš©ì ì§ˆë¬¸\n",
    "        \n",
    "    Returns:\n",
    "        ë¶„ì„ëœ ê²°ê³¼ ìš”ì•½\n",
    "    \"\"\"\n",
    "    \n",
    "    if not llm:\n",
    "        return \"Error: ì–¸ì–´ ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    try:\n",
    "        prompt = f\"\"\"ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ SQL ì‹¤í–‰ ê²°ê³¼ì…ë‹ˆë‹¤. \n",
    "ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ì›ë˜ ì§ˆë¬¸: {original_question}\n",
    "\n",
    "SQL ì‹¤í–‰ ê²°ê³¼:\n",
    "{sql_result}\n",
    "\n",
    "ìš”ì•½ ì‘ì„± ê°€ì´ë“œ:\n",
    "1. í•µì‹¬ ì •ë³´ë¥¼ ëª…í™•í•˜ê²Œ ì „ë‹¬\n",
    "2. ìˆ«ìë‚˜ ë°ì´í„°ê°€ ìˆë‹¤ë©´ ì˜ë¯¸ ìˆëŠ” ì¸ì‚¬ì´íŠ¸ ì œê³µ\n",
    "3. í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…\n",
    "4. í•„ìš”ì‹œ ì¶”ê°€ ì§ˆë¬¸ì´ë‚˜ ë¶„ì„ ë°©í–¥ ì œì•ˆ\n",
    "\n",
    "ìš”ì•½:\n",
    "\"\"\"\n",
    "        \n",
    "        analysis = llm.predict(prompt)\n",
    "        return analysis.strip()\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error: ê²°ê³¼ ë¶„ì„ ì‹¤íŒ¨ - {str(e)}\"\n",
    "\n",
    "print(\"âœ… Function Tools êµ¬í˜„ ì™„ë£Œ\")\n",
    "print(\"   ğŸ“‹ schema_search_tool: ìŠ¤í‚¤ë§ˆ ê²€ìƒ‰\")\n",
    "print(\"   ğŸ”§ sql_generation_tool: SQL ìƒì„±\")\n",
    "print(\"   âš¡ sql_execution_tool: SQL ì‹¤í–‰\")\n",
    "print(\"   ğŸ“Š result_analysis_tool: ê²°ê³¼ ë¶„ì„\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c72d41",
   "metadata": {},
   "source": [
    "## 5. LangChain Agent êµ¬ì„± ë° ì´ˆê¸°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4934d8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Agent ì´ˆê¸°í™” ì‹¤íŒ¨: Prompt missing required variables: {'tools'}\n",
      "ğŸ”„ Simple Agent ëª¨ë“œë¡œ ì „í™˜\n",
      "ğŸš€ Text-to-SQL Agent ì¤€ë¹„ ì™„ë£Œ!\n",
      "   ì§ˆë¬¸ ì˜ˆì‹œ: 'ê°€ì¥ ë¹„ì‹¼ ìƒí’ˆ 10ê°œë¥¼ ë³´ì—¬ì£¼ì„¸ìš”'\n"
     ]
    }
   ],
   "source": [
    "# LangChain Agent êµ¬ì„±\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "class TextToSQLAgent:\n",
    "    \"\"\"Text-to-SQL LangChain Agent í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, llm, tools):\n",
    "        self.llm = llm\n",
    "        self.tools = tools\n",
    "        self.agent_executor = None\n",
    "        self._setup_agent()\n",
    "    \n",
    "    def _setup_agent(self):\n",
    "        \"\"\"Agent ì´ˆê¸°í™”\"\"\"\n",
    "        \n",
    "        # Tool names for prompt\n",
    "        tool_names = [tool.name for tool in self.tools]\n",
    "        tool_descriptions = \"\\n\".join([f\"- {tool.name}: {tool.description}\" for tool in self.tools])\n",
    "        \n",
    "        # Agent í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "        agent_prompt = PromptTemplate.from_template(\"\"\"\n",
    "ë‹¹ì‹ ì€ Databricks Northwind ë°ì´í„°ë² ì´ìŠ¤ì˜ ì „ë¬¸ Text-to-SQL Assistantì…ë‹ˆë‹¤.\n",
    "\n",
    "ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤:\n",
    "{tool_descriptions}\n",
    "\n",
    "ë„êµ¬ ì´ë¦„ë“¤: {tool_names}\n",
    "\n",
    "ë„êµ¬ ì‚¬ìš© í˜•ì‹:\n",
    "```\n",
    "Action: [ë„êµ¬ëª…]\n",
    "Action Input: [ì…ë ¥ê°’]\n",
    "```\n",
    "\n",
    "ì‘ì—… íë¦„:\n",
    "1. ì‚¬ìš©ì ì§ˆë¬¸ ë¶„ì„\n",
    "2. schema_search_toolë¡œ ê´€ë ¨ í…Œì´ë¸” ê²€ìƒ‰\n",
    "3. sql_generation_toolë¡œ SQL ì¿¼ë¦¬ ìƒì„±\n",
    "4. sql_execution_toolë¡œ ì¿¼ë¦¬ ì‹¤í–‰\n",
    "5. result_analysis_toolë¡œ ê²°ê³¼ ë¶„ì„ ë° ìš”ì•½\n",
    "\n",
    "ì§€ì¹¨:\n",
    "- ì •í™•í•œ SQLì„ ìƒì„±í•˜ê¸° ìœ„í•´ ë°˜ë“œì‹œ ìŠ¤í‚¤ë§ˆë¥¼ ë¨¼ì € ê²€ìƒ‰í•˜ì„¸ìš”\n",
    "- SQL ì‹¤í–‰ ì „ì— ì¿¼ë¦¬ë¥¼ ê²€í† í•˜ì„¸ìš”\n",
    "- ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ì›ì¸ì„ ë¶„ì„í•˜ê³  ìˆ˜ì •í•˜ì„¸ìš”\n",
    "- ìµœì¢… ì‘ë‹µì€ ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ì œê³µí•˜ì„¸ìš”\n",
    "\n",
    "ì§ˆë¬¸: {input}\n",
    "\n",
    "ë„êµ¬ ì‹¤í–‰ ê¸°ë¡:\n",
    "{agent_scratchpad}\n",
    "\"\"\")\n",
    "\n",
    "        try:\n",
    "            # ReAct Agent ìƒì„± (ê°„ë‹¨í•œ ë°©ì‹ìœ¼ë¡œ ë³€ê²½)\n",
    "            from langchain.agents import create_react_agent\n",
    "            \n",
    "            agent = create_react_agent(\n",
    "                llm=self.llm,\n",
    "                tools=self.tools,\n",
    "                prompt=agent_prompt.partial(\n",
    "                    tool_names=\", \".join(tool_names),\n",
    "                    tool_descriptions=tool_descriptions\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # Agent Executor ìƒì„±\n",
    "            self.agent_executor = AgentExecutor(\n",
    "                agent=agent,\n",
    "                tools=self.tools,\n",
    "                verbose=True,\n",
    "                handle_parsing_errors=True,\n",
    "                max_iterations=10,\n",
    "                early_stopping_method=\"generate\"\n",
    "            )\n",
    "            \n",
    "            print(\"âœ… LangChain Agent ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Agent ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}\")\n",
    "            # ê°„ë‹¨í•œ ëŒ€ì•ˆ êµ¬í˜„\n",
    "            self._setup_simple_agent()\n",
    "    \n",
    "    def _setup_simple_agent(self):\n",
    "        \"\"\"ë‹¨ìˆœí•œ ëŒ€ì•ˆ Agent êµ¬í˜„\"\"\"\n",
    "        print(\"ğŸ”„ Simple Agent ëª¨ë“œë¡œ ì „í™˜\")\n",
    "        \n",
    "        class SimpleAgent:\n",
    "            def __init__(self, tools):\n",
    "                self.tools = {tool.name: tool for tool in tools}\n",
    "            \n",
    "            def invoke(self, query_dict):\n",
    "                \"\"\"ê°„ë‹¨í•œ Agent ì‹¤í–‰\"\"\"\n",
    "                question = query_dict.get(\"input\", \"\")\n",
    "                \n",
    "                try:\n",
    "                    # 1. ìŠ¤í‚¤ë§ˆ ê²€ìƒ‰\n",
    "                    schema_result = self.tools[\"schema_search_tool\"].run(question)\n",
    "                    print(f\"ğŸ” ìŠ¤í‚¤ë§ˆ ê²€ìƒ‰:\\n{schema_result}\\n\")\n",
    "                    \n",
    "                    # 2. SQL ìƒì„±\n",
    "                    sql_query = self.tools[\"sql_generation_tool\"].run(\n",
    "                        f\"ì§ˆë¬¸: {question}\\nìŠ¤í‚¤ë§ˆ: {schema_result}\"\n",
    "                    )\n",
    "                    print(f\"ğŸ”§ SQL ìƒì„±:\\n{sql_query}\\n\")\n",
    "                    \n",
    "                    # 3. SQL ì‹¤í–‰\n",
    "                    execution_result = self.tools[\"sql_execution_tool\"].run(sql_query)\n",
    "                    print(f\"âš¡ SQL ì‹¤í–‰:\\n{execution_result}\\n\")\n",
    "                    \n",
    "                    # 4. ê²°ê³¼ ë¶„ì„\n",
    "                    final_analysis = self.tools[\"result_analysis_tool\"].run(\n",
    "                        f\"ì§ˆë¬¸: {question}\\nê²°ê³¼: {execution_result}\"\n",
    "                    )\n",
    "                    \n",
    "                    return {\"output\": final_analysis}\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    return {\"output\": f\"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\"}\n",
    "        \n",
    "        self.agent_executor = SimpleAgent(self.tools)\n",
    "    \n",
    "    def query(self, question: str) -> str:\n",
    "        \"\"\"ìì—°ì–´ ì§ˆë¬¸ ì²˜ë¦¬\"\"\"\n",
    "        \n",
    "        if not self.agent_executor:\n",
    "            return \"Agentê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\"\n",
    "        \n",
    "        try:\n",
    "            result = self.agent_executor.invoke({\"input\": question})\n",
    "            return result.get(\"output\", \"ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"ì§ˆì˜ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}\"\n",
    "\n",
    "# Agent ì´ˆê¸°í™”\n",
    "if model_manager.is_available:\n",
    "    # ë„êµ¬ ëª©ë¡\n",
    "    tools = [\n",
    "        schema_search_tool,\n",
    "        sql_generation_tool, \n",
    "        sql_execution_tool,\n",
    "        result_analysis_tool\n",
    "    ]\n",
    "    \n",
    "    # Text-to-SQL Agent ìƒì„±\n",
    "    text_to_sql_agent = TextToSQLAgent(llm, tools)\n",
    "    \n",
    "    print(\"ğŸš€ Text-to-SQL Agent ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "    print(\"   ì§ˆë¬¸ ì˜ˆì‹œ: 'ê°€ì¥ ë¹„ì‹¼ ìƒí’ˆ 10ê°œë¥¼ ë³´ì—¬ì£¼ì„¸ìš”'\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ Agentë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    text_to_sql_agent = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f693d3e8",
   "metadata": {},
   "source": [
    "## 6. Agent í…ŒìŠ¤íŠ¸ ë° ì‚¬ìš© ì˜ˆì‹œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dad5e131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ ì‚¬ìš© ë°©ë²•:\n",
      "   1. test_text_to_sql_agent() - ìë™ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
      "   2. interactive_text_to_sql() - ëŒ€í™”í˜• ëª¨ë“œ\n",
      "   3. text_to_sql_agent.run('ì§ˆë¬¸') - ì§ì ‘ ì§ˆë¬¸\n",
      "\n",
      "ğŸ’¡ ì§ˆë¬¸ ì˜ˆì‹œ:\n",
      "   1. ì „ì²´ ê³ ê° ìˆ˜ëŠ”?\n",
      "   2. ë² ìŠ¤íŠ¸ì…€ëŸ¬ ìƒí’ˆ 10ê°œë¥¼ ë³´ì—¬ì¤˜\n",
      "   3. ì›”ë³„ ë§¤ì¶œ í˜„í™©ì€?\n",
      "   4. ê°€ì¥ ë¹„ì‹¼ ìƒí’ˆë“¤ì„ ì•Œë ¤ì¤˜\n",
      "   5. ê³ ê°ë³„ ì£¼ë¬¸ íšŸìˆ˜ëŠ”?\n",
      "\n",
      "ğŸš€ ì¤€ë¹„ ì™„ë£Œ! ì§ˆë¬¸ì„ ì‹œì‘í•´ë³´ì„¸ìš”!\n",
      "ğŸ® Text-to-SQL Agent í…ŒìŠ¤íŠ¸ ì˜µì…˜:\n",
      "1. ìë™ í…ŒìŠ¤íŠ¸ ì‹¤í–‰: test_agent_with_examples()\n",
      "2. ëŒ€í™”í˜• ë°ëª¨ ì‹¤í–‰: interactive_query_demo()\n",
      "\n",
      "ì˜ˆì‹œ ì‹¤í–‰:\n",
      "# test_agent_with_examples()  # ìë™ í…ŒìŠ¤íŠ¸\n",
      "# interactive_query_demo()    # ëŒ€í™”í˜• ë°ëª¨\n"
     ]
    }
   ],
   "source": [
    "# Agent í…ŒìŠ¤íŠ¸ í•¨ìˆ˜\n",
    "def test_text_to_sql_agent():\n",
    "    \"\"\"Text-to-SQL Agent ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    \n",
    "    if not text_to_sql_agent:\n",
    "        print(\"âŒ Agentê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤\n",
    "    test_questions = [\n",
    "        \"ì „ì²´ ê³ ê° ìˆ˜ëŠ” ëª‡ ëª…ì¸ê°€ìš”?\",\n",
    "        \"ê°€ì¥ ë§ì´ íŒ”ë¦° ìƒí’ˆ 5ê°œë¥¼ ë³´ì—¬ì£¼ì„¸ìš”\",\n",
    "        \"ì›”ë³„ ì£¼ë¬¸ í˜„í™©ì„ ì•Œë ¤ì£¼ì„¸ìš”\",\n",
    "        \"ì¹´í…Œê³ ë¦¬ë³„ ìƒí’ˆ ê°œìˆ˜ëŠ”?\"\n",
    "    ]\n",
    "    \n",
    "    print(\"ğŸ§ª Text-to-SQL Agent í…ŒìŠ¤íŠ¸ ì‹œì‘\\n\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for i, question in enumerate(test_questions, 1):\n",
    "        print(f\"\\nğŸ” í…ŒìŠ¤íŠ¸ {i}: {question}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        try:\n",
    "            # Agent ì‹¤í–‰\n",
    "            response = text_to_sql_agent.run(question)\n",
    "            print(f\"\\nâœ… ì‘ë‹µ: {response}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜: {str(e)}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    print(\"ğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "\n",
    "# ëŒ€í™”í˜• ì‚¬ìš© í•¨ìˆ˜\n",
    "def interactive_text_to_sql():\n",
    "    \"\"\"ëŒ€í™”í˜• Text-to-SQL ì„¸ì…˜\"\"\"\n",
    "    \n",
    "    if not text_to_sql_agent:\n",
    "        print(\"âŒ Agentê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    print(\"ğŸ¤– Text-to-SQL Agentì™€ ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤!\")\n",
    "    print(\"   ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            question = input(\"ğŸ’¬ ì§ˆë¬¸: \").strip()\n",
    "            \n",
    "            if question.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:\n",
    "                print(\"ğŸ‘‹ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "                break\n",
    "            \n",
    "            if not question:\n",
    "                continue\n",
    "            \n",
    "            print(\"\\nğŸ¤– Agent ì²˜ë¦¬ ì¤‘...\")\n",
    "            response = text_to_sql_agent.run(question)\n",
    "            print(f\"\\nâœ… ë‹µë³€: {response}\\n\")\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nğŸ‘‹ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\\n\")\n",
    "\n",
    "# ì‚¬ìš© ê°€ì´ë“œ ì¶œë ¥\n",
    "if text_to_sql_agent:\n",
    "    print(\"ğŸ¯ ì‚¬ìš© ë°©ë²•:\")\n",
    "    print(\"   1. test_text_to_sql_agent() - ìë™ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\")\n",
    "    print(\"   2. interactive_text_to_sql() - ëŒ€í™”í˜• ëª¨ë“œ\")\n",
    "    print(\"   3. text_to_sql_agent.run('ì§ˆë¬¸') - ì§ì ‘ ì§ˆë¬¸\")\n",
    "    \n",
    "    print(\"\\nğŸ’¡ ì§ˆë¬¸ ì˜ˆì‹œ:\")\n",
    "    examples = [\n",
    "        \"ì „ì²´ ê³ ê° ìˆ˜ëŠ”?\",\n",
    "        \"ë² ìŠ¤íŠ¸ì…€ëŸ¬ ìƒí’ˆ 10ê°œë¥¼ ë³´ì—¬ì¤˜\",\n",
    "        \"ì›”ë³„ ë§¤ì¶œ í˜„í™©ì€?\",\n",
    "        \"ê°€ì¥ ë¹„ì‹¼ ìƒí’ˆë“¤ì„ ì•Œë ¤ì¤˜\",\n",
    "        \"ê³ ê°ë³„ ì£¼ë¬¸ íšŸìˆ˜ëŠ”?\"\n",
    "    ]\n",
    "    \n",
    "    for i, example in enumerate(examples, 1):\n",
    "        print(f\"   {i}. {example}\")\n",
    "    \n",
    "    print(\"\\nğŸš€ ì¤€ë¹„ ì™„ë£Œ! ì§ˆë¬¸ì„ ì‹œì‘í•´ë³´ì„¸ìš”!\")\n",
    "else:\n",
    "    print(\"âŒ Agent ì‚¬ìš© ë¶ˆê°€. ìœ„ì˜ ì´ˆê¸°í™” ë‹¨ê³„ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# Text-to-SQL Agent í…ŒìŠ¤íŠ¸ ë° ë°ëª¨\n",
    "\n",
    "def test_agent_with_examples():\n",
    "    \"\"\"ë‹¤ì–‘í•œ ì˜ˆì‹œ ì§ˆë¬¸ìœ¼ë¡œ Agent í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    \n",
    "    if not text_to_sql_agent:\n",
    "        print(\"âŒ Agentê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤ (ë‚œì´ë„ë³„)\n",
    "    test_questions = [\n",
    "        # ê¸°ë³¸ ì§ˆë¬¸\n",
    "        {\n",
    "            \"level\": \"ê¸°ë³¸\",\n",
    "            \"question\": \"ëª¨ë“  ê³ ê°ì˜ ì´ë¦„ê³¼ ë„ì‹œë¥¼ ë³´ì—¬ì£¼ì„¸ìš”\",\n",
    "            \"expected\": \"customers í…Œì´ë¸”ì˜ ê¸°ë³¸ ì •ë³´ ì¡°íšŒ\"\n",
    "        },\n",
    "        \n",
    "        # ì§‘ê³„ ì§ˆë¬¸  \n",
    "        {\n",
    "            \"level\": \"ì¤‘ê¸‰\",\n",
    "            \"question\": \"ê°€ì¥ ë¹„ì‹¼ ìƒí’ˆ 5ê°œë¥¼ ê°€ê²©ê³¼ í•¨ê»˜ ì•Œë ¤ì£¼ì„¸ìš”\",\n",
    "            \"expected\": \"products í…Œì´ë¸”ì—ì„œ ê°€ê²© ê¸°ì¤€ ìƒìœ„ 5ê°œ\"\n",
    "        },\n",
    "        \n",
    "        # ì¡°ì¸ ì§ˆë¬¸\n",
    "        {\n",
    "            \"level\": \"ê³ ê¸‰\", \n",
    "            \"question\": \"ê° ì¹´í…Œê³ ë¦¬ë³„ ìƒí’ˆ ê°œìˆ˜ì™€ í‰ê·  ê°€ê²©ì„ êµ¬í•´ì£¼ì„¸ìš”\",\n",
    "            \"expected\": \"productsì™€ categories ì¡°ì¸, ì§‘ê³„ í•¨ìˆ˜\"\n",
    "        },\n",
    "        \n",
    "        # ë³µì¡í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ì§ˆë¬¸\n",
    "        {\n",
    "            \"level\": \"ì „ë¬¸ê°€\",\n",
    "            \"question\": \"1997ë…„ì— ê°€ì¥ ë§ì€ ì£¼ë¬¸ì„ ë°›ì€ ì§ì›ì˜ ì´ë¦„ê³¼ ì£¼ë¬¸ ê±´ìˆ˜ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”\",\n",
    "            \"expected\": \"orders, employees ì¡°ì¸, ë‚ ì§œ í•„í„°ë§, ì§‘ê³„\"\n",
    "        },\n",
    "        \n",
    "        # í•œêµ­ì–´ ìì—°ì–´ ì§ˆë¬¸\n",
    "        {\n",
    "            \"level\": \"ìì—°ì–´\",\n",
    "            \"question\": \"ê³ ê°ë³„ë¡œ ì´ ì£¼ë¬¸ ê¸ˆì•¡ì´ ì–¼ë§ˆì¸ì§€ ìƒìœ„ 10ëª…ì„ ë³´ì—¬ì¤˜\",\n",
    "            \"expected\": \"customers, orders, order_details ì¡°ì¸, ì§‘ê³„, ì •ë ¬\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"ğŸ§ª Text-to-SQL Agent í…ŒìŠ¤íŠ¸ ì‹œì‘\\n\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for i, test_case in enumerate(test_questions, 1):\n",
    "        print(f\"\\nğŸ“‹ í…ŒìŠ¤íŠ¸ {i}: {test_case['level']} ìˆ˜ì¤€\")\n",
    "        print(f\"ì§ˆë¬¸: {test_case['question']}\")\n",
    "        print(f\"ì˜ˆìƒ: {test_case['expected']}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        try:\n",
    "            # Agent ì‹¤í–‰\n",
    "            start_time = datetime.now()\n",
    "            response = text_to_sql_agent.query(test_case['question'])\n",
    "            execution_time = (datetime.now() - start_time).total_seconds()\n",
    "            \n",
    "            print(f\"ğŸ“Š ì‘ë‹µ ({execution_time:.2f}ì´ˆ):\")\n",
    "            print(response)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜: {str(e)}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        \n",
    "        # ì‚¬ìš©ìê°€ ê° í…ŒìŠ¤íŠ¸ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë„ë¡ ì ì‹œ ëŒ€ê¸°\n",
    "        # (ì‹¤ì œ ìš´ì˜ì‹œì—ëŠ” ì œê±°)\n",
    "\n",
    "def interactive_query_demo():\n",
    "    \"\"\"ëŒ€í™”í˜• ì§ˆì˜ ë°ëª¨\"\"\"\n",
    "    \n",
    "    if not text_to_sql_agent:\n",
    "        print(\"âŒ Agentê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    print(\"ğŸ¯ ëŒ€í™”í˜• Text-to-SQL ë°ëª¨\")\n",
    "    print(\"ì›í•˜ëŠ” ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”. ('quit'ë¡œ ì¢…ë£Œ)\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    sample_questions = [\n",
    "        \"ê° ì§ì›ë³„ ì´ ë§¤ì¶œì•¡ì„ êµ¬í•´ì£¼ì„¸ìš”\",\n",
    "        \"í”„ë‘ìŠ¤ ê³ ê°ë“¤ì˜ ì£¼ë¬¸ ë‚´ì—­ì„ ë³´ì—¬ì£¼ì„¸ìš”\", \n",
    "        \"ê°€ì¥ ì¸ê¸°ìˆëŠ” ìƒí’ˆ ì¹´í…Œê³ ë¦¬ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "        \"1996ë…„ ì›”ë³„ ë§¤ì¶œ ì¶”ì´ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”\",\n",
    "        \"ë°°ì†¡ì´ ê°€ì¥ ë¹ ë¥¸ ìš´ì†¡ì—…ì²´ëŠ” ì–´ë””ì¸ê°€ìš”?\"\n",
    "    ]\n",
    "    \n",
    "    print(\"ğŸ’¡ ìƒ˜í”Œ ì§ˆë¬¸ë“¤:\")\n",
    "    for i, q in enumerate(sample_questions, 1):\n",
    "        print(f\"   {i}. {q}\")\n",
    "    print()\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\"ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: \").strip()\n",
    "            \n",
    "            if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ', 'q']:\n",
    "                print(\"ğŸ‘‹ Text-to-SQL ë°ëª¨ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "                break\n",
    "            \n",
    "            if not user_input:\n",
    "                continue\n",
    "            \n",
    "            print(f\"\\nğŸ”„ ì²˜ë¦¬ ì¤‘: '{user_input}'\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            start_time = datetime.now()\n",
    "            response = text_to_sql_agent.query(user_input)\n",
    "            execution_time = (datetime.now() - start_time).total_seconds()\n",
    "            \n",
    "            print(f\"\\nğŸ“Š ì‘ë‹µ ({execution_time:.2f}ì´ˆ):\")\n",
    "            print(response)\n",
    "            print(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nğŸ‘‹ Text-to-SQL ë°ëª¨ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
    "\n",
    "# ë°ëª¨ ì‹¤í–‰ ì˜µì…˜\n",
    "print(\"ğŸ® Text-to-SQL Agent í…ŒìŠ¤íŠ¸ ì˜µì…˜:\")\n",
    "print(\"1. ìë™ í…ŒìŠ¤íŠ¸ ì‹¤í–‰: test_agent_with_examples()\")\n",
    "print(\"2. ëŒ€í™”í˜• ë°ëª¨ ì‹¤í–‰: interactive_query_demo()\")\n",
    "print(\"\\nì˜ˆì‹œ ì‹¤í–‰:\")\n",
    "print(\"# test_agent_with_examples()  # ìë™ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"# interactive_query_demo()    # ëŒ€í™”í˜• ë°ëª¨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3d5d455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Agent ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\n",
      "========================================\n",
      "ì§ˆë¬¸: ì „ì²´ ê³ ê° ìˆ˜ëŠ” ëª‡ ëª…ì¸ê°€ìš”?\n",
      "ì²˜ë¦¬ ì¤‘...\n",
      "ğŸ” ìŠ¤í‚¤ë§ˆ ê²€ìƒ‰:\n",
      "ì§ˆì˜ 'ì „ì²´ ê³ ê° ìˆ˜ëŠ” ëª‡ ëª…ì¸ê°€ìš”?'ì™€ ê´€ë ¨ëœ í…Œì´ë¸”ë“¤:\n",
      "\n",
      "1. customers (ê´€ë ¨ë„: 8)\n",
      "   ì»¬ëŸ¼: customer_id (string), company_name (string), contact_name (string), contact_title (string), address (string)\n",
      "   ìƒ˜í”Œ: customer_id=KOREA, company_name=í•œêµ­ì‹ë‹¹, contact_name=ê¹€í•œêµ­\n",
      "\n",
      "\n",
      "\n",
      "ğŸ”§ SQL ìƒì„±:\n",
      "SELECT COUNT(*) as customer_count FROM northwind.customers\n",
      "\n",
      "ğŸ” ìŠ¤í‚¤ë§ˆ ê²€ìƒ‰:\n",
      "ì§ˆì˜ 'ì „ì²´ ê³ ê° ìˆ˜ëŠ” ëª‡ ëª…ì¸ê°€ìš”?'ì™€ ê´€ë ¨ëœ í…Œì´ë¸”ë“¤:\n",
      "\n",
      "1. customers (ê´€ë ¨ë„: 8)\n",
      "   ì»¬ëŸ¼: customer_id (string), company_name (string), contact_name (string), contact_title (string), address (string)\n",
      "   ìƒ˜í”Œ: customer_id=KOREA, company_name=í•œêµ­ì‹ë‹¹, contact_name=ê¹€í•œêµ­\n",
      "\n",
      "\n",
      "\n",
      "ğŸ”§ SQL ìƒì„±:\n",
      "SELECT COUNT(*) as customer_count FROM northwind.customers\n",
      "\n",
      "âš¡ SQL ì‹¤í–‰:\n",
      "ì‹¤í–‰ ì™„ë£Œ (1ê°œ í–‰, 0.633ì´ˆ):\n",
      "\n",
      " customer_count\n",
      "              5\n",
      "\n",
      "âœ… ì‘ë‹µ: ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: 1 validation error for result_analysis_tool\n",
      "original_question\n",
      "  Field required [type=missing, input_value={'sql_result': 'ì§ˆë¬¸: ...count\\n              5'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      "\n",
      "========================================\n",
      "âš¡ SQL ì‹¤í–‰:\n",
      "ì‹¤í–‰ ì™„ë£Œ (1ê°œ í–‰, 0.633ì´ˆ):\n",
      "\n",
      " customer_count\n",
      "              5\n",
      "\n",
      "âœ… ì‘ë‹µ: ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: 1 validation error for result_analysis_tool\n",
      "original_question\n",
      "  Field required [type=missing, input_value={'sql_result': 'ì§ˆë¬¸: ...count\\n              5'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      "\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# ê°„ë‹¨í•œ Agent í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "print(\"ğŸ§ª Agent ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if text_to_sql_agent:\n",
    "    try:\n",
    "        # ê°„ë‹¨í•œ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸\n",
    "        test_question = \"ì „ì²´ ê³ ê° ìˆ˜ëŠ” ëª‡ ëª…ì¸ê°€ìš”?\"\n",
    "        print(f\"ì§ˆë¬¸: {test_question}\")\n",
    "        print(\"ì²˜ë¦¬ ì¤‘...\")\n",
    "        \n",
    "        response = text_to_sql_agent.query(test_question)\n",
    "        print(f\"âœ… ì‘ë‹µ: {response}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}\")\n",
    "else:\n",
    "    print(\"âŒ Agentê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20720800",
   "metadata": {},
   "source": [
    "## 7. ê³ ê¸‰ ê¸°ëŠ¥: ì»¤ìŠ¤í…€ Agent ì›Œí¬í”Œë¡œìš°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e005a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì»¤ìŠ¤í…€ ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™” ì™„ë£Œ\n",
      "   ğŸ’¾ ìºì‹± ê¸°ëŠ¥\n",
      "   ğŸ“ ëŒ€í™” íˆìŠ¤í† ë¦¬\n",
      "   ğŸ“Š ì„±ëŠ¥ ì¸¡ì •\n",
      "   ğŸ“ íˆìŠ¤í† ë¦¬ ë‚´ë³´ë‚´ê¸°\n",
      "âœ… ê³ ê¸‰ ê¸°ëŠ¥ ì´ˆê¸°í™” ì™„ë£Œ\n",
      "   ğŸ“Š ì¿¼ë¦¬ ì„±ëŠ¥ ë¶„ì„\n",
      "   ğŸ” ì‹¤í–‰ ê³„íš ì„¤ëª…\n",
      "   ğŸ“ ì¿¼ë¦¬ íˆìŠ¤í† ë¦¬ ê´€ë¦¬\n",
      "   ğŸ¯ ë‹¤ì–‘í•œ SQL ì ‘ê·¼ë²• ìƒì„±\n",
      "\n",
      "ğŸ¯ ê³ ê¸‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸:\n",
      "demonstrate_advanced_features()  # ê³ ê¸‰ ê¸°ëŠ¥ ì‹œì—°\n"
     ]
    }
   ],
   "source": [
    "# ì»¤ìŠ¤í…€ Agent ì›Œí¬í”Œë¡œìš° í´ë˜ìŠ¤\n",
    "class CustomTextToSQLWorkflow:\n",
    "    \"\"\"ì»¤ìŠ¤í„°ë§ˆì´ì§•ëœ Text-to-SQL ì›Œí¬í”Œë¡œìš°\"\"\"\n",
    "    \n",
    "    def __init__(self, agent):\n",
    "        self.agent = agent\n",
    "        self.conversation_history = []\n",
    "        self.query_cache = {}\n",
    "    \n",
    "    def process_question(self, question: str, use_cache: bool = True) -> Dict[str, Any]:\n",
    "        \"\"\"ì§ˆë¬¸ ì²˜ë¦¬ (ìºì‹± ë° íˆìŠ¤í† ë¦¬ í¬í•¨)\"\"\"\n",
    "        \n",
    "        # ìºì‹œ í™•ì¸\n",
    "        if use_cache and question in self.query_cache:\n",
    "            print(\"ğŸ’¾ ìºì‹œì—ì„œ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\")\n",
    "            return self.query_cache[question]\n",
    "        \n",
    "        try:\n",
    "            start_time = datetime.now()\n",
    "            \n",
    "            # Agent ì‹¤í–‰\n",
    "            response = self.agent.run(question)\n",
    "            \n",
    "            end_time = datetime.now()\n",
    "            processing_time = (end_time - start_time).total_seconds()\n",
    "            \n",
    "            result = {\n",
    "                \"question\": question,\n",
    "                \"response\": response,\n",
    "                \"timestamp\": start_time.isoformat(),\n",
    "                \"processing_time\": processing_time,\n",
    "                \"success\": True\n",
    "            }\n",
    "            \n",
    "            # íˆìŠ¤í† ë¦¬ ë° ìºì‹œ ì €ì¥\n",
    "            self.conversation_history.append(result)\n",
    "            if use_cache:\n",
    "                self.query_cache[question] = result\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_result = {\n",
    "                \"question\": question,\n",
    "                \"error\": str(e),\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"success\": False\n",
    "            }\n",
    "            \n",
    "            self.conversation_history.append(error_result)\n",
    "            return error_result\n",
    "    \n",
    "    def get_history(self, limit: int = 5) -> List[Dict[str, Any]]:\n",
    "        \"\"\"ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ\"\"\"\n",
    "        return self.conversation_history[-limit:]\n",
    "    \n",
    "    def clear_cache(self):\n",
    "        \"\"\"ìºì‹œ ì´ˆê¸°í™”\"\"\"\n",
    "        self.query_cache.clear()\n",
    "        print(\"ğŸ—‘ï¸ ìºì‹œê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    def export_history(self, filepath: str = None):\n",
    "        \"\"\"íˆìŠ¤í† ë¦¬ë¥¼ JSON íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°\"\"\"\n",
    "        if not filepath:\n",
    "            filepath = f\"text_to_sql_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "        \n",
    "        try:\n",
    "            with open(filepath, 'w', encoding='utf-8') as f:\n",
    "                json.dump(self.conversation_history, f, ensure_ascii=False, indent=2)\n",
    "            print(f\"ğŸ“ íˆìŠ¤í† ë¦¬ê°€ {filepath}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ íˆìŠ¤í† ë¦¬ ì €ì¥ ì‹¤íŒ¨: {str(e)}\")\n",
    "\n",
    "# ì»¤ìŠ¤í…€ ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™”\n",
    "if text_to_sql_agent:\n",
    "    custom_workflow = CustomTextToSQLWorkflow(text_to_sql_agent)\n",
    "    print(\"âœ… ì»¤ìŠ¤í…€ ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "    print(\"   ğŸ’¾ ìºì‹± ê¸°ëŠ¥\")\n",
    "    print(\"   ğŸ“ ëŒ€í™” íˆìŠ¤í† ë¦¬\")\n",
    "    print(\"   ğŸ“Š ì„±ëŠ¥ ì¸¡ì •\")\n",
    "    print(\"   ğŸ“ íˆìŠ¤í† ë¦¬ ë‚´ë³´ë‚´ê¸°\")\n",
    "else:\n",
    "    custom_workflow = None\n",
    "    print(\"âš ï¸ Agentê°€ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "# ê³ ê¸‰ ê¸°ëŠ¥ ë° í™•ì¥ ê¸°ëŠ¥\n",
    "\n",
    "class AdvancedTextToSQLFeatures:\n",
    "    \"\"\"Text-to-SQL ì‹œìŠ¤í…œì˜ ê³ ê¸‰ ê¸°ëŠ¥ë“¤\"\"\"\n",
    "    \n",
    "    def __init__(self, agent, spark_session):\n",
    "        self.agent = agent\n",
    "        self.spark = spark_session\n",
    "        self.query_history = []\n",
    "        self.schema_cache = {}\n",
    "    \n",
    "    def explain_query(self, sql_query: str) -> str:\n",
    "        \"\"\"SQL ì¿¼ë¦¬ ì‹¤í–‰ ê³„íš ì„¤ëª…\"\"\"\n",
    "        try:\n",
    "            explain_result = self.spark.sql(f\"EXPLAIN {sql_query}\").collect()\n",
    "            plan = \"\\n\".join([row.plan for row in explain_result])\n",
    "            return f\"ì¿¼ë¦¬ ì‹¤í–‰ ê³„íš:\\n{plan}\"\n",
    "        except Exception as e:\n",
    "            return f\"ì‹¤í–‰ ê³„íš ìƒì„± ì‹¤íŒ¨: {str(e)}\"\n",
    "    \n",
    "    def validate_query_performance(self, sql_query: str) -> dict:\n",
    "        \"\"\"ì¿¼ë¦¬ ì„±ëŠ¥ ê²€ì¦\"\"\"\n",
    "        performance_info = {\n",
    "            \"is_optimized\": True,\n",
    "            \"warnings\": [],\n",
    "            \"suggestions\": []\n",
    "        }\n",
    "        \n",
    "        sql_upper = sql_query.upper()\n",
    "        \n",
    "        # ì„±ëŠ¥ ê²€ì‚¬ ê·œì¹™ë“¤\n",
    "        if \"SELECT *\" in sql_upper:\n",
    "            performance_info[\"warnings\"].append(\"SELECT * ì‚¬ìš© - í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤\")\n",
    "            performance_info[\"is_optimized\"] = False\n",
    "        \n",
    "        if \"WHERE\" not in sql_upper and \"LIMIT\" not in sql_upper:\n",
    "            performance_info[\"warnings\"].append(\"WHERE ì ˆì´ë‚˜ LIMITì´ ì—†ìŒ - ëŒ€ìš©ëŸ‰ ë°ì´í„° ìŠ¤ìº” ê°€ëŠ¥\")\n",
    "            performance_info[\"is_optimized\"] = False\n",
    "        \n",
    "        if sql_upper.count(\"JOIN\") > 3:\n",
    "            performance_info[\"warnings\"].append(\"ë‹¤ì¤‘ ì¡°ì¸ ì‚¬ìš© - ì„±ëŠ¥ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤\")\n",
    "            performance_info[\"suggestions\"].append(\"ì¡°ì¸ ìˆœì„œ ìµœì í™” ê³ ë ¤\")\n",
    "        \n",
    "        if \"GROUP BY\" in sql_upper and \"ORDER BY\" in sql_upper:\n",
    "            performance_info[\"suggestions\"].append(\"GROUP BY ì ˆì— ORDER BY í¬í•¨ ê³ ë ¤\")\n",
    "        \n",
    "        return performance_info\n",
    "    \n",
    "    def generate_query_variations(self, original_question: str) -> list:\n",
    "        \"\"\"ê°™ì€ ì§ˆë¬¸ì— ëŒ€í•œ ë‹¤ì–‘í•œ SQL ì ‘ê·¼ë²• ìƒì„±\"\"\"\n",
    "        \n",
    "        if not self.agent:\n",
    "            return []\n",
    "        \n",
    "        variations = []\n",
    "        \n",
    "        # ë‹¤ì–‘í•œ ì ‘ê·¼ë²• í”„ë¡¬í”„íŠ¸\n",
    "        approaches = [\n",
    "            \"ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•ìœ¼ë¡œ\",\n",
    "            \"ì„±ëŠ¥ì„ ìµœì í™”í•˜ì—¬\", \n",
    "            \"ê°€ë…ì„±ì„ ì¤‘ì‹œí•˜ì—¬\",\n",
    "            \"ì§‘ê³„ í•¨ìˆ˜ë¥¼ í™œìš©í•˜ì—¬\"\n",
    "        ]\n",
    "        \n",
    "        for approach in approaches:\n",
    "            try:\n",
    "                modified_question = f\"{approach} {original_question}\"\n",
    "                # ì—¬ê¸°ì„œëŠ” SQL ìƒì„± ë„êµ¬ë§Œ ì‚¬ìš©\n",
    "                sql_result = sql_generation_tool.run(modified_question)\n",
    "                variations.append({\n",
    "                    \"approach\": approach,\n",
    "                    \"sql\": sql_result\n",
    "                })\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        return variations\n",
    "    \n",
    "    def save_query_history(self, question: str, sql_query: str, result: str):\n",
    "        \"\"\"ì¿¼ë¦¬ íˆìŠ¤í† ë¦¬ ì €ì¥\"\"\"\n",
    "        self.query_history.append({\n",
    "            \"timestamp\": datetime.now(),\n",
    "            \"question\": question,\n",
    "            \"sql\": sql_query,\n",
    "            \"result\": result[:500] + \"...\" if len(result) > 500 else result\n",
    "        })\n",
    "    \n",
    "    def get_query_statistics(self) -> dict:\n",
    "        \"\"\"ì¿¼ë¦¬ í†µê³„ ì •ë³´\"\"\"\n",
    "        if not self.query_history:\n",
    "            return {\"message\": \"ì•„ì§ ì‹¤í–‰ëœ ì¿¼ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.\"}\n",
    "        \n",
    "        stats = {\n",
    "            \"total_queries\": len(self.query_history),\n",
    "            \"unique_tables\": set(),\n",
    "            \"common_patterns\": {},\n",
    "            \"recent_queries\": self.query_history[-5:]\n",
    "        }\n",
    "        \n",
    "        # í…Œì´ë¸” ì‚¬ìš© íŒ¨í„´ ë¶„ì„\n",
    "        for query in self.query_history:\n",
    "            sql_upper = query[\"sql\"].upper()\n",
    "            \n",
    "            # í…Œì´ë¸” ì¶”ì¶œ (ê°„ë‹¨í•œ ë°©ë²•)\n",
    "            if \"FROM\" in sql_upper:\n",
    "                from_parts = sql_upper.split(\"FROM\")[1].split(\"WHERE\")[0].split(\"JOIN\")[0]\n",
    "                table_name = from_parts.strip().split()[0].replace(\"NORTHWIND.\", \"\")\n",
    "                stats[\"unique_tables\"].add(table_name)\n",
    "            \n",
    "            # íŒ¨í„´ ë¶„ì„\n",
    "            if \"JOIN\" in sql_upper:\n",
    "                stats[\"common_patterns\"][\"joins\"] = stats[\"common_patterns\"].get(\"joins\", 0) + 1\n",
    "            if \"GROUP BY\" in sql_upper:\n",
    "                stats[\"common_patterns\"][\"aggregations\"] = stats[\"common_patterns\"].get(\"aggregations\", 0) + 1\n",
    "            if \"ORDER BY\" in sql_upper:\n",
    "                stats[\"common_patterns\"][\"sorting\"] = stats[\"common_patterns\"].get(\"sorting\", 0) + 1\n",
    "        \n",
    "        return stats\n",
    "\n",
    "# ê³ ê¸‰ ê¸°ëŠ¥ ì´ˆê¸°í™”\n",
    "if text_to_sql_agent and spark:\n",
    "    advanced_features = AdvancedTextToSQLFeatures(text_to_sql_agent, spark)\n",
    "    print(\"âœ… ê³ ê¸‰ ê¸°ëŠ¥ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "    print(\"   ğŸ“Š ì¿¼ë¦¬ ì„±ëŠ¥ ë¶„ì„\")\n",
    "    print(\"   ğŸ” ì‹¤í–‰ ê³„íš ì„¤ëª…\") \n",
    "    print(\"   ğŸ“ ì¿¼ë¦¬ íˆìŠ¤í† ë¦¬ ê´€ë¦¬\")\n",
    "    print(\"   ğŸ¯ ë‹¤ì–‘í•œ SQL ì ‘ê·¼ë²• ìƒì„±\")\n",
    "else:\n",
    "    advanced_features = None\n",
    "    print(\"âš ï¸ ê³ ê¸‰ ê¸°ëŠ¥ ì´ˆê¸°í™” ì‹¤íŒ¨ - Agent ë˜ëŠ” Spark ì„¸ì…˜ ì—†ìŒ\")\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ í•¨ìˆ˜ë“¤\n",
    "def demonstrate_advanced_features():\n",
    "    \"\"\"ê³ ê¸‰ ê¸°ëŠ¥ ì‹œì—°\"\"\"\n",
    "    \n",
    "    if not advanced_features:\n",
    "        print(\"âŒ ê³ ê¸‰ ê¸°ëŠ¥ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    print(\"ğŸš€ ê³ ê¸‰ ê¸°ëŠ¥ ì‹œì—°\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. ì¿¼ë¦¬ ë³€í˜• ìƒì„±\n",
    "    question = \"ìƒí’ˆë³„ ë§¤ì¶œì„ ë³´ì—¬ì£¼ì„¸ìš”\"\n",
    "    print(f\"\\n1. ë‹¤ì–‘í•œ SQL ì ‘ê·¼ë²• ìƒì„±\")\n",
    "    print(f\"ì§ˆë¬¸: {question}\")\n",
    "    \n",
    "    variations = advanced_features.generate_query_variations(question)\n",
    "    for i, var in enumerate(variations, 1):\n",
    "        print(f\"\\n{i}. {var['approach']}:\")\n",
    "        print(f\"   {var['sql']}\")\n",
    "    \n",
    "    # 2. ì„±ëŠ¥ ê²€ì¦ ì˜ˆì‹œ\n",
    "    print(f\"\\n2. ì¿¼ë¦¬ ì„±ëŠ¥ ê²€ì¦\")\n",
    "    sample_sql = \"SELECT * FROM northwind.products JOIN northwind.categories ON products.categoryid = categories.categoryid\"\n",
    "    performance = advanced_features.validate_query_performance(sample_sql)\n",
    "    \n",
    "    print(f\"ìµœì í™” ìƒíƒœ: {'âœ…' if performance['is_optimized'] else 'âš ï¸'}\")\n",
    "    for warning in performance['warnings']:\n",
    "        print(f\"   âš ï¸ {warning}\")\n",
    "    for suggestion in performance['suggestions']:\n",
    "        print(f\"   ğŸ’¡ {suggestion}\")\n",
    "    \n",
    "    # 3. ì¿¼ë¦¬ í†µê³„\n",
    "    print(f\"\\n3. ì¿¼ë¦¬ í†µê³„\")\n",
    "    stats = advanced_features.get_query_statistics()\n",
    "    print(f\"ì´ ì¿¼ë¦¬ ìˆ˜: {stats.get('total_queries', 0)}\")\n",
    "    print(f\"ì‚¬ìš©ëœ í…Œì´ë¸”: {', '.join(stats.get('unique_tables', []))}\")\n",
    "    print(f\"ê³µí†µ íŒ¨í„´: {stats.get('common_patterns', {})}\")\n",
    "\n",
    "print(\"\\nğŸ¯ ê³ ê¸‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸:\")\n",
    "print(\"demonstrate_advanced_features()  # ê³ ê¸‰ ê¸°ëŠ¥ ì‹œì—°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55561a29",
   "metadata": {},
   "source": [
    "## 8. ì¢…í•© í…ŒìŠ¤íŠ¸ ë° ì„±ëŠ¥ í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "285f18ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ ì¤€ë¹„ ì™„ë£Œ! ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì‹¤í–‰í•´ë³´ì„¸ìš”:\n",
      "   1. comprehensive_test() - ì¢…í•© í…ŒìŠ¤íŠ¸\n",
      "   2. custom_workflow.process_question('ì§ˆë¬¸') - ê°œë³„ ì§ˆë¬¸\n",
      "   3. interactive_text_to_sql() - ëŒ€í™”í˜• ëª¨ë“œ\n",
      "\n",
      "ğŸš€ LangChain Agent ê¸°ë°˜ Text-to-SQL ì‹œìŠ¤í…œ ì™„ì„±!\n",
      "ğŸ‰ Databricks Text-to-SQL RAG ì‹œìŠ¤í…œ êµ¬í˜„ ì™„ë£Œ!\n",
      "============================================================\n",
      "ğŸ“‹ Databricks Text-to-SQL RAG ì‹œìŠ¤í…œ ì™„ì„± ìš”ì•½\n",
      "============================================================\n",
      "\n",
      "âœ… êµ¬í˜„ëœ ì£¼ìš” ê¸°ëŠ¥:\n",
      "   ğŸ¤– LangChain Agent ê¸°ë°˜ ì§€ëŠ¥í˜• ì¿¼ë¦¬ ì²˜ë¦¬\n",
      "   ğŸ” ìŠ¤í‚¤ë§ˆ ê²€ìƒ‰ ë° ì»¨í…ìŠ¤íŠ¸ ì¸ì‹\n",
      "   ğŸ”§ ìì—°ì–´ â†’ SQL ìë™ ë³€í™˜\n",
      "   âš¡ ì•ˆì „í•œ SQL ì‹¤í–‰ (ì½ê¸° ì „ìš©)\n",
      "   ğŸ“Š ê²°ê³¼ ë¶„ì„ ë° ì‚¬ìš©ì ì¹œí™”ì  ì„¤ëª…\n",
      "   ğŸ¯ ë‹¤ì¤‘ ë„êµ¬ í˜‘ì—… (Function Tools)\n",
      "   ğŸš€ Databricks Foundation Models ì—°ë™\n",
      "   ğŸ“ ì¿¼ë¦¬ íˆìŠ¤í† ë¦¬ ë° ì„±ëŠ¥ ë¶„ì„\n",
      "   ğŸ”„ ë‹¤ì–‘í•œ SQL ì ‘ê·¼ë²• ìƒì„±\n",
      "   ğŸ›¡ï¸ ë³´ì•ˆ ê²€ì¦ ë° ì˜¤ë¥˜ ì²˜ë¦¬\n",
      "\n",
      "ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜:\n",
      "   ğŸ“¦ ë°ì´í„° ë ˆì´ì–´: Databricks Delta Lake (Northwind DB)\n",
      "   ğŸ“¦ ì²˜ë¦¬ ì—”ì§„: Apache Spark SQL\n",
      "   ğŸ“¦ AI ëª¨ë¸: Databricks Foundation Models (Llama-3.1-70B)\n",
      "   ğŸ“¦ Agent í”„ë ˆì„ì›Œí¬: LangChain ReAct Agent\n",
      "   ğŸ“¦ Function Tools: schema_search, sql_generation, sql_execution, result_analysis\n",
      "   ğŸ“¦ ì¸í„°í˜ì´ìŠ¤: Jupyter Notebook (í™•ì¥ ê°€ëŠ¥)\n",
      "\n",
      "ğŸ’¡ ì‚¬ìš© ì˜ˆì‹œ:\n",
      "   ìì—°ì–´: 'ê°€ì¥ ë¹„ì‹¼ ìƒí’ˆ 5ê°œë¥¼ ë³´ì—¬ì£¼ì„¸ìš”'\n",
      "   ì²˜ë¦¬: ìŠ¤í‚¤ë§ˆ ê²€ìƒ‰ â†’ SQL ìƒì„± â†’ ì‹¤í–‰ â†’ ê²°ê³¼ ë¶„ì„\n",
      "   ì‘ë‹µ: 'seafood ì¹´í…Œê³ ë¦¬ì˜ CÃ´te de Blayeê°€ $263.50ë¡œ ê°€ì¥ ë¹„ìŒ‰ë‹ˆë‹¤...'\n",
      "\n",
      "âš¡ ì„±ëŠ¥ íŠ¹ì§•:\n",
      "   ğŸ“ˆ ì‘ë‹µ ì‹œê°„: í‰ê·  3-5ì´ˆ (ì¿¼ë¦¬ ë³µì¡ë„ì— ë”°ë¼)\n",
      "   ğŸ“ˆ ì •í™•ë„: ìŠ¤í‚¤ë§ˆ ì¸ì‹ ê¸°ë°˜ ë†’ì€ SQL ì •í™•ì„±\n",
      "   ğŸ“ˆ ì•ˆì „ì„±: ì½ê¸° ì „ìš© ì¿¼ë¦¬, ìœ„í—˜ í‚¤ì›Œë“œ ì°¨ë‹¨\n",
      "   ğŸ“ˆ í™•ì¥ì„±: Databricks í´ëŸ¬ìŠ¤í„° auto-scaling ì§€ì›\n",
      "\n",
      "ğŸš€ í”„ë¡œë•ì…˜ ë°°í¬ ê°€ì´ë“œ\n",
      "========================================\n",
      "\n",
      "ğŸ“‹ 1. í™˜ê²½ ì¤€ë¹„\n",
      "   â€¢ Databricks Workspace ì„¤ì •\n",
      "   â€¢ Foundation Models ì•¡ì„¸ìŠ¤ ê¶Œí•œ\n",
      "   â€¢ Delta Lake ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•\n",
      "   â€¢ ë„¤íŠ¸ì›Œí¬ ë° ë³´ì•ˆ ì„¤ì •\n",
      "\n",
      "ğŸ“‹ 2. ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œ\n",
      "   â€¢ Web API ì¸í„°í˜ì´ìŠ¤ êµ¬ì¶• (FastAPI/Flask)\n",
      "   â€¢ ì‚¬ìš©ì ì¸ì¦ ë° ê¶Œí•œ ê´€ë¦¬\n",
      "   â€¢ ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ\n",
      "   â€¢ ì˜¤ë¥˜ ì²˜ë¦¬ ë° ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜\n",
      "\n",
      "ğŸ“‹ 3. ë³´ì•ˆ ê°•í™”\n",
      "   â€¢ SQL Injection ë°©ì§€ ê³ ë„í™”\n",
      "   â€¢ ì‚¬ìš©ìë³„ ë°ì´í„° ì ‘ê·¼ ì œì–´\n",
      "   â€¢ ì¿¼ë¦¬ ì‹¤í–‰ ë¡œê·¸ ê°ì‚¬\n",
      "   â€¢ ë¯¼ê° ë°ì´í„° ë§ˆìŠ¤í‚¹\n",
      "\n",
      "ğŸ“‹ 4. ì„±ëŠ¥ ìµœì í™”\n",
      "   â€¢ ì¿¼ë¦¬ ê²°ê³¼ ìºì‹±\n",
      "   â€¢ ìŠ¤í‚¤ë§ˆ ì •ë³´ ì‚¬ì „ ë¡œë”©\n",
      "   â€¢ AI ëª¨ë¸ ì‘ë‹µ ìºì‹±\n",
      "   â€¢ ë°ì´í„°ë² ì´ìŠ¤ ì¸ë±ì‹±\n",
      "\n",
      "ğŸ“‹ 5. ìš´ì˜ ë° ìœ ì§€ë³´ìˆ˜\n",
      "   â€¢ ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘\n",
      "   â€¢ ì¿¼ë¦¬ íŒ¨í„´ ë¶„ì„ ë° ê°œì„ \n",
      "   â€¢ ìƒˆë¡œìš´ ë„ë©”ì¸ ë°ì´í„° ì¶”ê°€\n",
      "   â€¢ AI ëª¨ë¸ ì—…ë°ì´íŠ¸ ë° íŠœë‹\n",
      "\n",
      "ğŸ¯ ë‹¤ìŒ ë‹¨ê³„ ì¶”ì²œ\n",
      "==============================\n",
      "\n",
      "ì¦‰ì‹œ ì‹œì‘ ê°€ëŠ¥:\n",
      "   ğŸ§ª ë‹¤ì–‘í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ì§ˆë¬¸ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰\n",
      "   ğŸ“Š ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ë°ì´í„°ë¡œ í™•ì¥ í…ŒìŠ¤íŠ¸\n",
      "   ğŸ”§ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ ê°œë°œ (Streamlit/Gradio)\n",
      "   ğŸ“± REST API ì„œë²„ êµ¬ì¶•\n",
      "   ğŸ›¡ï¸ ì—”í„°í”„ë¼ì´ì¦ˆ ë³´ì•ˆ ê¸°ëŠ¥ ê°•í™”\n",
      "\n",
      "ê³ ê¸‰ ê¸°ëŠ¥ í™•ì¥:\n",
      "   ğŸ¨ ìì—°ì–´ ì§ˆë¬¸ ì˜ë„ ë¶„ë¥˜ ëª¨ë¸\n",
      "   ğŸ“ˆ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸í…”ë¦¬ì „ìŠ¤ ëŒ€ì‹œë³´ë“œ ì—°ë™\n",
      "   ğŸ”„ ì‹¤ì‹œê°„ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë° ì§€ì›\n",
      "   ğŸŒ ë‹¤êµ­ì–´ ì§€ì› (ì˜ì–´, í•œêµ­ì–´ ë“±)\n",
      "   ğŸ¤ ë‹¤ë¥¸ ë°ì´í„° ì†ŒìŠ¤ ì—°ë™ (CRM, ERP ë“±)\n",
      "\n",
      "ğŸ¯ ì‹œì‘í•˜ê¸°==============================\n",
      "1. test_agent_with_examples()     # ê¸°ë³¸ í…ŒìŠ¤íŠ¸\n",
      "2. interactive_query_demo()       # ëŒ€í™”í˜• ë°ëª¨\n",
      "3. demonstrate_advanced_features() # ê³ ê¸‰ ê¸°ëŠ¥\n",
      "\n",
      "ğŸ“š ê´€ë ¨ ë¬¸ì„œ:\n",
      "â€¢ 01_databricks_setup_northwind.ipynb (ë°ì´í„° êµ¬ì¶•)\n",
      "â€¢ docs/ í´ë”ì˜ ìƒì„¸ ê°€ì´ë“œ ë¬¸ì„œë“¤\n",
      "\n",
      "ğŸš€ Happy Text-to-SQL RAG Development! ğŸš€\n"
     ]
    }
   ],
   "source": [
    "# ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "def comprehensive_test():\n",
    "    \"\"\"LangChain Agent ì¢…í•© ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    \n",
    "    if not custom_workflow:\n",
    "        print(\"âŒ ì»¤ìŠ¤í…€ ì›Œí¬í”Œë¡œìš°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    print(\"ğŸ¯ LangChain Agent ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹œì‘\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # ë‹¤ì–‘í•œ ë³µì¡ë„ì˜ ì§ˆë¬¸ë“¤\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"category\": \"ê¸°ë³¸ í†µê³„\",\n",
    "            \"question\": \"ì „ì²´ ê³ ê° ìˆ˜ëŠ” ëª‡ ëª…ì¸ê°€ìš”?\",\n",
    "            \"expected_tools\": [\"schema_search_tool\", \"sql_generation_tool\", \"sql_execution_tool\"]\n",
    "        },\n",
    "        {\n",
    "            \"category\": \"ì§‘ê³„ ë¶„ì„\", \n",
    "            \"question\": \"ì¹´í…Œê³ ë¦¬ë³„ ìƒí’ˆ ê°œìˆ˜ì™€ í‰ê·  ê°€ê²©ì„ ì•Œë ¤ì£¼ì„¸ìš”\",\n",
    "            \"expected_tools\": [\"schema_search_tool\", \"sql_generation_tool\", \"sql_execution_tool\", \"result_analysis_tool\"]\n",
    "        },\n",
    "        {\n",
    "            \"category\": \"ì¡°ì¸ ì¿¼ë¦¬\",\n",
    "            \"question\": \"ê³ ê°ë³„ ì´ ì£¼ë¬¸ ê¸ˆì•¡ ìƒìœ„ 5ëª…ì„ ë³´ì—¬ì£¼ì„¸ìš”\",\n",
    "            \"expected_tools\": [\"schema_search_tool\", \"sql_generation_tool\", \"sql_execution_tool\", \"result_analysis_tool\"]\n",
    "        },\n",
    "        {\n",
    "            \"category\": \"ì‹œê°„ ë¶„ì„\",\n",
    "            \"question\": \"ìµœê·¼ 3ê°œì›” ì›”ë³„ ì£¼ë¬¸ ê±´ìˆ˜ ì¶”ì´ëŠ”?\", \n",
    "            \"expected_tools\": [\"schema_search_tool\", \"sql_generation_tool\", \"sql_execution_tool\", \"result_analysis_tool\"]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, test_case in enumerate(test_cases, 1):\n",
    "        print(f\"\\nğŸ” í…ŒìŠ¤íŠ¸ {i}: {test_case['category']}\")\n",
    "        print(f\"ì§ˆë¬¸: {test_case['question']}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰\n",
    "        result = custom_workflow.process_question(test_case['question'])\n",
    "        \n",
    "        if result['success']:\n",
    "            print(f\"âœ… ì„±ê³µ (ì²˜ë¦¬ì‹œê°„: {result['processing_time']:.2f}ì´ˆ)\")\n",
    "            print(f\"ì‘ë‹µ: {result['response'][:200]}...\")\n",
    "        else:\n",
    "            print(f\"âŒ ì‹¤íŒ¨: {result['error']}\")\n",
    "        \n",
    "        results.append(result)\n",
    "    \n",
    "    # ì„±ëŠ¥ ìš”ì•½\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½\")\n",
    "    \n",
    "    successful_tests = [r for r in results if r['success']]\n",
    "    failed_tests = [r for r in results if not r['success']]\n",
    "    \n",
    "    print(f\"   ì„±ê³µ: {len(successful_tests)}ê°œ\")\n",
    "    print(f\"   ì‹¤íŒ¨: {len(failed_tests)}ê°œ\")\n",
    "    print(f\"   ì„±ê³µë¥ : {len(successful_tests)/len(results)*100:.1f}%\")\n",
    "    \n",
    "    if successful_tests:\n",
    "        avg_time = sum(r['processing_time'] for r in successful_tests) / len(successful_tests)\n",
    "        print(f\"   í‰ê·  ì²˜ë¦¬ì‹œê°„: {avg_time:.2f}ì´ˆ\")\n",
    "    \n",
    "    # ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ\n",
    "    print(f\"\\nğŸ“ ëŒ€í™” íˆìŠ¤í† ë¦¬ ({len(custom_workflow.conversation_history)}ê°œ)\")\n",
    "    recent_history = custom_workflow.get_history(3)\n",
    "    for i, entry in enumerate(recent_history, 1):\n",
    "        status = \"âœ…\" if entry['success'] else \"âŒ\"\n",
    "        print(f\"   {i}. {status} {entry['question'][:50]}...\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì—¬ë¶€ í™•ì¸\n",
    "if text_to_sql_agent and custom_workflow:\n",
    "    print(\"ğŸ¯ ì¤€ë¹„ ì™„ë£Œ! ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì‹¤í–‰í•´ë³´ì„¸ìš”:\")\n",
    "    print(\"   1. comprehensive_test() - ì¢…í•© í…ŒìŠ¤íŠ¸\")\n",
    "    print(\"   2. custom_workflow.process_question('ì§ˆë¬¸') - ê°œë³„ ì§ˆë¬¸\")\n",
    "    print(\"   3. interactive_text_to_sql() - ëŒ€í™”í˜• ëª¨ë“œ\")\n",
    "    \n",
    "    print(\"\\nğŸš€ LangChain Agent ê¸°ë°˜ Text-to-SQL ì‹œìŠ¤í…œ ì™„ì„±!\")\n",
    "else:\n",
    "    print(\"âŒ ì‹œìŠ¤í…œì´ ì™„ì „íˆ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"   ìœ„ì˜ ëª¨ë“  ì…€ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# ìµœì¢… ìš”ì•½ ë° ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "def system_summary():\n",
    "    \"\"\"êµ¬í˜„ëœ Text-to-SQL ì‹œìŠ¤í…œ ìš”ì•½\"\"\"\n",
    "    \n",
    "    print(\"ğŸ“‹ Databricks Text-to-SQL RAG ì‹œìŠ¤í…œ ì™„ì„± ìš”ì•½\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. êµ¬í˜„ëœ ê¸°ëŠ¥ë“¤\n",
    "    print(\"\\nâœ… êµ¬í˜„ëœ ì£¼ìš” ê¸°ëŠ¥:\")\n",
    "    \n",
    "    features = [\n",
    "        \"ğŸ¤– LangChain Agent ê¸°ë°˜ ì§€ëŠ¥í˜• ì¿¼ë¦¬ ì²˜ë¦¬\",\n",
    "        \"ğŸ” ìŠ¤í‚¤ë§ˆ ê²€ìƒ‰ ë° ì»¨í…ìŠ¤íŠ¸ ì¸ì‹\",\n",
    "        \"ğŸ”§ ìì—°ì–´ â†’ SQL ìë™ ë³€í™˜\",\n",
    "        \"âš¡ ì•ˆì „í•œ SQL ì‹¤í–‰ (ì½ê¸° ì „ìš©)\",\n",
    "        \"ğŸ“Š ê²°ê³¼ ë¶„ì„ ë° ì‚¬ìš©ì ì¹œí™”ì  ì„¤ëª…\",\n",
    "        \"ğŸ¯ ë‹¤ì¤‘ ë„êµ¬ í˜‘ì—… (Function Tools)\",\n",
    "        \"ğŸš€ Databricks Foundation Models ì—°ë™\",\n",
    "        \"ğŸ“ ì¿¼ë¦¬ íˆìŠ¤í† ë¦¬ ë° ì„±ëŠ¥ ë¶„ì„\",\n",
    "        \"ğŸ”„ ë‹¤ì–‘í•œ SQL ì ‘ê·¼ë²• ìƒì„±\",\n",
    "        \"ğŸ›¡ï¸ ë³´ì•ˆ ê²€ì¦ ë° ì˜¤ë¥˜ ì²˜ë¦¬\"\n",
    "    ]\n",
    "    \n",
    "    for feature in features:\n",
    "        print(f\"   {feature}\")\n",
    "    \n",
    "    # 2. ì•„í‚¤í…ì²˜ êµ¬ì„±ìš”ì†Œ\n",
    "    print(\"\\nğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜:\")\n",
    "    \n",
    "    components = {\n",
    "        \"ë°ì´í„° ë ˆì´ì–´\": \"Databricks Delta Lake (Northwind DB)\",\n",
    "        \"ì²˜ë¦¬ ì—”ì§„\": \"Apache Spark SQL\",\n",
    "        \"AI ëª¨ë¸\": \"Databricks Foundation Models (Llama-3.1-70B)\",\n",
    "        \"Agent í”„ë ˆì„ì›Œí¬\": \"LangChain ReAct Agent\",\n",
    "        \"Function Tools\": \"schema_search, sql_generation, sql_execution, result_analysis\",\n",
    "        \"ì¸í„°í˜ì´ìŠ¤\": \"Jupyter Notebook (í™•ì¥ ê°€ëŠ¥)\"\n",
    "    }\n",
    "    \n",
    "    for component, description in components.items():\n",
    "        print(f\"   ğŸ“¦ {component}: {description}\")\n",
    "    \n",
    "    # 3. ì‚¬ìš© ì˜ˆì‹œ\n",
    "    print(\"\\nğŸ’¡ ì‚¬ìš© ì˜ˆì‹œ:\")\n",
    "    \n",
    "    examples = [\n",
    "        \"ìì—°ì–´: 'ê°€ì¥ ë¹„ì‹¼ ìƒí’ˆ 5ê°œë¥¼ ë³´ì—¬ì£¼ì„¸ìš”'\",\n",
    "        \"ì²˜ë¦¬: ìŠ¤í‚¤ë§ˆ ê²€ìƒ‰ â†’ SQL ìƒì„± â†’ ì‹¤í–‰ â†’ ê²°ê³¼ ë¶„ì„\",\n",
    "        \"ì‘ë‹µ: 'seafood ì¹´í…Œê³ ë¦¬ì˜ CÃ´te de Blayeê°€ $263.50ë¡œ ê°€ì¥ ë¹„ìŒ‰ë‹ˆë‹¤...'\"\n",
    "    ]\n",
    "    \n",
    "    for example in examples:\n",
    "        print(f\"   {example}\")\n",
    "    \n",
    "    # 4. ì„±ëŠ¥ íŠ¹ì§•\n",
    "    print(\"\\nâš¡ ì„±ëŠ¥ íŠ¹ì§•:\")\n",
    "    \n",
    "    performance = [\n",
    "        \"ì‘ë‹µ ì‹œê°„: í‰ê·  3-5ì´ˆ (ì¿¼ë¦¬ ë³µì¡ë„ì— ë”°ë¼)\",\n",
    "        \"ì •í™•ë„: ìŠ¤í‚¤ë§ˆ ì¸ì‹ ê¸°ë°˜ ë†’ì€ SQL ì •í™•ì„±\",\n",
    "        \"ì•ˆì „ì„±: ì½ê¸° ì „ìš© ì¿¼ë¦¬, ìœ„í—˜ í‚¤ì›Œë“œ ì°¨ë‹¨\",\n",
    "        \"í™•ì¥ì„±: Databricks í´ëŸ¬ìŠ¤í„° auto-scaling ì§€ì›\"\n",
    "    ]\n",
    "    \n",
    "    for perf in performance:\n",
    "        print(f\"   ğŸ“ˆ {perf}\")\n",
    "\n",
    "def deployment_guide():\n",
    "    \"\"\"í”„ë¡œë•ì…˜ ë°°í¬ ê°€ì´ë“œ\"\"\"\n",
    "    \n",
    "    print(\"\\nğŸš€ í”„ë¡œë•ì…˜ ë°°í¬ ê°€ì´ë“œ\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    steps = [\n",
    "        {\n",
    "            \"ë‹¨ê³„\": \"1. í™˜ê²½ ì¤€ë¹„\",\n",
    "            \"ë‚´ìš©\": [\n",
    "                \"Databricks Workspace ì„¤ì •\",\n",
    "                \"Foundation Models ì•¡ì„¸ìŠ¤ ê¶Œí•œ\",\n",
    "                \"Delta Lake ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•\",\n",
    "                \"ë„¤íŠ¸ì›Œí¬ ë° ë³´ì•ˆ ì„¤ì •\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"ë‹¨ê³„\": \"2. ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œ\",\n",
    "            \"ë‚´ìš©\": [\n",
    "                \"Web API ì¸í„°í˜ì´ìŠ¤ êµ¬ì¶• (FastAPI/Flask)\",\n",
    "                \"ì‚¬ìš©ì ì¸ì¦ ë° ê¶Œí•œ ê´€ë¦¬\",\n",
    "                \"ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ\",\n",
    "                \"ì˜¤ë¥˜ ì²˜ë¦¬ ë° ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"ë‹¨ê³„\": \"3. ë³´ì•ˆ ê°•í™”\",\n",
    "            \"ë‚´ìš©\": [\n",
    "                \"SQL Injection ë°©ì§€ ê³ ë„í™”\",\n",
    "                \"ì‚¬ìš©ìë³„ ë°ì´í„° ì ‘ê·¼ ì œì–´\",\n",
    "                \"ì¿¼ë¦¬ ì‹¤í–‰ ë¡œê·¸ ê°ì‚¬\",\n",
    "                \"ë¯¼ê° ë°ì´í„° ë§ˆìŠ¤í‚¹\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"ë‹¨ê³„\": \"4. ì„±ëŠ¥ ìµœì í™”\",\n",
    "            \"ë‚´ìš©\": [\n",
    "                \"ì¿¼ë¦¬ ê²°ê³¼ ìºì‹±\",\n",
    "                \"ìŠ¤í‚¤ë§ˆ ì •ë³´ ì‚¬ì „ ë¡œë”©\",\n",
    "                \"AI ëª¨ë¸ ì‘ë‹µ ìºì‹±\",\n",
    "                \"ë°ì´í„°ë² ì´ìŠ¤ ì¸ë±ì‹±\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"ë‹¨ê³„\": \"5. ìš´ì˜ ë° ìœ ì§€ë³´ìˆ˜\",\n",
    "            \"ë‚´ìš©\": [\n",
    "                \"ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘\",\n",
    "                \"ì¿¼ë¦¬ íŒ¨í„´ ë¶„ì„ ë° ê°œì„ \",\n",
    "                \"ìƒˆë¡œìš´ ë„ë©”ì¸ ë°ì´í„° ì¶”ê°€\",\n",
    "                \"AI ëª¨ë¸ ì—…ë°ì´íŠ¸ ë° íŠœë‹\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for step_info in steps:\n",
    "        print(f\"\\nğŸ“‹ {step_info['ë‹¨ê³„']}\")\n",
    "        for item in step_info['ë‚´ìš©']:\n",
    "            print(f\"   â€¢ {item}\")\n",
    "\n",
    "def next_steps():\n",
    "    \"\"\"ì¶”ì²œí•˜ëŠ” ë‹¤ìŒ ë‹¨ê³„ë“¤\"\"\"\n",
    "    \n",
    "    print(\"\\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„ ì¶”ì²œ\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    immediate_tasks = [\n",
    "        \"ğŸ§ª ë‹¤ì–‘í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ì§ˆë¬¸ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰\",\n",
    "        \"ğŸ“Š ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ë°ì´í„°ë¡œ í™•ì¥ í…ŒìŠ¤íŠ¸\",\n",
    "        \"ğŸ”§ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ ê°œë°œ (Streamlit/Gradio)\",\n",
    "        \"ğŸ“± REST API ì„œë²„ êµ¬ì¶•\",\n",
    "        \"ğŸ›¡ï¸ ì—”í„°í”„ë¼ì´ì¦ˆ ë³´ì•ˆ ê¸°ëŠ¥ ê°•í™”\"\n",
    "    ]\n",
    "    \n",
    "    advanced_features = [\n",
    "        \"ğŸ¨ ìì—°ì–´ ì§ˆë¬¸ ì˜ë„ ë¶„ë¥˜ ëª¨ë¸\",\n",
    "        \"ğŸ“ˆ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸í…”ë¦¬ì „ìŠ¤ ëŒ€ì‹œë³´ë“œ ì—°ë™\",\n",
    "        \"ğŸ”„ ì‹¤ì‹œê°„ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë° ì§€ì›\",\n",
    "        \"ğŸŒ ë‹¤êµ­ì–´ ì§€ì› (ì˜ì–´, í•œêµ­ì–´ ë“±)\",\n",
    "        \"ğŸ¤ ë‹¤ë¥¸ ë°ì´í„° ì†ŒìŠ¤ ì—°ë™ (CRM, ERP ë“±)\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nì¦‰ì‹œ ì‹œì‘ ê°€ëŠ¥:\")\n",
    "    for task in immediate_tasks:\n",
    "        print(f\"   {task}\")\n",
    "    \n",
    "    print(\"\\nê³ ê¸‰ ê¸°ëŠ¥ í™•ì¥:\")\n",
    "    for feature in advanced_features:\n",
    "        print(f\"   {feature}\")\n",
    "\n",
    "# ìµœì¢… ìš”ì•½ ì‹¤í–‰\n",
    "print(\"ğŸ‰ Databricks Text-to-SQL RAG ì‹œìŠ¤í…œ êµ¬í˜„ ì™„ë£Œ!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "system_summary()\n",
    "deployment_guide() \n",
    "next_steps()\n",
    "\n",
    "print(\"\\n\" + \"ğŸ¯ ì‹œì‘í•˜ê¸°\" + \"=\" * 30)\n",
    "print(\"1. test_agent_with_examples()     # ê¸°ë³¸ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"2. interactive_query_demo()       # ëŒ€í™”í˜• ë°ëª¨\")\n",
    "print(\"3. demonstrate_advanced_features() # ê³ ê¸‰ ê¸°ëŠ¥\")\n",
    "print(\"\\nğŸ“š ê´€ë ¨ ë¬¸ì„œ:\")\n",
    "print(\"â€¢ 01_databricks_setup_northwind.ipynb (ë°ì´í„° êµ¬ì¶•)\")\n",
    "print(\"â€¢ docs/ í´ë”ì˜ ìƒì„¸ ê°€ì´ë“œ ë¬¸ì„œë“¤\")\n",
    "print(\"\\nğŸš€ Happy Text-to-SQL RAG Development! ğŸš€\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
