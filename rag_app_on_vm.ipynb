{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ed57506",
   "metadata": {},
   "source": [
    "# Databricks RAG Application \n",
    "## VS Code + Databricks Extension í™˜ê²½ì—ì„œ ì‹¤í–‰í•˜ëŠ” RAG ì‹œìŠ¤í…œ\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ **VS Code Databricks Extension**ì„ ì‚¬ìš©í•˜ì—¬ Databricksì˜ Vector Searchì™€ LLMì„ í™œìš©í•œ ì™„ì „í•œ RAG(Retrieval-Augmented Generation) ì• í”Œë¦¬ì¼€ì´ì…˜ì…ë‹ˆë‹¤.\n",
    "\n",
    "## ğŸ¯ ëª©í‘œ\n",
    "- PDF ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³  ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥\n",
    "- Databricks Vector Searchë¥¼ ì‚¬ìš©í•œ ë¬¸ì„œ ê²€ìƒ‰\n",
    "- Databricks LLMì„ ì‚¬ìš©í•œ ì§ˆë¬¸ ë‹µë³€\n",
    "- Text-to-SQL ê¸°ëŠ¥ìœ¼ë¡œ ìì—°ì–´ â†’ SQL ë³€í™˜\n",
    "\n",
    "## ğŸš€ VS Code + Databricks Extension ì„¤ì •\n",
    "\n",
    "### 1ë‹¨ê³„: Extension ì„¤ì¹˜\n",
    "1. VS Code â†’ Extensions (`Ctrl+Shift+X`)\n",
    "2. \"Databricks\" ê²€ìƒ‰ ë° ì„¤ì¹˜ (Microsoft ê³µì‹)\n",
    "\n",
    "### 2ë‹¨ê³„: Workspace ì—°ê²°\n",
    "1. `Ctrl+Shift+P` â†’ \"Databricks: Configure Workspace\"\n",
    "2. Databricks URL: `https://your-workspace.cloud.databricks.com`\n",
    "3. Personal Access Token ì…ë ¥\n",
    "\n",
    "### 3ë‹¨ê³„: í´ëŸ¬ìŠ¤í„° ì—°ê²°\n",
    "1. VS Code ì¢Œì¸¡ Databricks íŒ¨ë„ì—ì„œ í´ëŸ¬ìŠ¤í„° ì„ íƒ\n",
    "2. \"Connect\" ë²„íŠ¼ í´ë¦­\n",
    "\n",
    "### 4ë‹¨ê³„: ì´ ë…¸íŠ¸ë¶ ì‹¤í–‰\n",
    "- ê° ì…€ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•˜ì„¸ìš”\n",
    "- í™˜ê²½ì´ ìë™ìœ¼ë¡œ ê°ì§€ë©ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6c2c74",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "\n",
    "ë¨¼ì € í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„í¬íŠ¸í•˜ê³  ì‹¤í–‰ í™˜ê²½ì„ ê°ì§€í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f735e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ ===\n",
      "=== í™˜ê²½ ê°ì§€ ì‹œì‘ ===\n",
      "ğŸš€ VS Code Databricks Extension í™˜ê²½ ê°ì§€ë¨!\n",
      "ğŸ¯ ê°ì§€ëœ í™˜ê²½: vscode_databricks\n",
      "âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ!\n",
      "ğŸš€ VS Code Databricks Extension í™˜ê²½ ê°ì§€ë¨!\n",
      "ğŸ¯ ê°ì§€ëœ í™˜ê²½: vscode_databricks\n",
      "âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "from langchain_community.chat_models import ChatDatabricks\n",
    "from langchain_community.vectorstores import DatabricksVectorSearch\n",
    "from langchain_community.embeddings import DatabricksEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from databricks.vector_search.client import VectorSearchClient\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(\"=== ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ ===\")\n",
    "\n",
    "# í™˜ê²½ ê°ì§€ ë¡œì§\n",
    "is_databricks_native = \"DATABRICKS_RUNTIME_VERSION\" in os.environ\n",
    "is_vscode_databricks = False\n",
    "spark = None\n",
    "\n",
    "print(\"=== í™˜ê²½ ê°ì§€ ì‹œì‘ ===\")\n",
    "\n",
    "if is_databricks_native:\n",
    "    print(\"ğŸ”¥ Native Databricks í™˜ê²½ ê°ì§€ë¨\")\n",
    "    environment_type = \"databricks_native\"\n",
    "else:\n",
    "    try:\n",
    "        from pyspark.sql import SparkSession\n",
    "        spark = SparkSession.builder.appName(\"RAG-Application\").getOrCreate()\n",
    "        \n",
    "        # Databricks ì—°ê²° í…ŒìŠ¤íŠ¸\n",
    "        try:\n",
    "            catalog_result = spark.sql(\"SELECT current_catalog()\").collect()\n",
    "            if catalog_result:\n",
    "                is_vscode_databricks = True\n",
    "                environment_type = \"vscode_databricks\"\n",
    "                print(\"ğŸš€ VS Code Databricks Extension í™˜ê²½ ê°ì§€ë¨!\")\n",
    "            else:\n",
    "                raise ValueError(\"Catalog query failed\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Databricks ì—°ê²° ì‹¤íŒ¨: {str(e)[:100]}...\")\n",
    "            spark = None\n",
    "            environment_type = \"local\"\n",
    "    except Exception as e:\n",
    "        print(f\"ğŸ’» ë¡œì»¬ í™˜ê²½ ê°ì§€ë¨: {str(e)[:50]}...\")\n",
    "        spark = None\n",
    "        environment_type = \"local\"\n",
    "\n",
    "print(f\"ğŸ¯ ê°ì§€ëœ í™˜ê²½: {environment_type}\")\n",
    "\n",
    "# í™˜ê²½ ê²€ì¦\n",
    "if environment_type == \"local\":\n",
    "    print(\"âŒ ì´ ë…¸íŠ¸ë¶ì€ Databricks í™˜ê²½ì—ì„œë§Œ ì‹¤í–‰ë©ë‹ˆë‹¤.\")\n",
    "    print(\"ğŸ’¡ VS Code Databricks Extensionì„ ì„¤ì¹˜í•˜ê³  í´ëŸ¬ìŠ¤í„°ì— ì—°ê²°í•˜ì„¸ìš”.\")\n",
    "    raise EnvironmentError(\"Databricks í™˜ê²½ì´ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "print(\"âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440d4ad5",
   "metadata": {},
   "source": [
    "## 2. Databricks í™˜ê²½ ì •ë³´ í™•ì¸\n",
    "\n",
    "í˜„ì¬ ì—°ê²°ëœ Databricks í™˜ê²½ì˜ ì¹´íƒˆë¡œê·¸, ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "761a0348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== í™˜ê²½ ê°ì§€ ì‹œì‘ ===\n",
      "ğŸš€ VS Code Databricks Extension í™˜ê²½ ê°ì§€ë¨!\n",
      "   âœ… ë¡œì»¬ VS Code â†’ Databricks í´ëŸ¬ìŠ¤í„° ì—°ê²° í™œì„±í™”\n",
      "\n",
      "ğŸ¯ ê°ì§€ëœ í™˜ê²½: vscode_databricks\n",
      "âœ… Databricks ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥\n",
      "ğŸ“Š Databricks í™˜ê²½ ì •ë³´ ìˆ˜ì§‘ ì¤‘...\n",
      "ğŸš€ VS Code Databricks Extension í™˜ê²½ ê°ì§€ë¨!\n",
      "   âœ… ë¡œì»¬ VS Code â†’ Databricks í´ëŸ¬ìŠ¤í„° ì—°ê²° í™œì„±í™”\n",
      "\n",
      "ğŸ¯ ê°ì§€ëœ í™˜ê²½: vscode_databricks\n",
      "âœ… Databricks ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥\n",
      "ğŸ“Š Databricks í™˜ê²½ ì •ë³´ ìˆ˜ì§‘ ì¤‘...\n",
      "âœ… í˜„ì¬ ì¹´íƒˆë¡œê·¸: workspace\n",
      "âœ… í˜„ì¬ ìŠ¤í‚¤ë§ˆ: default\n",
      "ğŸ·ï¸ Unity Catalog í™˜ê²½\n",
      "ğŸ“‹ Vector Search ì¸ë±ìŠ¤: workspace.default.rag_docs_index\n",
      "ğŸ“‹ ì†ŒìŠ¤ í…Œì´ë¸”: workspace.default.rag_documents\n",
      "âœ… í™˜ê²½ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ!\n",
      "\n",
      "ğŸ”§ ê¸°ëŠ¥ ê°€ìš©ì„±:\n",
      "   âœ… Databricks Vector Search\n",
      "   âœ… Databricks LLM\n",
      "   âœ… Spark SQL\n",
      "   âœ… Unity Catalog\n",
      "\n",
      "âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ! í˜„ì¬ í™˜ê²½: vscode_databricks\n",
      "\n",
      "ğŸ”§ ê¸°ëŠ¥ ê°€ìš©ì„± ë§¤íŠ¸ë¦­ìŠ¤:\n",
      "   âœ… Databricks Vector Search\n",
      "   âœ… Databricks LLM\n",
      "   âœ… Spark SQL\n",
      "   âœ… Unity Catalog\n",
      "\n",
      "âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ! í˜„ì¬ í™˜ê²½: vscode_databricks\n",
      "======================================================================\n",
      "âœ… í˜„ì¬ ì¹´íƒˆë¡œê·¸: workspace\n",
      "âœ… í˜„ì¬ ìŠ¤í‚¤ë§ˆ: default\n",
      "ğŸ·ï¸ Unity Catalog í™˜ê²½\n",
      "ğŸ“‹ Vector Search ì¸ë±ìŠ¤: workspace.default.rag_docs_index\n",
      "ğŸ“‹ ì†ŒìŠ¤ í…Œì´ë¸”: workspace.default.rag_documents\n",
      "âœ… í™˜ê²½ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ!\n",
      "\n",
      "ğŸ”§ ê¸°ëŠ¥ ê°€ìš©ì„±:\n",
      "   âœ… Databricks Vector Search\n",
      "   âœ… Databricks LLM\n",
      "   âœ… Spark SQL\n",
      "   âœ… Unity Catalog\n",
      "\n",
      "âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ! í˜„ì¬ í™˜ê²½: vscode_databricks\n",
      "\n",
      "ğŸ”§ ê¸°ëŠ¥ ê°€ìš©ì„± ë§¤íŠ¸ë¦­ìŠ¤:\n",
      "   âœ… Databricks Vector Search\n",
      "   âœ… Databricks LLM\n",
      "   âœ… Spark SQL\n",
      "   âœ… Unity Catalog\n",
      "\n",
      "âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ! í˜„ì¬ í™˜ê²½: vscode_databricks\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”§ ê³ ê¸‰ í™˜ê²½ ê°ì§€ ë° ì„¤ì • - VS Code Databricks Extension ì§€ì›\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# í™˜ê²½ ê°ì§€ ë³€ìˆ˜ë“¤\n",
    "is_databricks_native = \"DATABRICKS_RUNTIME_VERSION\" in os.environ\n",
    "is_vscode_databricks = False\n",
    "\n",
    "print(\"=== í™˜ê²½ ê°ì§€ ì‹œì‘ ===\")\n",
    "\n",
    "# 1. Native Databricks í™˜ê²½ í™•ì¸\n",
    "if is_databricks_native:\n",
    "    print(\"ğŸ”¥ Native Databricks í™˜ê²½ ê°ì§€ë¨\")\n",
    "    environment_type = \"databricks_native\"\n",
    "    \n",
    "# 2. VS Code Databricks Extension í™˜ê²½ í™•ì¸\n",
    "else:\n",
    "    try:\n",
    "        # Spark ì„¸ì…˜ ìƒì„± ì‹œë„ë¡œ VS Code Extension í™•ì¸\n",
    "        from pyspark.sql import SparkSession\n",
    "        spark = SparkSession.builder.appName(\"VSCode-Databricks-RAG\").getOrCreate()\n",
    "        \n",
    "        # Databricks íŠ¹ì • ëª…ë ¹ì–´ í…ŒìŠ¤íŠ¸\n",
    "        try:\n",
    "            # Databricks í™˜ê²½ì—ì„œë§Œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´ í…ŒìŠ¤íŠ¸\n",
    "            catalog_result = spark.sql(\"SELECT current_catalog()\").collect()\n",
    "            if catalog_result:\n",
    "                is_vscode_databricks = True\n",
    "                environment_type = \"vscode_databricks\"\n",
    "                print(\"ğŸš€ VS Code Databricks Extension í™˜ê²½ ê°ì§€ë¨!\")\n",
    "                print(\"   âœ… ë¡œì»¬ VS Code â†’ Databricks í´ëŸ¬ìŠ¤í„° ì—°ê²° í™œì„±í™”\")\n",
    "        except:\n",
    "            # SparkëŠ” ìˆì§€ë§Œ Databricks ê¸°ëŠ¥ì´ ì—†ëŠ” ê²½ìš°\n",
    "            print(\"âš ï¸ Spark ì„¸ì…˜ì€ ìˆì§€ë§Œ Databricks ì—°ê²° ì—†ìŒ\")\n",
    "            spark = None\n",
    "            \n",
    "    except Exception as e:\n",
    "        # Spark ìì²´ê°€ ì—†ëŠ” ì™„ì „ ë¡œì»¬ í™˜ê²½\n",
    "        print(\"ğŸ’» ë¡œì»¬ ê°œë°œ í™˜ê²½ ê°ì§€ë¨\")\n",
    "        spark = None\n",
    "        environment_type = \"local_dev\"\n",
    "        print(f\"   Spark ì—°ê²° ì‹¤íŒ¨: {str(e)[:100]}...\")\n",
    "\n",
    "# 3. í™˜ê²½ë³„ ì„¤ì • ë° ê¸°ëŠ¥ í™•ì¸\n",
    "print(f\"\\nğŸ¯ ê°ì§€ëœ í™˜ê²½: {environment_type}\")\n",
    "\n",
    "if is_databricks_native or is_vscode_databricks:\n",
    "    print(\"âœ… Databricks ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥\")\n",
    "    \n",
    "    # Databricks í™˜ê²½ ì •ë³´ ìˆ˜ì§‘\n",
    "    print(\"ğŸ“Š Databricks í™˜ê²½ ì •ë³´ ìˆ˜ì§‘ ì¤‘...\")\n",
    "\n",
    "    try:\n",
    "        # í˜„ì¬ ì¹´íƒˆë¡œê·¸ì™€ ìŠ¤í‚¤ë§ˆ í™•ì¸\n",
    "        current_catalog = spark.sql(\"SELECT current_catalog()\").collect()[0][0]\n",
    "        current_schema = spark.sql(\"SELECT current_schema()\").collect()[0][0]\n",
    "        \n",
    "        print(f\"âœ… í˜„ì¬ ì¹´íƒˆë¡œê·¸: {current_catalog}\")\n",
    "        print(f\"âœ… í˜„ì¬ ìŠ¤í‚¤ë§ˆ: {current_schema}\")\n",
    "        \n",
    "        # Unity Catalog í™˜ê²½ íŒë‹¨\n",
    "        if current_catalog and current_catalog.lower() not in ['none', 'null', 'hive_metastore']:\n",
    "            catalog_prefix = f\"{current_catalog}.{current_schema}\"\n",
    "            print(\"ğŸ·ï¸ Unity Catalog í™˜ê²½\")\n",
    "        else:\n",
    "            catalog_prefix = current_schema\n",
    "            print(\"ğŸ·ï¸ Hive ë©”íƒ€ìŠ¤í† ì–´ í™˜ê²½\")\n",
    "        \n",
    "        # í…Œì´ë¸” ë° ì¸ë±ìŠ¤ ì´ë¦„ ì„¤ì •\n",
    "        index_name = f\"{catalog_prefix}.rag_docs_index\"\n",
    "        source_table_name = f\"{catalog_prefix}.rag_documents\"\n",
    "        \n",
    "        print(f\"ğŸ“‹ Vector Search ì¸ë±ìŠ¤: {index_name}\")\n",
    "        print(f\"ğŸ“‹ ì†ŒìŠ¤ í…Œì´ë¸”: {source_table_name}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ í™˜ê²½ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}\")\n",
    "        # ê¸°ë³¸ê°’ ì„¤ì •\n",
    "        current_catalog = None\n",
    "        current_schema = \"default\"\n",
    "        catalog_prefix = current_schema\n",
    "        index_name = f\"{catalog_prefix}.rag_docs_index\"\n",
    "        source_table_name = f\"{catalog_prefix}.rag_documents\"\n",
    "\n",
    "    print(\"âœ… í™˜ê²½ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ!\")\n",
    "\n",
    "    # ê¸°ëŠ¥ ê°€ìš©ì„± í™•ì¸\n",
    "    print(f\"\\nğŸ”§ ê¸°ëŠ¥ ê°€ìš©ì„±:\")\n",
    "    features = {\n",
    "        \"Databricks Vector Search\": is_databricks_native or is_vscode_databricks,\n",
    "        \"Databricks LLM\": is_databricks_native or is_vscode_databricks,\n",
    "        \"Spark SQL\": bool(spark),\n",
    "        \"Unity Catalog\": is_databricks_native or is_vscode_databricks,\n",
    "    }\n",
    "\n",
    "    for feature, available in features.items():\n",
    "        status = \"âœ…\" if available else \"âŒ\"\n",
    "        print(f\"   {status} {feature}\")\n",
    "\n",
    "    print(f\"\\nâœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ! í˜„ì¬ í™˜ê²½: {environment_type}\")\n",
    "else:\n",
    "    print(\"ğŸ’¡ ë¡œì»¬ ê°œë°œ í™˜ê²½ - ëŒ€ì•ˆ ì˜µì…˜ ì‚¬ìš©\")\n",
    "    current_catalog = None\n",
    "    current_schema = \"default\"\n",
    "    spark = None\n",
    "\n",
    "# 4. í™˜ê²½ë³„ ê¸°ëŠ¥ ê°€ìš©ì„± ë§¤íŠ¸ë¦­ìŠ¤\n",
    "print(f\"\\nğŸ”§ ê¸°ëŠ¥ ê°€ìš©ì„± ë§¤íŠ¸ë¦­ìŠ¤:\")\n",
    "features = {\n",
    "    \"Databricks Vector Search\": is_databricks_native or is_vscode_databricks,\n",
    "    \"Databricks LLM\": is_databricks_native or is_vscode_databricks,\n",
    "    \"Spark SQL\": bool(spark),\n",
    "    \"Unity Catalog\": is_databricks_native or is_vscode_databricks,\n",
    "}\n",
    "\n",
    "for feature, available in features.items():\n",
    "    status = \"âœ…\" if available else \"âŒ\"\n",
    "    print(f\"   {status} {feature}\")\n",
    "\n",
    "print(f\"\\nâœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ! í˜„ì¬ í™˜ê²½: {environment_type}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e04ce4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Databricks Vector Search ì„¤ì • ì¤‘...\n",
      "âœ… Vector Search í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì„±ê³µ\n",
      "âœ… ê¸°ì¡´ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©: rag_endpoint\n",
      "âœ… Vector Search ê¸°ë³¸ ì„¤ì • ì™„ë£Œ!\n",
      "   ì—”ë“œí¬ì¸íŠ¸: rag_endpoint\n",
      "   ì¸ë±ìŠ¤ ì´ë¦„: workspace.default.rag_docs_index\n",
      "   ì†ŒìŠ¤ í…Œì´ë¸”: workspace.default.rag_documents\n",
      "ğŸ·ï¸ Unity Catalog í™˜ê²½ ê°ì§€\n",
      "ğŸ“Š ì¸ë±ìŠ¤ ì´ë¦„: workspace.default.rag_docs_index_vscode\n",
      "ğŸ“Š ì†ŒìŠ¤ í…Œì´ë¸” ì´ë¦„: workspace.default.rag_documents_vscode\n",
      "âœ… ê¸°ì¡´ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©: rag_endpoint\n",
      "âœ… Vector Search ê¸°ë³¸ ì„¤ì • ì™„ë£Œ!\n",
      "   ì—”ë“œí¬ì¸íŠ¸: rag_endpoint\n",
      "   ì¸ë±ìŠ¤ ì´ë¦„: workspace.default.rag_docs_index\n",
      "   ì†ŒìŠ¤ í…Œì´ë¸”: workspace.default.rag_documents\n",
      "ğŸ·ï¸ Unity Catalog í™˜ê²½ ê°ì§€\n",
      "ğŸ“Š ì¸ë±ìŠ¤ ì´ë¦„: workspace.default.rag_docs_index_vscode\n",
      "ğŸ“Š ì†ŒìŠ¤ í…Œì´ë¸” ì´ë¦„: workspace.default.rag_documents_vscode\n",
      "âœ… ì†ŒìŠ¤ í…Œì´ë¸” ì¡´ì¬ í™•ì¸: workspace.default.rag_documents_vscode\n",
      "âœ… ì†ŒìŠ¤ í…Œì´ë¸” ì¡´ì¬ í™•ì¸: workspace.default.rag_documents_vscode\n",
      "âœ… ê¸°ì¡´ ì¸ë±ìŠ¤ ë°œê²¬: workspace.default.rag_docs_index_vscode\n",
      "âœ… ê¸°ì¡´ ì¸ë±ìŠ¤ ë°œê²¬: workspace.default.rag_docs_index_vscode\n",
      "ğŸ“Š ì¸ë±ìŠ¤ ìƒíƒœ: ì¤€ë¹„ë¨\n",
      "\n",
      "ğŸ“‹ Vector Search ìƒíƒœ ìš”ì•½:\n",
      "   âœ… í´ë¼ì´ì–¸íŠ¸: ì—°ê²°ë¨\n",
      "   âœ… ì—”ë“œí¬ì¸íŠ¸: rag_endpoint\n",
      "   âœ… ì†ŒìŠ¤ í…Œì´ë¸”: workspace.default.rag_documents_vscode\n",
      "   âœ… ë²¡í„° ì¸ë±ìŠ¤: workspace.default.rag_docs_index_vscode\n",
      "\n",
      "ğŸ¯ ë‹¤ìŒ ë‹¨ê³„: RAG ì‹œìŠ¤í…œ êµ¬ì„±\n",
      "   â†’ Vector Store ìƒì„± ì…€ë¡œ ì§„í–‰í•˜ì„¸ìš”\n",
      "\n",
      "ğŸ”§ Vector Search ì„¤ì • ì™„ë£Œ!\n",
      "   í™˜ê²½: Databricks\n",
      "   Vector Search ì‚¬ìš© ê°€ëŠ¥: âœ…\n",
      "\n",
      "ğŸš€ VS Code Extension í™˜ê²½ íŠ¹ë³„ ê¸°ëŠ¥:\n",
      "   âœ… ì‹¤ì‹œê°„ ì›Œí¬í”Œë¡œìš° ìƒíƒœ í™•ì¸\n",
      "   âœ… ì§€ëŠ¥ì  ì˜¤ë¥˜ í•´ê²° ê°€ì´ë“œ\n",
      "   âœ… ë‹¨ê³„ë³„ ì§„í–‰ ìƒí™© ì¶”ì \n",
      "ğŸ“Š ì¸ë±ìŠ¤ ìƒíƒœ: ì¤€ë¹„ë¨\n",
      "\n",
      "ğŸ“‹ Vector Search ìƒíƒœ ìš”ì•½:\n",
      "   âœ… í´ë¼ì´ì–¸íŠ¸: ì—°ê²°ë¨\n",
      "   âœ… ì—”ë“œí¬ì¸íŠ¸: rag_endpoint\n",
      "   âœ… ì†ŒìŠ¤ í…Œì´ë¸”: workspace.default.rag_documents_vscode\n",
      "   âœ… ë²¡í„° ì¸ë±ìŠ¤: workspace.default.rag_docs_index_vscode\n",
      "\n",
      "ğŸ¯ ë‹¤ìŒ ë‹¨ê³„: RAG ì‹œìŠ¤í…œ êµ¬ì„±\n",
      "   â†’ Vector Store ìƒì„± ì…€ë¡œ ì§„í–‰í•˜ì„¸ìš”\n",
      "\n",
      "ğŸ”§ Vector Search ì„¤ì • ì™„ë£Œ!\n",
      "   í™˜ê²½: Databricks\n",
      "   Vector Search ì‚¬ìš© ê°€ëŠ¥: âœ…\n",
      "\n",
      "ğŸš€ VS Code Extension í™˜ê²½ íŠ¹ë³„ ê¸°ëŠ¥:\n",
      "   âœ… ì‹¤ì‹œê°„ ì›Œí¬í”Œë¡œìš° ìƒíƒœ í™•ì¸\n",
      "   âœ… ì§€ëŠ¥ì  ì˜¤ë¥˜ í•´ê²° ê°€ì´ë“œ\n",
      "   âœ… ë‹¨ê³„ë³„ ì§„í–‰ ìƒí™© ì¶”ì \n"
     ]
    }
   ],
   "source": [
    "# Databricks Vector Search í´ë¼ì´ì–¸íŠ¸ ì„¤ì •\n",
    "print(\"ğŸš€ Databricks Vector Search ì„¤ì • ì¤‘...\")\n",
    "\n",
    "# Vector Search í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "try:\n",
    "    vsc = VectorSearchClient(disable_notice=True)\n",
    "    print(\"âœ… Vector Search í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì„±ê³µ\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Vector Search í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì‹¤íŒ¨: {e}\")\n",
    "    raise\n",
    "\n",
    "# ë²¡í„° ê²€ìƒ‰ ì—”ë“œí¬ì¸íŠ¸ ì„¤ì •\n",
    "endpoint_name = \"rag_endpoint\"\n",
    "\n",
    "try:\n",
    "    # ê¸°ì¡´ ì—”ë“œí¬ì¸íŠ¸ í™•ì¸\n",
    "    endpoint = vsc.get_endpoint(endpoint_name)\n",
    "    print(f\"âœ… ê¸°ì¡´ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©: {endpoint_name}\")\n",
    "except Exception:\n",
    "    try:\n",
    "        # ìƒˆ ì—”ë“œí¬ì¸íŠ¸ ìƒì„±\n",
    "        print(f\"ğŸ”§ ìƒˆ ì—”ë“œí¬ì¸íŠ¸ ìƒì„±: {endpoint_name}\")\n",
    "        vsc.create_endpoint(\n",
    "            name=endpoint_name,\n",
    "            endpoint_type=\"STANDARD\"\n",
    "        )\n",
    "        print(f\"âœ… ì—”ë“œí¬ì¸íŠ¸ ìƒì„± ì™„ë£Œ: {endpoint_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ì—”ë“œí¬ì¸íŠ¸ ìƒì„±/ì¡°íšŒ ì‹¤íŒ¨: {e}\")\n",
    "        print(\"ê¸°ì¡´ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.\")\n",
    "\n",
    "print(f\"âœ… Vector Search ê¸°ë³¸ ì„¤ì • ì™„ë£Œ!\")\n",
    "print(f\"   ì—”ë“œí¬ì¸íŠ¸: {endpoint_name}\")\n",
    "print(f\"   ì¸ë±ìŠ¤ ì´ë¦„: {index_name}\")\n",
    "print(f\"   ì†ŒìŠ¤ í…Œì´ë¸”: {source_table_name}\")\n",
    "\n",
    "# í™˜ê²½ì— ë”°ë¥¸ í…Œì´ë¸” ë° ì¸ë±ìŠ¤ ì´ë¦„ ë™ì  ì„¤ì •\n",
    "if current_catalog and current_catalog.lower() not in ['none', 'null']:\n",
    "    # Unity Catalog í™˜ê²½\n",
    "    catalog_prefix = f\"{current_catalog}.{current_schema}\"\n",
    "    index_name = f\"{catalog_prefix}.rag_docs_index_vscode\"\n",
    "    source_table_name = f\"{catalog_prefix}.rag_documents_vscode\"\n",
    "    print(f\"ğŸ·ï¸ Unity Catalog í™˜ê²½ ê°ì§€\")\n",
    "else:\n",
    "    # Hive ë©”íƒ€ìŠ¤í† ì–´ í™˜ê²½\n",
    "    catalog_prefix = current_schema\n",
    "    index_name = f\"{catalog_prefix}.rag_docs_index_vscode\"\n",
    "    source_table_name = f\"{catalog_prefix}.rag_documents_vscode\"\n",
    "    print(f\"ğŸ·ï¸ Hive ë©”íƒ€ìŠ¤í† ì–´ í™˜ê²½ ê°ì§€\")\n",
    "\n",
    "print(f\"ğŸ“Š ì¸ë±ìŠ¤ ì´ë¦„: {index_name}\")\n",
    "print(f\"ğŸ“Š ì†ŒìŠ¤ í…Œì´ë¸” ì´ë¦„: {source_table_name}\")\n",
    "\n",
    "# ğŸ” ì†ŒìŠ¤ í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸\n",
    "table_exists = False\n",
    "try:\n",
    "    table_info = spark.sql(f\"DESCRIBE TABLE {source_table_name}\")\n",
    "    table_exists = True\n",
    "    print(f\"âœ… ì†ŒìŠ¤ í…Œì´ë¸” ì¡´ì¬ í™•ì¸: {source_table_name}\")\n",
    "except Exception:\n",
    "    print(f\"âš ï¸ ì†ŒìŠ¤ í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {source_table_name}\")\n",
    "    print(\"   ë¨¼ì € PDF ì²˜ë¦¬ ì…€ì„ ì‹¤í–‰í•˜ì—¬ í…Œì´ë¸”ì„ ìƒì„±í•´ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# ê¸°ì¡´ ì¸ë±ìŠ¤ í™•ì¸\n",
    "index = None\n",
    "try:\n",
    "    index = vsc.get_index(endpoint_name=endpoint_name, index_name=index_name)\n",
    "    print(f\"âœ… ê¸°ì¡´ ì¸ë±ìŠ¤ ë°œê²¬: {index_name}\")\n",
    "\n",
    "    # ì¸ë±ìŠ¤ ìƒíƒœ í™•ì¸\n",
    "    index_status = index.describe()\n",
    "    status = index_status.get(\"status\", {})\n",
    "    is_ready = status.get(\"ready\", False)\n",
    "\n",
    "    print(f\"ğŸ“Š ì¸ë±ìŠ¤ ìƒíƒœ: {'ì¤€ë¹„ë¨' if is_ready else 'ì¤€ë¹„ ì¤‘'}\")\n",
    "\n",
    "    if not is_ready:\n",
    "        print(\"â³ ì¸ë±ìŠ¤ê°€ ì•„ì§ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\")\n",
    "\n",
    "except Exception:\n",
    "    print(f\"âŒ ê¸°ì¡´ ì¸ë±ìŠ¤ ì—†ìŒ: {index_name}\")\n",
    "\n",
    "    # í…Œì´ë¸”ì´ ì¡´ì¬í•˜ëŠ” ê²½ìš°ì—ë§Œ ì¸ë±ìŠ¤ ìƒì„± ì‹œë„\n",
    "    if table_exists:\n",
    "        print(f\"ğŸ”§ ìƒˆ ë²¡í„° ì¸ë±ìŠ¤ ìƒì„± ì‹œë„...\")\n",
    "        try:\n",
    "            index = vsc.create_delta_sync_index(\n",
    "                endpoint_name=endpoint_name,\n",
    "                index_name=index_name,\n",
    "                source_table_name=source_table_name,\n",
    "                pipeline_type=\"TRIGGERED\",\n",
    "                primary_key=\"id\",\n",
    "                embedding_source_column=\"content\",\n",
    "                embedding_model_endpoint_name=\"databricks-bge-large-en\"\n",
    "            )\n",
    "            print(\"âœ… ì¸ë±ìŠ¤ ìƒì„± ìš”ì²­ ì™„ë£Œ!\")\n",
    "            print(\"â³ ì¸ë±ìŠ¤ ì¤€ë¹„ê¹Œì§€ ëª‡ ë¶„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "            index = None\n",
    "    else:\n",
    "        print(\"ğŸ”„ ì¸ë±ìŠ¤ ìƒì„±ì„ ìœ„í•´ ë¨¼ì € ë‹¤ìŒì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:\")\n",
    "        print(\"   1. PDF ì²˜ë¦¬ ì…€ ì‹¤í–‰\")\n",
    "        print(\"   2. í…Œì´ë¸” ìƒì„± í™•ì¸\")\n",
    "        print(\"   3. ì´ ì…€ ë‹¤ì‹œ ì‹¤í–‰\")\n",
    "        index = None\n",
    "\n",
    "# ì›Œí¬í”Œë¡œìš° ìƒíƒœ ìš”ì•½\n",
    "print(f\"\\nğŸ“‹ Vector Search ìƒíƒœ ìš”ì•½:\")\n",
    "print(f\"   âœ… í´ë¼ì´ì–¸íŠ¸: ì—°ê²°ë¨\")\n",
    "print(f\"   {'âœ…' if endpoint else 'âŒ'} ì—”ë“œí¬ì¸íŠ¸: {endpoint_name}\")\n",
    "print(f\"   {'âœ…' if table_exists else 'âŒ'} ì†ŒìŠ¤ í…Œì´ë¸”: {source_table_name}\")\n",
    "print(f\"   {'âœ…' if index else 'âŒ'} ë²¡í„° ì¸ë±ìŠ¤: {index_name}\")\n",
    "\n",
    "# ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´\n",
    "if not table_exists:\n",
    "    print(f\"\\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„: PDF ì²˜ë¦¬ ë° í…Œì´ë¸” ìƒì„±\")\n",
    "    print(f\"   â†’ 'PDF ë¬¸ì„œ ì²˜ë¦¬ ë° ì²­í‚¹' ì…€ì„ ì‹¤í–‰í•˜ì„¸ìš”\")\n",
    "elif not index:\n",
    "    print(f\"\\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„: ì¸ë±ìŠ¤ ìƒì„± ì¬ì‹œë„\")\n",
    "    print(f\"   â†’ ì´ ì…€ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”\")\n",
    "else:\n",
    "    print(f\"\\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„: RAG ì‹œìŠ¤í…œ êµ¬ì„±\")\n",
    "    print(f\"   â†’ Vector Store ìƒì„± ì…€ë¡œ ì§„í–‰í•˜ì„¸ìš”\")\n",
    "\n",
    "print(f\"\\nğŸ”§ Vector Search ì„¤ì • ì™„ë£Œ!\")\n",
    "print(f\"   í™˜ê²½: Databricks\")\n",
    "print(f\"   Vector Search ì‚¬ìš© ê°€ëŠ¥: âœ…\")\n",
    "\n",
    "# VS Code Extension í™˜ê²½ íŠ¹ë³„ íŒ\n",
    "if is_vscode_databricks:\n",
    "    print(f\"\\nğŸš€ VS Code Extension í™˜ê²½ íŠ¹ë³„ ê¸°ëŠ¥:\")\n",
    "    print(f\"   âœ… ì‹¤ì‹œê°„ ì›Œí¬í”Œë¡œìš° ìƒíƒœ í™•ì¸\")\n",
    "    print(f\"   âœ… ì§€ëŠ¥ì  ì˜¤ë¥˜ í•´ê²° ê°€ì´ë“œ\")\n",
    "    print(f\"   âœ… ë‹¨ê³„ë³„ ì§„í–‰ ìƒí™© ì¶”ì \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f820658",
   "metadata": {},
   "source": [
    "## 3. PDF ë¬¸ì„œ ì²˜ë¦¬ ë° ë°ì´í„° ì¤€ë¹„\n",
    "\n",
    "PDF ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³  ì²­í‚¹í•˜ì—¬ Vector Searchìš© í…Œì´ë¸”ì„ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "716f3972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ PDF ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘...\n",
      "âœ… PDF íŒŒì¼ ë°œê²¬: ./data/pdf/a-practical-guide-to-building-agents.pdf\n",
      "ğŸ“– PDF íŒŒì¼ ë¡œë”© ì¤‘...\n",
      "âœ… PDF ë¡œë”© ì™„ë£Œ: 34 í˜ì´ì§€\n",
      "ğŸ”ª ë¬¸ì„œ ì²­í‚¹ ì¤‘...\n",
      "âœ… ì²­í‚¹ ì™„ë£Œ: 54 ê°œì˜ ì²­í¬\n",
      "ğŸ’¾ Delta í…Œì´ë¸” ì €ì¥ ì¤‘: workspace.default.rag_documents_vscode\n",
      "ğŸ”§ Vector Searchë¥¼ ìœ„í•œ Change Data Feed í™œì„±í™”...\n",
      "âœ… PDF ë¡œë”© ì™„ë£Œ: 34 í˜ì´ì§€\n",
      "ğŸ”ª ë¬¸ì„œ ì²­í‚¹ ì¤‘...\n",
      "âœ… ì²­í‚¹ ì™„ë£Œ: 54 ê°œì˜ ì²­í¬\n",
      "ğŸ’¾ Delta í…Œì´ë¸” ì €ì¥ ì¤‘: workspace.default.rag_documents_vscode\n",
      "ğŸ”§ Vector Searchë¥¼ ìœ„í•œ Change Data Feed í™œì„±í™”...\n",
      "ğŸ”„ ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ: workspace.default.rag_documents_vscode\n",
      "ğŸ”„ ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ: workspace.default.rag_documents_vscode\n",
      "âœ… Change Data Feedê°€ í™œì„±í™”ëœ í…Œì´ë¸” ìƒì„± ì™„ë£Œ\n",
      "âœ… Change Data Feedê°€ í™œì„±í™”ëœ í…Œì´ë¸” ìƒì„± ì™„ë£Œ\n",
      "ğŸ”§ Change Data Feed ì¶”ê°€ í™œì„±í™” ì™„ë£Œ\n",
      "ğŸ”§ Change Data Feed ì¶”ê°€ í™œì„±í™” ì™„ë£Œ\n",
      "âœ… í…Œì´ë¸” ì €ì¥ ì™„ë£Œ: 54ê°œ ì²­í¬\n",
      "âœ… í…Œì´ë¸” ì €ì¥ ì™„ë£Œ: 54ê°œ ì²­í¬\n",
      "âœ… Change Data Feed ìƒíƒœ: true\n",
      "ğŸ“Š ì €ì¥ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\n",
      "âœ… Change Data Feed ìƒíƒœ: true\n",
      "ğŸ“Š ì €ì¥ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\n",
      "+-------+---------------------------------------------------+-------------------------------------------------------------------------------------------------------+\n",
      "|id     |source                                             |preview                                                                                                |\n",
      "+-------+---------------------------------------------------+-------------------------------------------------------------------------------------------------------+\n",
      "|chunk_0|./data/pdf/a-practical-guide-to-building-agents.pdf|A  p r a c t i c a l  â€¨\\ng u i d e  t o  â€¨\\nb u i l d i n g  a g e n t s                               |\n",
      "|chunk_1|./data/pdf/a-practical-guide-to-building-agents.pdf|C o n t e n t s\\nWha t is an agen t? 4\\nWhen should y ou build an agen t? 5\\nA gen t design f ounda tio|\n",
      "|chunk_2|./data/pdf/a-practical-guide-to-building-agents.pdf|I n t r o d u c t i o n\\nL ar ge language models ar e becoming incr easingly  capable o f  handling c  |\n",
      "+-------+---------------------------------------------------+-------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "âœ… PDF ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ!\n",
      "âœ… Vector Search í˜¸í™˜ í…Œì´ë¸” ìƒì„± ì™„ë£Œ!\n",
      "+-------+---------------------------------------------------+-------------------------------------------------------------------------------------------------------+\n",
      "|id     |source                                             |preview                                                                                                |\n",
      "+-------+---------------------------------------------------+-------------------------------------------------------------------------------------------------------+\n",
      "|chunk_0|./data/pdf/a-practical-guide-to-building-agents.pdf|A  p r a c t i c a l  â€¨\\ng u i d e  t o  â€¨\\nb u i l d i n g  a g e n t s                               |\n",
      "|chunk_1|./data/pdf/a-practical-guide-to-building-agents.pdf|C o n t e n t s\\nWha t is an agen t? 4\\nWhen should y ou build an agen t? 5\\nA gen t design f ounda tio|\n",
      "|chunk_2|./data/pdf/a-practical-guide-to-building-agents.pdf|I n t r o d u c t i o n\\nL ar ge language models ar e becoming incr easingly  capable o f  handling c  |\n",
      "+-------+---------------------------------------------------+-------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "âœ… PDF ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ!\n",
      "âœ… Vector Search í˜¸í™˜ í…Œì´ë¸” ìƒì„± ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# PDF ë¬¸ì„œ ì²˜ë¦¬ ë° ì²­í‚¹\n",
    "print(\"ğŸ“„ PDF ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘...\")\n",
    "\n",
    "# PDF íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "pdf_paths = [\n",
    "    \"./data/pdf/a-practical-guide-to-building-agents.pdf\",\n",
    "    \"/dbfs/FileStore/shared_uploads/a-practical-guide-to-building-agents.pdf\",\n",
    "    \"/FileStore/shared_uploads/a-practical-guide-to-building-agents.pdf\"\n",
    "]\n",
    "\n",
    "# PDF íŒŒì¼ ê²€ìƒ‰\n",
    "pdf_found = False\n",
    "pdf_path = None\n",
    "documents = []\n",
    "\n",
    "for path in pdf_paths:\n",
    "    if os.path.exists(path):\n",
    "        pdf_path = path\n",
    "        pdf_found = True\n",
    "        print(f\"âœ… PDF íŒŒì¼ ë°œê²¬: {pdf_path}\")\n",
    "        break\n",
    "\n",
    "# PDF íŒŒì¼ ì²˜ë¦¬ ë˜ëŠ” ìƒ˜í”Œ ë°ì´í„° ìƒì„±\n",
    "if pdf_found:\n",
    "    try:\n",
    "        print(f\"ğŸ“– PDF íŒŒì¼ ë¡œë”© ì¤‘...\")\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        documents = loader.load()\n",
    "        print(f\"âœ… PDF ë¡œë”© ì™„ë£Œ: {len(documents)} í˜ì´ì§€\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ PDF ë¡œë”© ì‹¤íŒ¨: {e}\")\n",
    "        documents = []\n",
    "        pdf_found = False\n",
    "\n",
    "# PDFê°€ ì—†ìœ¼ë©´ ìƒ˜í”Œ ë°ì´í„° ìƒì„±\n",
    "if not pdf_found or not documents:\n",
    "    print(\"ğŸ”„ ìƒ˜í”Œ í…ìŠ¤íŠ¸ ë°ì´í„° ìƒì„± ì¤‘...\")\n",
    "    \n",
    "    # ìƒ˜í”Œ ë¬¸ì„œ ë°ì´í„°\n",
    "    sample_contents = [\n",
    "        \"\"\"AI Agents and RAG Systems\n",
    "        \n",
    "        AI agents are autonomous systems that combine perception, decision-making, and action execution. \n",
    "        They use machine learning and natural language processing to interact effectively with users.\n",
    "        \n",
    "        Key components include:\n",
    "        1. Perception: Understanding various inputs\n",
    "        2. Decision Making: Processing and choosing actions  \n",
    "        3. Action Execution: Implementing decisions\n",
    "        4. Learning: Adapting from feedback\"\"\",\n",
    "        \n",
    "        \"\"\"Vector Databases and Embeddings\n",
    "        \n",
    "        Vector databases store high-dimensional vectors for efficient similarity search.\n",
    "        Popular options include Databricks Vector Search, Chroma, and Pinecone.\n",
    "        \n",
    "        Embeddings convert text into numerical vectors that capture semantic meaning.\n",
    "        Modern models like BGE and OpenAI's embeddings provide high-quality representations.\"\"\",\n",
    "        \n",
    "        \"\"\"Text-to-SQL Systems\n",
    "        \n",
    "        Text-to-SQL enables natural language database queries without complex SQL knowledge.\n",
    "        Implementation approaches include rule-based systems, ML models, and LLMs.\n",
    "        \n",
    "        Best practices: Include schema info, use few-shot learning, implement validation.\"\"\"\n",
    "    ]\n",
    "    \n",
    "    # Document ê°ì²´ ìƒì„±\n",
    "    from types import SimpleNamespace\n",
    "    documents = []\n",
    "    for i, content in enumerate(sample_contents):\n",
    "        doc = SimpleNamespace()\n",
    "        doc.page_content = content\n",
    "        doc.metadata = {\"page\": i, \"source\": \"sample_ai_guide.pdf\"}\n",
    "        documents.append(doc)\n",
    "    \n",
    "    print(f\"âœ… ìƒ˜í”Œ ë¬¸ì„œ ìƒì„± ì™„ë£Œ: {len(documents)} í˜ì´ì§€\")\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ì²­í‚¹\n",
    "print(\"ğŸ”ª ë¬¸ì„œ ì²­í‚¹ ì¤‘...\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f\"âœ… ì²­í‚¹ ì™„ë£Œ: {len(chunks)} ê°œì˜ ì²­í¬\")\n",
    "\n",
    "# í…Œì´ë¸”ìš© ë°ì´í„° ì¤€ë¹„\n",
    "chunk_data = []\n",
    "for i, chunk in enumerate(chunks):\n",
    "    chunk_data.append({\n",
    "        \"id\": f\"chunk_{i}\",\n",
    "        \"content\": chunk.page_content,\n",
    "        \"source\": chunk.metadata.get(\"source\", \"sample_document.pdf\"),\n",
    "        \"page\": chunk.metadata.get(\"page\", 0),\n",
    "        \"chunk_index\": i\n",
    "    })\n",
    "\n",
    "# Delta í…Œì´ë¸”ì— ì €ì¥ (Change Data Feed í™œì„±í™”)\n",
    "print(f\"ğŸ’¾ Delta í…Œì´ë¸” ì €ì¥ ì¤‘: {source_table_name}\")\n",
    "print(\"ğŸ”§ Vector Searchë¥¼ ìœ„í•œ Change Data Feed í™œì„±í™”...\")\n",
    "\n",
    "try:\n",
    "    # ê¸°ì¡´ í…Œì´ë¸”ì´ ìˆëŠ” ê²½ìš° ì‚­ì œ\n",
    "    try:\n",
    "        spark.sql(f\"DROP TABLE IF EXISTS {source_table_name}\")\n",
    "        print(f\"ğŸ”„ ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ: {source_table_name}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # DataFrame ìƒì„±\n",
    "    df = spark.createDataFrame(chunk_data)\n",
    "    \n",
    "    # Change Data Feedê°€ í™œì„±í™”ëœ Delta í…Œì´ë¸”ë¡œ ì €ì¥\n",
    "    df.write \\\n",
    "        .format(\"delta\") \\\n",
    "        .option(\"delta.enableChangeDataFeed\", \"true\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .saveAsTable(source_table_name)\n",
    "    \n",
    "    print(f\"âœ… Change Data Feedê°€ í™œì„±í™”ëœ í…Œì´ë¸” ìƒì„± ì™„ë£Œ\")\n",
    "    \n",
    "    # Change Data Feed í™œì„±í™” í™•ì¸\n",
    "    try:\n",
    "        spark.sql(f\"ALTER TABLE {source_table_name} SET TBLPROPERTIES (delta.enableChangeDataFeed = true)\")\n",
    "        print(\"ğŸ”§ Change Data Feed ì¶”ê°€ í™œì„±í™” ì™„ë£Œ\")\n",
    "    except Exception as e:\n",
    "        print(f\"â„¹ï¸ Change Data FeedëŠ” ì´ë¯¸ í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤: {e}\")\n",
    "    \n",
    "    # ì €ì¥ í™•ì¸\n",
    "    count = spark.sql(f\"SELECT COUNT(*) FROM {source_table_name}\").collect()[0][0]\n",
    "    print(f\"âœ… í…Œì´ë¸” ì €ì¥ ì™„ë£Œ: {count}ê°œ ì²­í¬\")\n",
    "    \n",
    "    # í…Œì´ë¸” ì†ì„± í™•ì¸\n",
    "    try:\n",
    "        properties = spark.sql(f\"SHOW TBLPROPERTIES {source_table_name}\").collect()\n",
    "        for prop in properties:\n",
    "            if 'enableChangeDataFeed' in prop.key:\n",
    "                print(f\"âœ… Change Data Feed ìƒíƒœ: {prop.value}\")\n",
    "                break\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ í…Œì´ë¸” ì†ì„± í™•ì¸ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    # ìƒ˜í”Œ ë°ì´í„° í™•ì¸\n",
    "    print(\"ğŸ“Š ì €ì¥ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "    spark.sql(f\"SELECT id, source, LEFT(content, 100) as preview FROM {source_table_name} LIMIT 3\").show(truncate=False)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ í…Œì´ë¸” ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"âœ… PDF ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ!\")\n",
    "print(\"âœ… Vector Search í˜¸í™˜ í…Œì´ë¸” ìƒì„± ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddbb900",
   "metadata": {},
   "source": [
    "## 4. Vector Search ì¸ë±ìŠ¤ ìƒì„± ë° ë™ê¸°í™”\n",
    "\n",
    "ì†ŒìŠ¤ í…Œì´ë¸”ì„ ê¸°ë°˜ìœ¼ë¡œ ë²¡í„° ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ê³  ë™ê¸°í™”í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea623258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Vector Search ì¸ë±ìŠ¤ ì„¤ì • ì¤‘...\n",
      "âœ… ê¸°ì¡´ ì¸ë±ìŠ¤ ë°œê²¬: workspace.default.rag_docs_index_vscode\n",
      "âœ… ê¸°ì¡´ ì¸ë±ìŠ¤ ë°œê²¬: workspace.default.rag_docs_index_vscode\n",
      "ğŸ“Š ì¸ë±ìŠ¤ ìƒíƒœ: ì¤€ë¹„ë¨\n",
      "ğŸ‰ ì¸ë±ìŠ¤ê°€ ì‚¬ìš© ì¤€ë¹„ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "ğŸ“Š ì¸ë±ìŠ¤ ìƒíƒœ: ì¤€ë¹„ë¨\n",
      "ğŸ‰ ì¸ë±ìŠ¤ê°€ ì‚¬ìš© ì¤€ë¹„ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "ğŸ”„ ì¸ë±ìŠ¤ ë™ê¸°í™” ì‹œë„ ì¤‘...\n",
      "ğŸ”„ ì¸ë±ìŠ¤ ë™ê¸°í™” ì‹œë„ ì¤‘...\n",
      "âœ… ë™ê¸°í™” ìš”ì²­ ì™„ë£Œ!\n",
      "â³ ë™ê¸°í™” ìƒíƒœ í™•ì¸ ì¤‘...\n",
      "âœ… ë™ê¸°í™” ìš”ì²­ ì™„ë£Œ!\n",
      "â³ ë™ê¸°í™” ìƒíƒœ í™•ì¸ ì¤‘...\n",
      "ğŸ‰ ì¸ë±ìŠ¤ ë™ê¸°í™” ì™„ë£Œ!\n",
      "âœ… Vector Search ì¸ë±ìŠ¤ ì„¤ì • ê³¼ì • ì™„ë£Œ!\n",
      "ğŸ‰ ì¸ë±ìŠ¤ ë™ê¸°í™” ì™„ë£Œ!\n",
      "âœ… Vector Search ì¸ë±ìŠ¤ ì„¤ì • ê³¼ì • ì™„ë£Œ!\n",
      "\n",
      "ğŸ“‹ ìµœì¢… ìƒíƒœ:\n",
      "   ì¸ë±ìŠ¤ ì´ë¦„: workspace.default.rag_docs_index_vscode\n",
      "   ìƒíƒœ: âœ… ì‚¬ìš© ì¤€ë¹„ë¨\n",
      "\n",
      "ğŸ“‹ ìµœì¢… ìƒíƒœ:\n",
      "   ì¸ë±ìŠ¤ ì´ë¦„: workspace.default.rag_docs_index_vscode\n",
      "   ìƒíƒœ: âœ… ì‚¬ìš© ì¤€ë¹„ë¨\n"
     ]
    }
   ],
   "source": [
    "# Databricks í™˜ê²½ì—ì„œë§Œ ë²¡í„° ì¸ë±ìŠ¤ ìƒì„± ë° ê´€ë¦¬\n",
    "if is_databricks_native or is_vscode_databricks:\n",
    "    print(\"ğŸ” Vector Search ì¸ë±ìŠ¤ ì„¤ì • ì¤‘...\")\n",
    "    \n",
    "    # ê¸°ì¡´ ì¸ë±ìŠ¤ í™•ì¸\n",
    "    index = None\n",
    "    try:\n",
    "        index = vsc.get_index(endpoint_name=endpoint_name, index_name=index_name)\n",
    "        print(f\"âœ… ê¸°ì¡´ ì¸ë±ìŠ¤ ë°œê²¬: {index_name}\")\n",
    "        \n",
    "        # ì¸ë±ìŠ¤ ìƒíƒœ í™•ì¸\n",
    "        index_status = index.describe()\n",
    "        is_ready = index_status.get(\"status\", {}).get(\"ready\", False)\n",
    "        print(f\"ğŸ“Š ì¸ë±ìŠ¤ ìƒíƒœ: {'ì¤€ë¹„ë¨' if is_ready else 'ì¤€ë¹„ ì¤‘'}\")\n",
    "        \n",
    "        if is_ready:\n",
    "            print(\"ğŸ‰ ì¸ë±ìŠ¤ê°€ ì‚¬ìš© ì¤€ë¹„ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "        else:\n",
    "            print(\"â³ ì¸ë±ìŠ¤ê°€ ì•„ì§ ì´ˆê¸°í™” ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        if \"RESOURCE_DOES_NOT_EXIST\" in str(e):\n",
    "            print(f\"âŒ ê¸°ì¡´ ì¸ë±ìŠ¤ ì—†ìŒ: {index_name}\")\n",
    "            \n",
    "            # ìƒˆ ì¸ë±ìŠ¤ ìƒì„±\n",
    "            print(\"ğŸ”§ ìƒˆ ë²¡í„° ì¸ë±ìŠ¤ ìƒì„± ì¤‘...\")\n",
    "            try:\n",
    "                index = vsc.create_delta_sync_index(\n",
    "                    endpoint_name=endpoint_name,\n",
    "                    index_name=index_name,\n",
    "                    source_table_name=source_table_name,\n",
    "                    pipeline_type=\"TRIGGERED\",\n",
    "                    primary_key=\"id\",\n",
    "                    embedding_source_column=\"content\",\n",
    "                    embedding_model_endpoint_name=\"databricks-bge-large-en\"\n",
    "                )\n",
    "                print(\"âœ… ì¸ë±ìŠ¤ ìƒì„± ìš”ì²­ ì™„ë£Œ!\")\n",
    "                print(\"â³ ì¸ë±ìŠ¤ ì´ˆê¸°í™”ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "                print(\"   ì´ˆê¸°í™”ì—ëŠ” 5-10ë¶„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "                \n",
    "            except Exception as create_e:\n",
    "                print(f\"âŒ ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {create_e}\")\n",
    "                if \"does not have change data feed enabled\" in str(create_e):\n",
    "                    print(\"ğŸ’¡ í•´ê²° ë°©ë²•: PDF ì²˜ë¦¬ ì…€ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì—¬ Change Data Feedë¥¼ í™œì„±í™”í•˜ì„¸ìš”.\")\n",
    "                raise\n",
    "        else:\n",
    "            print(f\"âŒ ì¸ë±ìŠ¤ ì¡°íšŒ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}\")\n",
    "            raise\n",
    "\n",
    "    # ì¸ë±ìŠ¤ ë™ê¸°í™” ì‹œë„ (ì¤€ë¹„ëœ ê²½ìš°ì—ë§Œ)\n",
    "    if index:\n",
    "        try:\n",
    "            # í˜„ì¬ ìƒíƒœ ì¬í™•ì¸\n",
    "            current_status = index.describe()\n",
    "            is_currently_ready = current_status.get(\"status\", {}).get(\"ready\", False)\n",
    "            \n",
    "            if is_currently_ready:\n",
    "                print(\"ğŸ”„ ì¸ë±ìŠ¤ ë™ê¸°í™” ì‹œë„ ì¤‘...\")\n",
    "                try:\n",
    "                    index.sync()\n",
    "                    print(\"âœ… ë™ê¸°í™” ìš”ì²­ ì™„ë£Œ!\")\n",
    "                    \n",
    "                    # ë™ê¸°í™” ì™„ë£Œ í™•ì¸ (ê°„ë‹¨í•œ ì²´í¬)\n",
    "                    print(\"â³ ë™ê¸°í™” ìƒíƒœ í™•ì¸ ì¤‘...\")\n",
    "                    import time\n",
    "                    time.sleep(5)  # 5ì´ˆ ëŒ€ê¸°\n",
    "                    \n",
    "                    final_status = vsc.get_index(endpoint_name=endpoint_name, index_name=index_name).describe()\n",
    "                    if final_status.get(\"status\", {}).get(\"ready\", False):\n",
    "                        print(\"ğŸ‰ ì¸ë±ìŠ¤ ë™ê¸°í™” ì™„ë£Œ!\")\n",
    "                    else:\n",
    "                        print(\"â³ ë™ê¸°í™”ê°€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ê³„ì† ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.\")\n",
    "                        \n",
    "                except Exception as sync_e:\n",
    "                    if \"is not ready\" in str(sync_e):\n",
    "                        print(\"â³ ì¸ë±ìŠ¤ê°€ ì•„ì§ ì¤€ë¹„ ì¤‘ì´ë¯€ë¡œ ë™ê¸°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "                        print(\"   ëª‡ ë¶„ í›„ì— ì´ ì…€ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì—¬ ë™ê¸°í™”í•˜ì„¸ìš”.\")\n",
    "                    else:\n",
    "                        print(f\"âš ï¸ ë™ê¸°í™” ì˜¤ë¥˜: {sync_e}\")\n",
    "            else:\n",
    "                print(\"â³ ì¸ë±ìŠ¤ê°€ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•„ ë™ê¸°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "                print(\"   ì¸ë±ìŠ¤ ì¤€ë¹„ ì™„ë£Œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.\")\n",
    "                \n",
    "        except Exception as status_e:\n",
    "            print(f\"âš ï¸ ì¸ë±ìŠ¤ ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {status_e}\")\n",
    "\n",
    "    print(\"âœ… Vector Search ì¸ë±ìŠ¤ ì„¤ì • ê³¼ì • ì™„ë£Œ!\")\n",
    "    \n",
    "    # ìƒíƒœ ìš”ì•½\n",
    "    if index:\n",
    "        try:\n",
    "            final_status = index.describe()\n",
    "            ready_status = final_status.get(\"status\", {}).get(\"ready\", False)\n",
    "            print(f\"\\nğŸ“‹ ìµœì¢… ìƒíƒœ:\")\n",
    "            print(f\"   ì¸ë±ìŠ¤ ì´ë¦„: {index_name}\")\n",
    "            print(f\"   ìƒíƒœ: {'âœ… ì‚¬ìš© ì¤€ë¹„ë¨' if ready_status else 'â³ ì´ˆê¸°í™” ì¤‘'}\")\n",
    "            if not ready_status:\n",
    "                print(f\"   ğŸ’¡ ì¸ë±ìŠ¤ ì¤€ë¹„ ì™„ë£Œê¹Œì§€ 5-10ë¶„ ì†Œìš”ë©ë‹ˆë‹¤.\")\n",
    "                print(f\"   ğŸ’¡ ì™„ë£Œ í›„ Vector Store ì„¤ì • ì…€ì„ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "        except Exception:\n",
    "            print(f\"\\nğŸ“‹ ì¸ë±ìŠ¤ ìƒì„± ìš”ì²­ ì™„ë£Œ\")\n",
    "            print(f\"   ğŸ’¡ ìƒíƒœ í™•ì¸ì€ ëª‡ ë¶„ í›„ì— ê°€ëŠ¥í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e7ec189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— Vector Store ë° ì„ë² ë”© ì„¤ì • ì¤‘...\n",
      "âœ… Databricks BGE-Large ì„ë² ë”© ëª¨ë¸ ì—°ê²° ì™„ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23067/2822407483.py:6: LangChainDeprecationWarning: The class `DatabricksEmbeddings` was deprecated in LangChain 0.3.3 and will be removed in 1.0. An updated version of the class exists in the :class:`~databricks-langchain package and should be used instead. To use it run `pip install -U :class:`~databricks-langchain` and import as `from :class:`~databricks_langchain import DatabricksEmbeddings``.\n",
      "  embedding_model = DatabricksEmbeddings(endpoint=\"databricks-bge-large-en\")\n",
      "/tmp/ipykernel_23067/2822407483.py:14: LangChainDeprecationWarning: The class `DatabricksVectorSearch` was deprecated in LangChain 0.3.3 and will be removed in 1.0. An updated version of the class exists in the :class:`~databricks-langchain package and should be used instead. To use it run `pip install -U :class:`~databricks-langchain` and import as `from :class:`~databricks_langchain import DatabricksVectorSearch``.\n",
      "  vector_store = DatabricksVectorSearch(\n",
      "/tmp/ipykernel_23067/2822407483.py:14: LangChainDeprecationWarning: The class `DatabricksVectorSearch` was deprecated in LangChain 0.3.3 and will be removed in 1.0. An updated version of the class exists in the :class:`~databricks-langchain package and should be used instead. To use it run `pip install -U :class:`~databricks-langchain` and import as `from :class:`~databricks_langchain import DatabricksVectorSearch``.\n",
      "  vector_store = DatabricksVectorSearch(\n",
      "WARNING:langchain_community.vectorstores.databricks_vector_search:embedding model is not used in delta-sync index with Databricks-managed embeddings.\n",
      "WARNING:langchain_community.vectorstores.databricks_vector_search:embedding model is not used in delta-sync index with Databricks-managed embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Databricks Vector Store ìƒì„± ì™„ë£Œ\n",
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n",
      "ğŸ§ª Vector Store ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ\n",
      "âœ… Vector Store ì„¤ì • ì™„ë£Œ!\n",
      "ğŸ§ª Vector Store ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ\n",
      "âœ… Vector Store ì„¤ì • ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# Vector Store ë° ì„ë² ë”© ëª¨ë¸ ì„¤ì •\n",
    "print(\"ğŸ”— Vector Store ë° ì„ë² ë”© ì„¤ì • ì¤‘...\")\n",
    "\n",
    "# Databricks ì„ë² ë”© ëª¨ë¸ ì„¤ì •\n",
    "try:\n",
    "    embedding_model = DatabricksEmbeddings(endpoint=\"databricks-bge-large-en\")\n",
    "    print(\"âœ… Databricks BGE-Large ì„ë² ë”© ëª¨ë¸ ì—°ê²° ì™„ë£Œ\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì„ë² ë”© ëª¨ë¸ ì—°ê²° ì‹¤íŒ¨: {e}\")\n",
    "    raise\n",
    "\n",
    "# Vector Store ìƒì„± (ì˜¬ë°”ë¥¸ ë§¤ê°œë³€ìˆ˜ ì‚¬ìš©)\n",
    "try:\n",
    "    vector_store = DatabricksVectorSearch(\n",
    "        index=vsc.get_index(endpoint_name=endpoint_name, index_name=index_name),\n",
    "        text_column=\"content\",  # í…ìŠ¤íŠ¸ ì»¬ëŸ¼ëª…\n",
    "        embedding=embedding_model  # ì„ë² ë”© ëª¨ë¸\n",
    "    )\n",
    "    print(\"âœ… Databricks Vector Store ìƒì„± ì™„ë£Œ\")\n",
    "    \n",
    "    # ì—°ê²° í…ŒìŠ¤íŠ¸\n",
    "    try:\n",
    "        test_results = vector_store.similarity_search(\"test query\", k=1)\n",
    "        print(\"ğŸ§ª Vector Store ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Vector Store í…ŒìŠ¤íŠ¸: {e}\")\n",
    "        print(\"   ì¸ë±ìŠ¤ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Vector Store ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "    print(\"   Vector Search í´ë¼ì´ì–¸íŠ¸ì™€ ì¸ë±ìŠ¤ê°€ ì¤€ë¹„ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "\n",
    "print(\"âœ… Vector Store ì„¤ì • ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61ec5240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— RAG ì²´ì¸ êµ¬ì„± ì¤‘...\n",
      "âœ… Retriever ìƒì„± ì™„ë£Œ\n",
      "âŒ ì‚¬ìš© ê°€ëŠ¥í•œ LLM ì—”ë“œí¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "âŒ LLM ëª¨ë¸ ì—°ê²° ì‹¤íŒ¨: LLM ì—”ë“œí¬ì¸íŠ¸ í•„ìš”\n",
      "ğŸ”„ ê°„ë‹¨í•œ ì‘ë‹µ ì‹œìŠ¤í…œìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤...\n",
      "âœ… ëŒ€ì²´ ì‘ë‹µ ì‹œìŠ¤í…œ í™œì„±í™”\n",
      "âš ï¸ LLM ì—†ì´ Vector Search ì „ìš© ëª¨ë“œë¡œ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
      "âœ… Vector Search ì „ìš© ì²´ì¸ êµ¬ì„± ì™„ë£Œ\n",
      "ğŸ‰ RAG ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!\n",
      "   ëª¨ë“œ: Vector Search ì „ìš©\n",
      "   Vector Search: ì‚¬ìš© ê°€ëŠ¥\n",
      "   LLM: ëŒ€ì²´ ëª¨ë“œ\n",
      "\n",
      "ğŸ’¡ ì‚¬ìš©ë²•: ë¬¸ì„œ ê²€ìƒ‰ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤. LLM ì¶”ë¡ ì€ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”— RAG ì²´ì¸ êµ¬ì„±\n",
    "print(\"ğŸ”— RAG ì²´ì¸ êµ¬ì„± ì¤‘...\")\n",
    "\n",
    "# 1. Retriever ìƒì„±\n",
    "retriever = None\n",
    "try:\n",
    "    if 'vector_store' in locals() and vector_store is not None:\n",
    "        retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "        print(\"âœ… Retriever ìƒì„± ì™„ë£Œ\")\n",
    "    else:\n",
    "        print(\"âš ï¸ Vector Storeê°€ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        print(\"   RAG ì²´ì¸ì„ Vector Store ì—†ì´ êµ¬ì„±í•©ë‹ˆë‹¤.\")\n",
    "        print(\"   ì‹¤ì œ ê²€ìƒ‰ ê¸°ëŠ¥ì€ Vector Store ì¤€ë¹„ í›„ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Retriever ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "    print(\"   RAG ì²´ì¸ì„ ì œí•œëœ ê¸°ëŠ¥ìœ¼ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "# 2. Databricks LLM ëª¨ë¸ ì—°ê²°\n",
    "chat_model = None\n",
    "try:\n",
    "    if 'llm_endpoint' in locals() and llm_endpoint:\n",
    "        print(f\"ğŸ”— LLM ì—°ê²° ì‹œë„: {llm_endpoint}\")\n",
    "        chat_model = ChatDatabricks(\n",
    "            endpoint=llm_endpoint,\n",
    "            max_tokens=500,\n",
    "            temperature=0.1\n",
    "        )\n",
    "        # ì—°ê²° í…ŒìŠ¤íŠ¸\n",
    "        test_response = chat_model.invoke(\"Hello\")\n",
    "        print(f\"âœ… Databricks LLM ëª¨ë¸ ì—°ê²° ì™„ë£Œ: {llm_endpoint}\")\n",
    "    else:\n",
    "        print(\"âŒ ì‚¬ìš© ê°€ëŠ¥í•œ LLM ì—”ë“œí¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        raise ValueError(\"LLM ì—”ë“œí¬ì¸íŠ¸ í•„ìš”\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ LLM ëª¨ë¸ ì—°ê²° ì‹¤íŒ¨: {e}\")\n",
    "    print(\"ğŸ”„ ê°„ë‹¨í•œ ì‘ë‹µ ì‹œìŠ¤í…œìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤...\")\n",
    "    \n",
    "    # ê°„ë‹¨í•œ ëŒ€ì²´ ì‘ë‹µ ì‹œìŠ¤í…œ\n",
    "    class SimpleLLM:\n",
    "        def invoke(self, query):\n",
    "            return {\n",
    "                \"result\": f\"LLM ì—”ë“œí¬ì¸íŠ¸ì— ì—°ê²°í•  ìˆ˜ ì—†ì–´ ê°„ë‹¨í•œ ì‘ë‹µì„ ì œê³µí•©ë‹ˆë‹¤.\\n\\nì§ˆë¬¸: {query.get('query', query)}\\n\\nğŸ’¡ í•´ê²°ë°©ë²•:\\n1. Databricks ê´€ë¦¬ìì—ê²Œ Foundation Model APIs í™œì„±í™” ìš”ì²­\\n2. Model Serving ê¶Œí•œ í™•ì¸\\n3. ì‚¬ìš© ê°€ëŠ¥í•œ LLM ì—”ë“œí¬ì¸íŠ¸ ë°°í¬ í™•ì¸\",\n",
    "                \"source_documents\": []\n",
    "            }\n",
    "    \n",
    "    chat_model = SimpleLLM()\n",
    "    print(\"âœ… ëŒ€ì²´ ì‘ë‹µ ì‹œìŠ¤í…œ í™œì„±í™”\")\n",
    "\n",
    "# 3. RAG ì²´ì¸ êµ¬ì„±\n",
    "qa_chain = None\n",
    "try:\n",
    "    if retriever is not None and chat_model is not None and hasattr(chat_model, 'invoke') and not isinstance(chat_model, type(SimpleLLM())):\n",
    "        # ì™„ì „í•œ RAG ì²´ì¸ êµ¬ì„± (ì‹¤ì œ LLMê³¼ Vector Store)\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=chat_model,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=retriever,\n",
    "            return_source_documents=True\n",
    "        )\n",
    "        print(\"âœ… ì™„ì „í•œ RAG ì²´ì¸ êµ¬ì„± ì™„ë£Œ\")\n",
    "        rag_mode = \"ì™„ì „í•œ RAG\"\n",
    "        \n",
    "    elif retriever is not None:\n",
    "        # Vector Searchë§Œ ìˆëŠ” ê²½ìš°\n",
    "        print(\"âš ï¸ LLM ì—†ì´ Vector Search ì „ìš© ëª¨ë“œë¡œ êµ¬ì„±í•©ë‹ˆë‹¤.\")\n",
    "        \n",
    "        class VectorSearchOnlyChain:\n",
    "            def __init__(self, retriever):\n",
    "                self.retriever = retriever\n",
    "                \n",
    "            def invoke(self, query):\n",
    "                docs = self.retriever.get_relevant_documents(query.get('query', query))\n",
    "                result = f\"Vector Search ê²°ê³¼ (LLM ì—†ìŒ):\\n\\n\"\n",
    "                for i, doc in enumerate(docs[:3], 1):\n",
    "                    result += f\"{i}. {doc.page_content[:200]}...\\n\\n\"\n",
    "                return {\"result\": result, \"source_documents\": docs}\n",
    "        \n",
    "        qa_chain = VectorSearchOnlyChain(retriever)\n",
    "        print(\"âœ… Vector Search ì „ìš© ì²´ì¸ êµ¬ì„± ì™„ë£Œ\")\n",
    "        rag_mode = \"Vector Search ì „ìš©\"\n",
    "        \n",
    "    else:\n",
    "        # ë‘˜ ë‹¤ ì—†ëŠ” ê²½ìš° - ê°„ë‹¨í•œ ì‘ë‹µë§Œ\n",
    "        qa_chain = chat_model\n",
    "        print(\"âœ… ê°„ë‹¨í•œ ì‘ë‹µ ì²´ì¸ êµ¬ì„± ì™„ë£Œ\")\n",
    "        rag_mode = \"ê°„ë‹¨í•œ ì‘ë‹µ\"\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ RAG ì²´ì¸ êµ¬ì„± ì‹¤íŒ¨: {e}\")\n",
    "    # ìµœì†Œí•œì˜ ì‘ë‹µ ì²´ì¸\n",
    "    qa_chain = SimpleLLM()\n",
    "    print(\"âœ… ìµœì†Œí•œì˜ ì‘ë‹µ ì²´ì¸ êµ¬ì„± ì™„ë£Œ\")\n",
    "    rag_mode = \"ê¸°ë³¸ ì‘ë‹µ\"\n",
    "\n",
    "print(\"ğŸ‰ RAG ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "print(f\"   ëª¨ë“œ: {rag_mode}\")\n",
    "print(f\"   Vector Search: {'ì‚¬ìš© ê°€ëŠ¥' if retriever else 'ì¤€ë¹„ í•„ìš”'}\")\n",
    "print(f\"   LLM: {'ì‚¬ìš© ê°€ëŠ¥' if chat_model and not isinstance(chat_model, type(SimpleLLM())) else 'ëŒ€ì²´ ëª¨ë“œ'}\")\n",
    "\n",
    "# ì‚¬ìš©ë²• ì•ˆë‚´\n",
    "if rag_mode == \"ì™„ì „í•œ RAG\":\n",
    "    print(f\"\\nğŸ’¡ ì‚¬ìš©ë²•: ëª¨ë“  ê¸°ëŠ¥ì´ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.\")\n",
    "elif rag_mode == \"Vector Search ì „ìš©\":\n",
    "    print(f\"\\nğŸ’¡ ì‚¬ìš©ë²•: ë¬¸ì„œ ê²€ìƒ‰ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤. LLM ì¶”ë¡ ì€ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(f\"\\nğŸ’¡ ì‚¬ìš©ë²•: ì œí•œëœ ê¸°ëŠ¥ë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.\")\n",
    "    print(f\"   â†’ Foundation Model APIs í™œì„±í™” í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c0c1fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ì‚¬ìš© ê°€ëŠ¥í•œ LLM ì—”ë“œí¬ì¸íŠ¸ í™•ì¸ ì¤‘...\n",
      "ğŸ“¡ Databricks serving endpoints ì¡°íšŒ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-27 08:37:03,396 23067 ERROR _handle_rpc_error GRPC Error received\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wjadmin/Dev/Databricks/databricks_rag/.venv/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py\", line 1711, in _execute_and_fetch_as_iterator\n",
      "    for b in generator:\n",
      "  File \"<frozen _collections_abc>\", line 330, in __next__\n",
      "  File \"/home/wjadmin/Dev/Databricks/databricks_rag/.venv/lib/python3.11/site-packages/pyspark/sql/connect/client/reattach.py\", line 135, in send\n",
      "    if not self._has_next():\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/wjadmin/Dev/Databricks/databricks_rag/.venv/lib/python3.11/site-packages/pyspark/sql/connect/client/reattach.py\", line 196, in _has_next\n",
      "    raise e\n",
      "  File \"/home/wjadmin/Dev/Databricks/databricks_rag/.venv/lib/python3.11/site-packages/pyspark/sql/connect/client/reattach.py\", line 168, in _has_next\n",
      "    self._current = self._call_iter(\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/wjadmin/Dev/Databricks/databricks_rag/.venv/lib/python3.11/site-packages/pyspark/sql/connect/client/reattach.py\", line 291, in _call_iter\n",
      "    raise e\n",
      "  File \"/home/wjadmin/Dev/Databricks/databricks_rag/.venv/lib/python3.11/site-packages/pyspark/sql/connect/client/reattach.py\", line 271, in _call_iter\n",
      "    return iter_fun()\n",
      "           ^^^^^^^^^^\n",
      "  File \"/home/wjadmin/Dev/Databricks/databricks_rag/.venv/lib/python3.11/site-packages/pyspark/sql/connect/client/reattach.py\", line 169, in <lambda>\n",
      "    lambda: next(self._iterator)  # type: ignore[arg-type]\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/wjadmin/Dev/Databricks/databricks_rag/.venv/lib/python3.11/site-packages/grpc/_channel.py\", line 543, in __next__\n",
      "    return self._next()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/wjadmin/Dev/Databricks/databricks_rag/.venv/lib/python3.11/site-packages/grpc/_channel.py\", line 969, in _next\n",
      "    raise self\n",
      "grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:\n",
      "\tstatus = StatusCode.INTERNAL\n",
      "\tdetails = \"\n",
      "[PARSE_SYNTAX_ERROR] Syntax error at or near end of input. SQLSTATE: 42601 (line 1, pos 14)\n",
      "\n",
      "== SQL ==\n",
      "SHOW ENDPOINTS\n",
      "--------------^^^\n",
      "\"\n",
      "\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"\\n[PARSE_SYNTAX_ERROR] Syntax error at or near end of input. SQLSTATE: 42601 (line 1, pos 14)\\n\\n== SQL ==\\nSHOW ENDPOINTS\\n--------------^^^\\n\", grpc_status:13}\"\n",
      ">\n",
      "ERROR:pyspark.sql.connect.client.logging:GRPC Error received\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wjadmin/Dev/Databricks/databricks_rag/.venv/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py\", line 1711, in _execute_and_fetch_as_iterator\n",
      "    for b in generator:\n",
      "  File \"<frozen _collections_abc>\", line 330, in __next__\n",
      "  File \"/home/wjadmin/Dev/Databricks/databricks_rag/.venv/lib/python3.11/site-packages/pyspark/sql/connect/client/reattach.py\", line 135, in send\n",
      "    if not self._has_next():\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/wjadmin/Dev/Databricks/databricks_rag/.venv/lib/python3.11/site-packages/pyspark/sql/connect/client/reattach.py\", line 196, in _has_next\n",
      "    raise e\n",
      "  File \"/home/wjadmin/Dev/Databricks/databricks_rag/.venv/lib/python3.11/site-packages/pyspark/sql/connect/client/reattach.py\", line 168, in _has_next\n",
      "    self._current = self._call_iter(\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/wjadmin/Dev/Databricks/databricks_rag/.venv/lib/python3.11/site-packages/pyspark/sql/connect/client/reattach.py\", line 291, in _call_iter\n",
      "    raise e\n",
      "  File \"/home/wjadmin/Dev/Databricks/databricks_rag/.venv/lib/python3.11/site-packages/pyspark/sql/connect/client/reattach.py\", line 271, in _call_iter\n",
      "    return iter_fun()\n",
      "           ^^^^^^^^^^\n",
      "  File \"/home/wjadmin/Dev/Databricks/databricks_rag/.venv/lib/python3.11/site-packages/pyspark/sql/connect/client/reattach.py\", line 169, in <lambda>\n",
      "    lambda: next(self._iterator)  # type: ignore[arg-type]\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/wjadmin/Dev/Databricks/databricks_rag/.venv/lib/python3.11/site-packages/grpc/_channel.py\", line 543, in __next__\n",
      "    return self._next()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/wjadmin/Dev/Databricks/databricks_rag/.venv/lib/python3.11/site-packages/grpc/_channel.py\", line 969, in _next\n",
      "    raise self\n",
      "grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:\n",
      "\tstatus = StatusCode.INTERNAL\n",
      "\tdetails = \"\n",
      "[PARSE_SYNTAX_ERROR] Syntax error at or near end of input. SQLSTATE: 42601 (line 1, pos 14)\n",
      "\n",
      "== SQL ==\n",
      "SHOW ENDPOINTS\n",
      "--------------^^^\n",
      "\"\n",
      "\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"\\n[PARSE_SYNTAX_ERROR] Syntax error at or near end of input. SQLSTATE: 42601 (line 1, pos 14)\\n\\n== SQL ==\\nSHOW ENDPOINTS\\n--------------^^^\\n\", grpc_status:13}\"\n",
      ">\n",
      "ERROR:pyspark.sql.connect.client.logging:GRPC Error received\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wjadmin/Dev/Databricks/databricks_rag/.venv/lib/python3.11/site-packages/pyspark/sql/connect/client/core.py\", line 1711, in _execute_and_fetch_as_iterator\n",
      "    for b in generator:\n",
      "  File \"<frozen _collections_abc>\", line 330, in __next__\n",
      "  File \"/home/wjadmin/Dev/Databricks/databricks_rag/.venv/lib/python3.11/site-packages/pyspark/sql/connect/client/reattach.py\", line 135, in send\n",
      "    if not self._has_next():\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/wjadmin/Dev/Databricks/databricks_rag/.venv/lib/python3.11/site-packages/pyspark/sql/connect/client/reattach.py\", line 196, in _has_next\n",
      "    raise e\n",
      "  File \"/home/wjadmin/Dev/Databricks/databricks_rag/.venv/lib/python3.11/site-packages/pyspark/sql/connect/client/reattach.py\", line 168, in _has_next\n",
      "    self._current = self._call_iter(\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/wjadmin/Dev/Databricks/databricks_rag/.venv/lib/python3.11/site-packages/pyspark/sql/connect/client/reattach.py\", line 291, in _call_iter\n",
      "    raise e\n",
      "  File \"/home/wjadmin/Dev/Databricks/databricks_rag/.venv/lib/python3.11/site-packages/pyspark/sql/connect/client/reattach.py\", line 271, in _call_iter\n",
      "    return iter_fun()\n",
      "           ^^^^^^^^^^\n",
      "  File \"/home/wjadmin/Dev/Databricks/databricks_rag/.venv/lib/python3.11/site-packages/pyspark/sql/connect/client/reattach.py\", line 169, in <lambda>\n",
      "    lambda: next(self._iterator)  # type: ignore[arg-type]\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/wjadmin/Dev/Databricks/databricks_rag/.venv/lib/python3.11/site-packages/grpc/_channel.py\", line 543, in __next__\n",
      "    return self._next()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/wjadmin/Dev/Databricks/databricks_rag/.venv/lib/python3.11/site-packages/grpc/_channel.py\", line 969, in _next\n",
      "    raise self\n",
      "grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:\n",
      "\tstatus = StatusCode.INTERNAL\n",
      "\tdetails = \"\n",
      "[PARSE_SYNTAX_ERROR] Syntax error at or near end of input. SQLSTATE: 42601 (line 1, pos 14)\n",
      "\n",
      "== SQL ==\n",
      "SHOW ENDPOINTS\n",
      "--------------^^^\n",
      "\"\n",
      "\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"\\n[PARSE_SYNTAX_ERROR] Syntax error at or near end of input. SQLSTATE: 42601 (line 1, pos 14)\\n\\n== SQL ==\\nSHOW ENDPOINTS\\n--------------^^^\\n\", grpc_status:13}\"\n",
      ">\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Endpoints ì¡°íšŒ ì‹¤íŒ¨: \n",
      "[PARSE_SYNTAX_ERROR] Syntax error at or near end of input. SQLSTATE: 42601 (line 1, pos 14)\n",
      "\n",
      "== SQL ==\n",
      "SHOW ENDPOINTS\n",
      "--------------^^^\n",
      "\n",
      "\n",
      "JVM stacktrace:\n",
      "org.apache.spark.sql.catalyst.parser.ParseException\n",
      "\tat org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)\n",
      "\tat org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:118)\n",
      "\tat org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:150)\n",
      "\tat org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$6(SparkSession.scala:1087)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:216)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$5(SparkSession.scala:1086)\n",
      "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:532)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$4(SparkSession.scala:1086)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:1082)\n",
      "\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.executeSQL(SparkConnectPlanner.scala:3606)\n",
      "\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleSqlCommand(SparkConnectPlanner.scala:3435)\n",
      "\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:3370)\n",
      "\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.handleCommand(ExecuteThreadRunner.scala:413)\n",
      "\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:312)\n",
      "\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:233)\n",
      "\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:464)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1450)\n",
      "\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:464)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:97)\n",
      "\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:90)\n",
      "\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:240)\n",
      "\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:89)\n",
      "\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:463)\n",
      "\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:233)\n",
      "\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:139)\n",
      "\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.$anonfun$run$2(ExecuteThreadRunner.scala:614)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)\n",
      "\tat com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)\n",
      "\tat com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)\n",
      "\tat scala.util.Using$.resource(Using.scala:269)\n",
      "\tat com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)\n",
      "\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:614)\n",
      "\n",
      "ğŸ”§ Foundation Model API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸...\n",
      "ğŸ“¡ í…ŒìŠ¤íŠ¸ ì¤‘: databricks-meta-llama-3-1-405b-instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23067/136608683.py:37: LangChainDeprecationWarning: The class `ChatDatabricks` was deprecated in LangChain 0.3.3 and will be removed in 1.0. An updated version of the class exists in the :class:`~databricks-langchain package and should be used instead. To use it run `pip install -U :class:`~databricks-langchain` and import as `from :class:`~databricks_langchain import ChatDatabricks``.\n",
      "  test_model = ChatDatabricks(endpoint=endpoint_name, max_tokens=5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì‚¬ìš© ê°€ëŠ¥: databricks-meta-llama-3-1-405b-instruct\n",
      "\n",
      "ğŸ“Š LLM ì—”ë“œí¬ì¸íŠ¸ í™•ì¸ ê²°ê³¼:\n",
      "   âœ… ì‚¬ìš© ê°€ëŠ¥í•œ ì—”ë“œí¬ì¸íŠ¸: 1ê°œ\n",
      "   ğŸ¯ ì„ íƒëœ ì—”ë“œí¬ì¸íŠ¸: databricks-meta-llama-3-1-405b-instruct\n",
      "âœ… LLM ì—”ë“œí¬ì¸íŠ¸ ì„¤ì • ì™„ë£Œ: databricks-meta-llama-3-1-405b-instruct\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” ì‚¬ìš© ê°€ëŠ¥í•œ LLM ì—”ë“œí¬ì¸íŠ¸ í™•ì¸\n",
    "print(\"ğŸ” ì‚¬ìš© ê°€ëŠ¥í•œ LLM ì—”ë“œí¬ì¸íŠ¸ í™•ì¸ ì¤‘...\")\n",
    "\n",
    "# Databricks serving endpoints ëª©ë¡ í™•ì¸\n",
    "try:\n",
    "    print(\"ğŸ“¡ Databricks serving endpoints ì¡°íšŒ ì¤‘...\")\n",
    "    endpoints_result = spark.sql(\"SHOW ENDPOINTS\").collect()\n",
    "    \n",
    "    if endpoints_result:\n",
    "        print(\"âœ… ì‚¬ìš© ê°€ëŠ¥í•œ serving endpoints:\")\n",
    "        for row in endpoints_result:\n",
    "            print(f\"   â€¢ {row[0]}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ ì¡°íšŒëœ serving endpointsê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Endpoints ì¡°íšŒ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "# ëŒ€ì•ˆ: Foundation Model API ì—”ë“œí¬ì¸íŠ¸ í™•ì¸\n",
    "print(f\"\\nğŸ”§ Foundation Model API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸...\")\n",
    "\n",
    "# Foundation Model API ì—”ë“œí¬ì¸íŠ¸ë“¤ (ìƒˆë¡œìš´ í˜•ì‹)\n",
    "foundation_endpoints = [\n",
    "    \"databricks-meta-llama-3-1-405b-instruct\",\n",
    "    \"databricks-meta-llama-3-1-70b-instruct\", \n",
    "    \"databricks-meta-llama-3-70b-instruct\",\n",
    "    \"databricks-mixtral-8x7b-instruct\",\n",
    "    \"databricks-dbrx-instruct\"\n",
    "]\n",
    "\n",
    "available_endpoint = None\n",
    "working_endpoints = []\n",
    "\n",
    "for endpoint_name in foundation_endpoints:\n",
    "    try:\n",
    "        print(f\"ğŸ“¡ í…ŒìŠ¤íŠ¸ ì¤‘: {endpoint_name}\")\n",
    "        test_model = ChatDatabricks(endpoint=endpoint_name, max_tokens=5)\n",
    "        # ë§¤ìš° ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸\n",
    "        test_response = test_model.invoke(\"Hi\")\n",
    "        working_endpoints.append(endpoint_name)\n",
    "        if available_endpoint is None:\n",
    "            available_endpoint = endpoint_name\n",
    "        print(f\"âœ… ì‚¬ìš© ê°€ëŠ¥: {endpoint_name}\")\n",
    "        break  # ì²« ë²ˆì§¸ ì‘ë™í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ì¤‘ë‹¨\n",
    "    except Exception as e:\n",
    "        if \"ENDPOINT_NOT_FOUND\" in str(e):\n",
    "            print(f\"âŒ ì—”ë“œí¬ì¸íŠ¸ ì—†ìŒ: {endpoint_name}\")\n",
    "        elif \"PERMISSION_DENIED\" in str(e) or \"FORBIDDEN\" in str(e):\n",
    "            print(f\"âš ï¸ ê¶Œí•œ ì—†ìŒ: {endpoint_name}\")\n",
    "        else:\n",
    "            print(f\"âš ï¸ ì—°ê²° ì˜¤ë¥˜: {endpoint_name} - {str(e)[:50]}...\")\n",
    "\n",
    "print(f\"\\nğŸ“Š LLM ì—”ë“œí¬ì¸íŠ¸ í™•ì¸ ê²°ê³¼:\")\n",
    "if working_endpoints:\n",
    "    print(f\"   âœ… ì‚¬ìš© ê°€ëŠ¥í•œ ì—”ë“œí¬ì¸íŠ¸: {len(working_endpoints)}ê°œ\")\n",
    "    print(f\"   ğŸ¯ ì„ íƒëœ ì—”ë“œí¬ì¸íŠ¸: {available_endpoint}\")\n",
    "    llm_endpoint = available_endpoint\n",
    "else:\n",
    "    print(f\"   âŒ ì‚¬ìš© ê°€ëŠ¥í•œ LLM ì—”ë“œí¬ì¸íŠ¸ ì—†ìŒ\")\n",
    "    print(f\"   ğŸ’¡ í•´ê²° ë°©ë²•:\")\n",
    "    print(f\"      1. Databricks ê´€ë¦¬ìì—ê²Œ Foundation Model APIs í™œì„±í™” ìš”ì²­\")\n",
    "    print(f\"      2. ì›Œí¬ìŠ¤í˜ì´ìŠ¤ì—ì„œ Model Serving ê¶Œí•œ í™•ì¸\")\n",
    "    print(f\"      3. ë˜ëŠ” OpenAI API í‚¤ë¥¼ ì‚¬ìš©í•œ ëŒ€ì•ˆ LLM ì„¤ì •\")\n",
    "    llm_endpoint = None\n",
    "\n",
    "# LLM ì—†ì´ë„ Vector Search í…ŒìŠ¤íŠ¸ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •\n",
    "if llm_endpoint:\n",
    "    print(f\"âœ… LLM ì—”ë“œí¬ì¸íŠ¸ ì„¤ì • ì™„ë£Œ: {llm_endpoint}\")\n",
    "else:\n",
    "    print(f\"âš ï¸ LLM ì—†ì´ Vector Searchë§Œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥í•œ ëª¨ë“œë¡œ ì„¤ì •ë©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d951bf",
   "metadata": {},
   "source": [
    "### Databricks í™˜ê²½ ì „ìš© ë…¸íŠ¸ë¶\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ Databricks í™˜ê²½ì—ì„œë§Œ ì‘ë™í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "### VS Code Databricks Extension ì„¤ì¹˜ (ê¶Œì¥)\n",
    "1. VS Codeì—ì„œ \"Databricks\" í™•ì¥ ê²€ìƒ‰ ë° ì„¤ì¹˜\n",
    "2. `Ctrl+Shift+P` â†’ \"Databricks: Configure Workspace\"\n",
    "3. Databricks URLê³¼ Personal Access Token ì…ë ¥  \n",
    "4. í´ëŸ¬ìŠ¤í„° ì—°ê²° í›„ ì´ ë…¸íŠ¸ë¶ ì‹¤í–‰\n",
    "\n",
    "## ë²¡í„° ì¸ë±ìŠ¤ ë™ê¸°í™”\n",
    "\n",
    "ì´ ì„¹ì…˜ì—ì„œëŠ” Databricks í™˜ê²½ì—ì„œ ë²¡í„° ì¸ë±ìŠ¤ë¥¼ ë™ê¸°í™”í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ì£¼ìš” ë‹¨ê³„\n",
    "1. **ì¸ë±ìŠ¤ ë™ê¸°í™” ì‹œì‘**: Databricks ë˜ëŠ” VS Code Databricks Extension í™˜ê²½ì—ì„œë§Œ ì‹¤í–‰ë©ë‹ˆë‹¤.\n",
    "2. **ìƒíƒœ í™•ì¸**: ì¸ë±ìŠ¤ ë™ê¸°í™” ìƒíƒœë¥¼ í™•ì¸í•˜ê³  ì¤€ë¹„ ìƒíƒœë¥¼ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤.\n",
    "3. **ìµœëŒ€ ëŒ€ê¸° ì‹œê°„**: ë™ê¸°í™” ì™„ë£Œê¹Œì§€ ìµœëŒ€ 5ë¶„ ëŒ€ê¸°í•˜ë©° ì§„í–‰ ìƒíƒœë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "4. **ì™„ë£Œ í™•ì¸**: ë™ê¸°í™” ì™„ë£Œ í›„ ë²¡í„° ê²€ìƒ‰ ì¤€ë¹„ ìƒíƒœë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ì£¼ì˜ì‚¬í•­\n",
    "- Databricks í™˜ê²½ì—ì„œë§Œ ì‹¤í–‰ ê°€ëŠ¥í•˜ë©°, ë‹¤ë¥¸ í™˜ê²½ì—ì„œëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤.\n",
    "- Spark Connect ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. `spark.remote` ì˜µì…˜ ë˜ëŠ” `SPARK_REMOTE` í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.\n",
    "\n",
    "## 5. RAG ì²´ì¸ êµ¬ì„±\n",
    "\n",
    "Retrieverì™€ LLMì„ ì—°ê²°í•˜ì—¬ ì™„ì „í•œ RAG ì‹œìŠ¤í…œì„ êµ¬ì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c03b088",
   "metadata": {},
   "source": [
    "## ğŸš€ VS Code Databricks Extension í™˜ê²½ì—ì„œ ì‹¤í–‰í•˜ê¸° (ê¶Œì¥)\n",
    "\n",
    "### âœ¨ VS Code + Databricks Extensionì˜ ì¥ì \n",
    "- **í•˜ì´ë¸Œë¦¬ë“œ ê°œë°œ**: ë¡œì»¬ í¸ì§‘ + í´ë¼ìš°ë“œ ì‹¤í–‰\n",
    "- **ì‹¤ì‹œê°„ í˜‘ì—…**: Gitì„ í†µí•œ ì™„ë²½í•œ ë²„ì „ ê´€ë¦¬\n",
    "- **ë¹ ë¥¸ ê°œë°œ**: ìµìˆ™í•œ VS Code ì¸í„°í˜ì´ìŠ¤\n",
    "- **ëª¨ë“  ê¸°ëŠ¥**: Native Databricksì˜ ëª¨ë“  ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥\n",
    "\n",
    "### ğŸ”§ 1ë‹¨ê³„: VS Code Databricks Extension ì„¤ì¹˜\n",
    "1. **VS Code ì—´ê¸°** â†’ Extensions (`Ctrl+Shift+X`)\n",
    "2. **\"Databricks\" ê²€ìƒ‰** â†’ Microsoft ê³µì‹ í™•ì¥ ì„¤ì¹˜\n",
    "3. **ì¬ì‹œì‘** â†’ VS Code ì¬ì‹œì‘\n",
    "\n",
    "### ğŸ”‘ 2ë‹¨ê³„: Databricks ì¸ì¦ ì„¤ì •\n",
    "1. **Personal Access Token ìƒì„±**:\n",
    "   - Databricks Workspace â†’ User Settings â†’ Developer\n",
    "   - Access Tokens â†’ Generate New Token\n",
    "   - í† í° ë³µì‚¬ ë° ì•ˆì „íˆ ë³´ê´€\n",
    "\n",
    "2. **VS Codeì—ì„œ Workspace ì—°ê²°**:\n",
    "   - `Ctrl+Shift+P` â†’ \"Databricks: Configure Workspace\"\n",
    "   - Databricks URL ì…ë ¥: `https://your-workspace.cloud.databricks.com`\n",
    "   - Personal Access Token ì…ë ¥\n",
    "\n",
    "### ğŸ–¥ï¸ 3ë‹¨ê³„: í´ëŸ¬ìŠ¤í„° ì—°ê²°\n",
    "1. **VS Code ì¢Œì¸¡ Databricks íŒ¨ë„** í™•ì¸\n",
    "2. **í´ëŸ¬ìŠ¤í„° ëª©ë¡**ì—ì„œ ì‚¬ìš©í•  í´ëŸ¬ìŠ¤í„° ì„ íƒ\n",
    "3. **\"Connect\" ë²„íŠ¼** í´ë¦­í•˜ì—¬ ì—°ê²°\n",
    "\n",
    "### ğŸ“ 4ë‹¨ê³„: íŒŒì¼ ë° ë°ì´í„° ì¤€ë¹„\n",
    "1. **ë¡œì»¬ íŒŒì¼ ì¤€ë¹„**:\n",
    "   ```\n",
    "   ./data/docs/a-practical-guide-to-building-agents.pdf\n",
    "   ```\n",
    "2. **ë˜ëŠ” DBFS ì—…ë¡œë“œ**:\n",
    "   - Databricks UI â†’ Data â†’ Upload File\n",
    "   - VS Code í„°ë¯¸ë„: `databricks fs cp local_file.pdf /FileStore/shared_uploads/`\n",
    "\n",
    "### âš¡ 5ë‹¨ê³„: ë…¸íŠ¸ë¶ ì‹¤í–‰\n",
    "1. **ì´ ë…¸íŠ¸ë¶ ì‹¤í–‰**: ì…€ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰\n",
    "2. **í™˜ê²½ ê°ì§€ í™•ì¸**: \"VS Code Databricks Extension í™˜ê²½ ê°ì§€ë¨!\" ë©”ì‹œì§€ í™•ì¸\n",
    "3. **ëª¨ë“  ê¸°ëŠ¥ ì‚¬ìš©**: Vector Search, LLM, Text-to-SQL ë“±\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¥ Native Databricks í™˜ê²½ì—ì„œ ì‹¤í–‰í•˜ê¸°\n",
    "\n",
    "### 1ë‹¨ê³„: Databricks Workspace ì ‘ì†\n",
    "1. **ë¸Œë¼ìš°ì €ì—ì„œ Workspace URL ì ‘ì†**\n",
    "2. **Compute â†’ Create Cluster** (ML Runtime ì„ íƒ)\n",
    "3. **Workspace â†’ Import** â†’ ì´ .ipynb íŒŒì¼ ì—…ë¡œë“œ\n",
    "\n",
    "### 2ë‹¨ê³„: íŒŒì¼ ì—…ë¡œë“œ\n",
    "1. **ì¢Œì¸¡ 'Data' ë©”ë‰´** â†’ 'Create Table'\n",
    "2. **'Upload File'** â†’ PDF íŒŒì¼ ì„ íƒ\n",
    "3. **ì—…ë¡œë“œ í›„ ê²½ë¡œ ìˆ˜ì •** â†’ í•´ë‹¹ ì…€ì˜ `pdf_path` ë³€ìˆ˜ ì—…ë°ì´íŠ¸\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’» VS Code Databricks Extension í™˜ê²½ì—ì„œ ì‹¤í–‰í•˜ê¸° (ê¶Œì¥)\n",
    "\n",
    "### âœ¨ VS Code + Databricks Extensionì˜ ì¥ì \n",
    "- **í•˜ì´ë¸Œë¦¬ë“œ ê°œë°œ**: ë¡œì»¬ í¸ì§‘ + í´ë¼ìš°ë“œ ì‹¤í–‰\n",
    "- **Git í†µí•©**: ì™„ë²½í•œ ë²„ì „ ê´€ë¦¬ ë° í˜‘ì—…  \n",
    "- **ë””ë²„ê¹…**: VS Codeì˜ ê°•ë ¥í•œ ë””ë²„ê¹… ë„êµ¬\n",
    "- **IntelliSense**: ìë™ì™„ì„± ë° ì½”ë“œ ë¶„ì„\n",
    "\n",
    "### ì„¤ì • ë°©ë²•\n",
    "1. VS Codeì—ì„œ \"Databricks\" í™•ì¥ ì„¤ì¹˜\n",
    "2. Databricks ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ì—°ê²° ì„¤ì •\n",
    "3. í´ëŸ¬ìŠ¤í„° ì„ íƒ ë° ì—°ê²°\n",
    "4. ì´ ë…¸íŠ¸ë¶ì„ VS Codeì—ì„œ ì‹¤í–‰\n",
    "   - Text-to-SQL: ìƒ˜í”Œ ìŠ¤í‚¤ë§ˆë§Œ\n",
    "   - Vector Search: ë¡œì»¬ ë²¡í„° DBë§Œ\n",
    "\n",
    "---\n",
    "\n",
    "# RAG ì²´ì¸ êµ¬ì„±\n",
    "print(\"ğŸ”— RAG ì²´ì¸ êµ¬ì„± ì¤‘...\")\n",
    "\n",
    "# 1. Retriever ìƒì„±\n",
    "try:\n",
    "    if 'vector_store' in locals() and vector_store is not None:\n",
    "        retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "        print(\"âœ… Retriever ìƒì„± ì™„ë£Œ\")\n",
    "    else:\n",
    "        print(\"âŒ Vector Storeê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        print(\"ë¨¼ì € Vector Store ì„¤ì • ì…€ì„ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "        raise ValueError(\"Vector Store í•„ìš”\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Retriever ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "    raise\n",
    "\n",
    "# 2. Databricks LLM ëª¨ë¸ ì—°ê²°\n",
    "try:\n",
    "    chat_model = ChatDatabricks(\n",
    "        endpoint=\"databricks-dbrx-instruct\",\n",
    "        max_tokens=500,\n",
    "        temperature=0.1\n",
    "    )\n",
    "    print(\"âœ… Databricks LLM ëª¨ë¸ ì—°ê²° ì™„ë£Œ\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ LLM ëª¨ë¸ ì—°ê²° ì‹¤íŒ¨: {e}\")\n",
    "    raise\n",
    "\n",
    "# 3. RAG ì²´ì¸ êµ¬ì„±\n",
    "try:\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=chat_model,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True\n",
    "    )\n",
    "    print(\"âœ… RAG ì²´ì¸ êµ¬ì„± ì™„ë£Œ\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ RAG ì²´ì¸ êµ¬ì„± ì‹¤íŒ¨: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"ğŸ‰ RAG ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfc9e16",
   "metadata": {},
   "source": [
    "## 6. RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "RAG ì‹œìŠ¤í…œì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abddb101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘...\n",
      "ğŸ“Š í˜„ì¬ RAG ì‹œìŠ¤í…œ ìƒíƒœ:\n",
      "   LLM ì—”ë“œí¬ì¸íŠ¸: âœ… databricks-meta-llama-3-1-405b-instruct\n",
      "   Vector Store: âœ… ì‚¬ìš© ê°€ëŠ¥\n",
      "   RAG ì²´ì¸: âœ… êµ¬ì„±ë¨\n",
      "\n",
      "â“ ì§ˆë¬¸: AI ì—ì´ì „íŠ¸ë€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "------------------------------------------------------------\n",
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23067/107802947.py:73: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = self.retriever.get_relevant_documents(query.get('query', query))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– ë‹µë³€:\n",
      "Vector Search ê²°ê³¼ (LLM ì—†ìŒ):\n",
      "\n",
      "1. C o n c l u s i o n\n",
      "A gen ts mark  a ne w  er a in w orkflo w  aut oma tion,  wher e s y st ems can r eason thr ough ambiguity ,  tak e \n",
      "ac tion acr oss t ools,  and handle multi-st ep task s with a h...\n",
      "\n",
      "2. W h e n  s h o u l d  y o u  \n",
      "b u i l d  a n  a g e n t ?\n",
      "Building agen ts r equir es r e thinking ho w  y our  s y st ems mak e decisions and handle comple xity .  \n",
      "U nlik e con v en tional aut oma t...\n",
      "\n",
      "3. S e l e c t i n g  y o u r  m o d e l s\n",
      "Diff er en t models ha v e diff er en t str engths and tr adeo ffs r ela t ed t o task  comple xity ,  la t enc y ,  and \n",
      "cost.  A s w e â€™ll see in the ne xt se...\n",
      "\n",
      "\n",
      "\n",
      "ğŸ“š ì°¸ì¡° ë¬¸ì„œ (3ê°œ):\n",
      "   1. Unknown (í˜ì´ì§€ N/A)\n",
      "      C o n c l u s i o n\n",
      "A gen ts mark  a ne w  er a in w orkflo w  aut oma tion,  wher e s y st ems can ...\n",
      "   2. Unknown (í˜ì´ì§€ N/A)\n",
      "      W h e n  s h o u l d  y o u  \n",
      "b u i l d  a n  a g e n t ?\n",
      "Building agen ts r equir es r e thinking h...\n",
      "   3. Unknown (í˜ì´ì§€ N/A)\n",
      "      S e l e c t i n g  y o u r  m o d e l s\n",
      "Diff er en t models ha v e diff er en t str engths and tr ad...\n",
      "================================================================================\n",
      "\n",
      "â“ ì§ˆë¬¸: ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì˜ ì¥ì ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "------------------------------------------------------------\n",
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n",
      "ğŸ¤– ë‹µë³€:\n",
      "Vector Search ê²°ê³¼ (LLM ì—†ìŒ):\n",
      "\n",
      "1. A  p r a c t i c a l  â€¨\n",
      "g u i d e  t o  â€¨\n",
      "b u i l d i n g  a g e n t s...\n",
      "\n",
      "2. O r c h e s t r a t i o n\n",
      "With the f ounda tional componen ts in place ,  y ou can consider  or chestr a tion pa tt erns t o enable â€¨\n",
      "y our  agen t t o e x ecut e w orkflo w s e ff ec tiv ely .\n",
      "While ...\n",
      "\n",
      "3. When t o consider  cr ea ting multiple agen ts\n",
      "Our  gener al r ecommenda tion is t o maximiz e a single agen tâ€™ s capabilities fir st.  M or e agen ts can \n",
      "pr o vide in tuitiv e separ a tion o f  conc...\n",
      "\n",
      "\n",
      "\n",
      "ğŸ“š ì°¸ì¡° ë¬¸ì„œ (3ê°œ):\n",
      "   1. Unknown (í˜ì´ì§€ N/A)\n",
      "      A  p r a c t i c a l  â€¨\n",
      "g u i d e  t o  â€¨\n",
      "b u i l d i n g  a g e n t s...\n",
      "   2. Unknown (í˜ì´ì§€ N/A)\n",
      "      O r c h e s t r a t i o n\n",
      "With the f ounda tional componen ts in place ,  y ou can consider  or ches...\n",
      "   3. Unknown (í˜ì´ì§€ N/A)\n",
      "      When t o consider  cr ea ting multiple agen ts\n",
      "Our  gener al r ecommenda tion is t o maximiz e a sin...\n",
      "================================================================================\n",
      "\n",
      "â“ ì§ˆë¬¸: Text-to-SQL ì‹œìŠ¤í…œì˜ êµ¬í˜„ ë°©ë²•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
      "------------------------------------------------------------\n",
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n",
      "ğŸ¤– ë‹µë³€:\n",
      "Vector Search ê²°ê³¼ (LLM ì—†ìŒ):\n",
      "\n",
      "1. A  p r a c t i c a l  â€¨\n",
      "g u i d e  t o  â€¨\n",
      "b u i l d i n g  a g e n t s...\n",
      "\n",
      "2. O r c h e s t r a t i o n\n",
      "With the f ounda tional componen ts in place ,  y ou can consider  or chestr a tion pa tt erns t o enable â€¨\n",
      "y our  agen t t o e x ecut e w orkflo w s e ff ec tiv ely .\n",
      "While ...\n",
      "\n",
      "3. When t o consider  cr ea ting multiple agen ts\n",
      "Our  gener al r ecommenda tion is t o maximiz e a single agen tâ€™ s capabilities fir st.  M or e agen ts can \n",
      "pr o vide in tuitiv e separ a tion o f  conc...\n",
      "\n",
      "\n",
      "\n",
      "ğŸ“š ì°¸ì¡° ë¬¸ì„œ (3ê°œ):\n",
      "   1. Unknown (í˜ì´ì§€ N/A)\n",
      "      A  p r a c t i c a l  â€¨\n",
      "g u i d e  t o  â€¨\n",
      "b u i l d i n g  a g e n t s...\n",
      "   2. Unknown (í˜ì´ì§€ N/A)\n",
      "      O r c h e s t r a t i o n\n",
      "With the f ounda tional componen ts in place ,  y ou can consider  or ches...\n",
      "   3. Unknown (í˜ì´ì§€ N/A)\n",
      "      When t o consider  cr ea ting multiple agen ts\n",
      "Our  gener al r ecommenda tion is t o maximiz e a sin...\n",
      "================================================================================\n",
      "\n",
      "â“ ì§ˆë¬¸: Text-to-SQL ì‹œìŠ¤í…œì˜ êµ¬í˜„ ë°©ë²•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
      "------------------------------------------------------------\n",
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n",
      "ğŸ¤– ë‹µë³€:\n",
      "Vector Search ê²°ê³¼ (LLM ì—†ìŒ):\n",
      "\n",
      "1. I n t r o d u c t i o n\n",
      "L ar ge language models ar e becoming incr easingly  capable o f  handling comple x,  multi-st ep task s.  \n",
      "A dv ances in r easoning,  multimodality ,  and t ool use ha v e unl...\n",
      "\n",
      "2. R u l e s - b a s e d  p r o t e c t i o n s Simple de t erministic measur es (blocklists,  input length limits,  \n",
      "r ege x  filt er s ) t o pr e v en t kno wn thr ea ts lik e pr ohibit ed t erms or  \n",
      "...\n",
      "\n",
      "3. W h e n  s h o u l d  y o u  \n",
      "b u i l d  a n  a g e n t ?\n",
      "Building agen ts r equir es r e thinking ho w  y our  s y st ems mak e decisions and handle comple xity .  \n",
      "U nlik e con v en tional aut oma t...\n",
      "\n",
      "\n",
      "\n",
      "ğŸ“š ì°¸ì¡° ë¬¸ì„œ (3ê°œ):\n",
      "   1. Unknown (í˜ì´ì§€ N/A)\n",
      "      I n t r o d u c t i o n\n",
      "L ar ge language models ar e becoming incr easingly  capable o f  handling c...\n",
      "   2. Unknown (í˜ì´ì§€ N/A)\n",
      "      R u l e s - b a s e d  p r o t e c t i o n s Simple de t erministic measur es (blocklists,  input le...\n",
      "   3. Unknown (í˜ì´ì§€ N/A)\n",
      "      W h e n  s h o u l d  y o u  \n",
      "b u i l d  a n  a g e n t ?\n",
      "Building agen ts r equir es r e thinking h...\n",
      "================================================================================\n",
      "âœ… RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\n",
      "ğŸ¤– ë‹µë³€:\n",
      "Vector Search ê²°ê³¼ (LLM ì—†ìŒ):\n",
      "\n",
      "1. I n t r o d u c t i o n\n",
      "L ar ge language models ar e becoming incr easingly  capable o f  handling comple x,  multi-st ep task s.  \n",
      "A dv ances in r easoning,  multimodality ,  and t ool use ha v e unl...\n",
      "\n",
      "2. R u l e s - b a s e d  p r o t e c t i o n s Simple de t erministic measur es (blocklists,  input length limits,  \n",
      "r ege x  filt er s ) t o pr e v en t kno wn thr ea ts lik e pr ohibit ed t erms or  \n",
      "...\n",
      "\n",
      "3. W h e n  s h o u l d  y o u  \n",
      "b u i l d  a n  a g e n t ?\n",
      "Building agen ts r equir es r e thinking ho w  y our  s y st ems mak e decisions and handle comple xity .  \n",
      "U nlik e con v en tional aut oma t...\n",
      "\n",
      "\n",
      "\n",
      "ğŸ“š ì°¸ì¡° ë¬¸ì„œ (3ê°œ):\n",
      "   1. Unknown (í˜ì´ì§€ N/A)\n",
      "      I n t r o d u c t i o n\n",
      "L ar ge language models ar e becoming incr easingly  capable o f  handling c...\n",
      "   2. Unknown (í˜ì´ì§€ N/A)\n",
      "      R u l e s - b a s e d  p r o t e c t i o n s Simple de t erministic measur es (blocklists,  input le...\n",
      "   3. Unknown (í˜ì´ì§€ N/A)\n",
      "      W h e n  s h o u l d  y o u  \n",
      "b u i l d  a n  a g e n t ?\n",
      "Building agen ts r equir es r e thinking h...\n",
      "================================================================================\n",
      "âœ… RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸\n",
    "print(\"ğŸ§ª RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘...\")\n",
    "\n",
    "def test_rag_system(question):\n",
    "    \"\"\"RAG ì‹œìŠ¤í…œìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€\"\"\"\n",
    "    print(f\"\\nâ“ ì§ˆë¬¸: {question}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # ì „ì—­ ë³€ìˆ˜ ì ‘ê·¼ì„ ìœ„í•´ globals() ì‚¬ìš©\n",
    "    qa_chain = globals().get('qa_chain')\n",
    "    vector_store = globals().get('vector_store')\n",
    "    \n",
    "    # RAG ì²´ì¸ì´ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸\n",
    "    if qa_chain is not None:\n",
    "        try:\n",
    "            # RAG ì²´ì¸ ì‹¤í–‰\n",
    "            result = qa_chain.invoke({\"query\": question})\n",
    "            \n",
    "            # ë‹µë³€ ì¶œë ¥\n",
    "            print(\"ğŸ¤– ë‹µë³€:\")\n",
    "            print(result[\"result\"])\n",
    "            \n",
    "            # ì°¸ì¡° ë¬¸ì„œ ì¶œë ¥\n",
    "            if \"source_documents\" in result:\n",
    "                print(f\"\\nğŸ“š ì°¸ì¡° ë¬¸ì„œ ({len(result['source_documents'])}ê°œ):\")\n",
    "                for i, doc in enumerate(result[\"source_documents\"], 1):\n",
    "                    source = doc.metadata.get(\"source\", \"Unknown\")\n",
    "                    page = doc.metadata.get(\"page\", \"N/A\")\n",
    "                    content_preview = doc.page_content[:100] + \"...\"\n",
    "                    print(f\"   {i}. {source} (í˜ì´ì§€ {page})\")\n",
    "                    print(f\"      {content_preview}\")\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "            if \"ENDPOINT_NOT_FOUND\" in str(e):\n",
    "                print(\"ğŸ’¡ LLM ì—”ë“œí¬ì¸íŠ¸ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. LLM ì—”ë“œí¬ì¸íŠ¸ ë°œê²¬ ì…€ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "            return None\n",
    "    \n",
    "    else:\n",
    "        print(\"âš ï¸ RAG ì²´ì¸ì´ êµ¬ì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        # Vector Searchë§Œìœ¼ë¡œ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰\n",
    "        if vector_store is not None:\n",
    "            try:\n",
    "                print(\"ğŸ” Vector Searchë§Œìœ¼ë¡œ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...\")\n",
    "                similar_docs = vector_store.similarity_search(question, k=3)\n",
    "                \n",
    "                print(f\"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {len(similar_docs)}ê°œ ë¬¸ì„œ\")\n",
    "                for i, doc in enumerate(similar_docs, 1):\n",
    "                    source = doc.metadata.get(\"source\", \"Unknown\")\n",
    "                    page = doc.metadata.get(\"page\", \"N/A\")\n",
    "                    content_preview = doc.page_content[:200] + \"...\"\n",
    "                    print(f\"\\n   {i}. ë¬¸ì„œ: {source} (í˜ì´ì§€ {page})\")\n",
    "                    print(f\"      ë‚´ìš©: {content_preview}\")\n",
    "                \n",
    "                print(f\"\\nğŸ’¡ LLMì´ ì‚¬ìš© ê°€ëŠ¥í•˜ë‹¤ë©´ ì´ ë¬¸ì„œë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "                return {\"documents\": similar_docs}\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Vector Search ì‹¤íŒ¨: {e}\")\n",
    "        else:\n",
    "            print(\"âŒ Vector Storeë„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        return None\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤\n",
    "test_questions = [\n",
    "    \"AI ì—ì´ì „íŠ¸ë€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "    \"ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì˜ ì¥ì ì€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "    \"Text-to-SQL ì‹œìŠ¤í…œì˜ êµ¬í˜„ ë°©ë²•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"\n",
    "]\n",
    "\n",
    "# í˜„ì¬ ìƒíƒœ í™•ì¸ (globals ì‚¬ìš©)\n",
    "llm_endpoint = globals().get('llm_endpoint')\n",
    "vector_store = globals().get('vector_store')\n",
    "qa_chain = globals().get('qa_chain')\n",
    "\n",
    "print(f\"ğŸ“Š í˜„ì¬ RAG ì‹œìŠ¤í…œ ìƒíƒœ:\")\n",
    "print(f\"   LLM ì—”ë“œí¬ì¸íŠ¸: {'âœ… ' + llm_endpoint if llm_endpoint else 'âŒ ì—†ìŒ'}\")\n",
    "print(f\"   Vector Store: {'âœ… ì‚¬ìš© ê°€ëŠ¥' if vector_store else 'âŒ ì—†ìŒ'}\")\n",
    "print(f\"   RAG ì²´ì¸: {'âœ… êµ¬ì„±ë¨' if qa_chain else 'âŒ ë¯¸êµ¬ì„±'}\")\n",
    "\n",
    "# ê° ì§ˆë¬¸ í…ŒìŠ¤íŠ¸\n",
    "for question in test_questions:\n",
    "    test_rag_system(question)\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "print(\"âœ… RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "\n",
    "# í•´ê²° ë°©ë²• ì•ˆë‚´\n",
    "if qa_chain is None:\n",
    "    print(f\"\\nğŸ’¡ RAG ì²´ì¸ ë¬¸ì œ í•´ê²° ë°©ë²•:\")\n",
    "    print(f\"   1. LLM ì—”ë“œí¬ì¸íŠ¸ ë°œê²¬ ì…€ì„ ì‹¤í–‰í•˜ì—¬ ì‚¬ìš© ê°€ëŠ¥í•œ ì—”ë“œí¬ì¸íŠ¸ í™•ì¸\")\n",
    "    print(f\"   2. Databricks ê´€ë¦¬ìì—ê²Œ Foundation Model APIs í™œì„±í™” ìš”ì²­\")\n",
    "    print(f\"   3. Vector Store ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸\")\n",
    "    print(f\"   4. ìœ„ ë¬¸ì œë“¤ì´ í•´ê²°ë˜ë©´ ì´ ì…€ì„ ë‹¤ì‹œ ì‹¤í–‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63e6ab80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” LLM ì—”ë“œí¬ì¸íŠ¸ ë°œê²¬ ë° RAG ì²´ì¸ ì„¤ì •...\n",
      "ğŸ”— RAG ì²´ì¸ êµ¬ì„± ì¤‘ (ì—”ë“œí¬ì¸íŠ¸: databricks-meta-llama-3-1-405b-instruct)...\n",
      "âœ… RAG ì²´ì¸ êµ¬ì„± ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# LLM ì—”ë“œí¬ì¸íŠ¸ ë°œê²¬ ë° RAG ì²´ì¸ ì„¤ì •\n",
    "print(\"ğŸ” LLM ì—”ë“œí¬ì¸íŠ¸ ë°œê²¬ ë° RAG ì²´ì¸ ì„¤ì •...\")\n",
    "\n",
    "# LLM ì—”ë“œí¬ì¸íŠ¸ê°€ ì•„ì§ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš° ì¬ì‹œë„\n",
    "if 'llm_endpoint' not in locals() or not llm_endpoint:\n",
    "    print(\"ğŸ”„ LLM ì—”ë“œí¬ì¸íŠ¸ ì¬ê²€ìƒ‰ ì¤‘...\")\n",
    "    \n",
    "    # ì¼ë°˜ì ì¸ Foundation Model ì—”ë“œí¬ì¸íŠ¸ë“¤\n",
    "    common_endpoints = [\n",
    "        \"databricks-meta-llama-3-1-405b-instruct\",\n",
    "        \"databricks-meta-llama-3-1-70b-instruct\", \n",
    "        \"databricks-meta-llama-3-70b-instruct\",\n",
    "        \"databricks-mixtral-8x7b-instruct\",\n",
    "        \"databricks-dbrx-instruct\"\n",
    "    ]\n",
    "    \n",
    "    available_endpoint = None\n",
    "    working_endpoints = []\n",
    "    \n",
    "    for endpoint_name in common_endpoints:\n",
    "        try:\n",
    "            print(f\"ğŸ“¡ í…ŒìŠ¤íŠ¸ ì¤‘: {endpoint_name}\")\n",
    "            test_model = ChatDatabricks(endpoint=endpoint_name, max_tokens=5)\n",
    "            # ë§¤ìš° ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸\n",
    "            test_response = test_model.invoke(\"Hi\")\n",
    "            working_endpoints.append(endpoint_name)\n",
    "            if available_endpoint is None:\n",
    "                available_endpoint = endpoint_name\n",
    "            print(f\"âœ… ì‚¬ìš© ê°€ëŠ¥: {endpoint_name}\")\n",
    "            break  # ì²« ë²ˆì§¸ ì‘ë™í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ì¤‘ë‹¨\n",
    "        except Exception as e:\n",
    "            if \"ENDPOINT_NOT_FOUND\" in str(e):\n",
    "                print(f\"âŒ ì—”ë“œí¬ì¸íŠ¸ ì—†ìŒ: {endpoint_name}\")\n",
    "            elif \"PERMISSION_DENIED\" in str(e) or \"FORBIDDEN\" in str(e):\n",
    "                print(f\"âš ï¸ ê¶Œí•œ ì—†ìŒ: {endpoint_name}\")\n",
    "            else:\n",
    "                print(f\"âš ï¸ ì—°ê²° ì˜¤ë¥˜: {endpoint_name} - {str(e)[:50]}...\")\n",
    "    \n",
    "    llm_endpoint = available_endpoint\n",
    "    \n",
    "    print(f\"\\nğŸ“Š LLM ì—”ë“œí¬ì¸íŠ¸ í™•ì¸ ê²°ê³¼:\")\n",
    "    if working_endpoints:\n",
    "        print(f\"   âœ… ì‚¬ìš© ê°€ëŠ¥í•œ ì—”ë“œí¬ì¸íŠ¸: {len(working_endpoints)}ê°œ\")\n",
    "        print(f\"   ğŸ¯ ì„ íƒëœ ì—”ë“œí¬ì¸íŠ¸: {llm_endpoint}\")\n",
    "    else:\n",
    "        print(f\"   âŒ ì‚¬ìš© ê°€ëŠ¥í•œ LLM ì—”ë“œí¬ì¸íŠ¸ ì—†ìŒ\")\n",
    "        print(f\"   ğŸ’¡ í•´ê²° ë°©ë²•:\")\n",
    "        print(f\"      1. Databricks ê´€ë¦¬ìì—ê²Œ Foundation Model APIs í™œì„±í™” ìš”ì²­\")\n",
    "        print(f\"      2. ì›Œí¬ìŠ¤í˜ì´ìŠ¤ì—ì„œ Model Serving ê¶Œí•œ í™•ì¸\")\n",
    "        llm_endpoint = None\n",
    "\n",
    "# RAG ì²´ì¸ ì„¤ì •\n",
    "if llm_endpoint and 'vector_store' in locals():\n",
    "    try:\n",
    "        print(f\"ğŸ”— RAG ì²´ì¸ êµ¬ì„± ì¤‘ (ì—”ë“œí¬ì¸íŠ¸: {llm_endpoint})...\")\n",
    "        \n",
    "        # LLM ëª¨ë¸ ìƒì„±\n",
    "        chat_model = ChatDatabricks(\n",
    "            endpoint=llm_endpoint,\n",
    "            max_tokens=500,\n",
    "            temperature=0.1\n",
    "        )\n",
    "        \n",
    "        # ë¦¬íŠ¸ë¦¬ë²„ ìƒì„±\n",
    "        retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "        \n",
    "        # RAG ì²´ì¸ êµ¬ì„±\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=chat_model,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=retriever,\n",
    "            return_source_documents=True\n",
    "        )\n",
    "        \n",
    "        print(\"âœ… RAG ì²´ì¸ êµ¬ì„± ì™„ë£Œ!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ RAG ì²´ì¸ êµ¬ì„± ì‹¤íŒ¨: {e}\")\n",
    "        qa_chain = None\n",
    "        \n",
    "elif not llm_endpoint:\n",
    "    print(\"âš ï¸ LLM ì—”ë“œí¬ì¸íŠ¸ê°€ ì—†ìœ¼ë¯€ë¡œ Vector Searchë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.\")\n",
    "    qa_chain = None\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸ Vector Storeê°€ ì—†ìœ¼ë¯€ë¡œ RAG ì²´ì¸ì„ êµ¬ì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    qa_chain = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09077c1",
   "metadata": {},
   "source": [
    "## 7. ëŒ€í™”í˜• ì§ˆë¬¸ ë‹µë³€\n",
    "\n",
    "ì§ì ‘ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì—¬ RAG ì‹œìŠ¤í…œê³¼ ìƒí˜¸ì‘ìš©í•´ë³´ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5183a894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— RAG ì²´ì¸ êµ¬ì„± ì¤‘...\n",
      "âœ… ì‚¬ìš© ê°€ëŠ¥í•œ LLM ì—”ë“œí¬ì¸íŠ¸: databricks-meta-llama-3-1-405b-instruct\n",
      "âœ… ì™„ì „í•œ RAG ì²´ì¸ êµ¬ì„± ì™„ë£Œ\n",
      "\n",
      "ğŸ’¬ ëŒ€í™”í˜• RAG ì‹œìŠ¤í…œ ì‹œì‘!\n",
      "ì›í•˜ëŠ” ì§ˆë¬¸ì„ ì•„ë˜ ë³€ìˆ˜ì— ì…ë ¥í•˜ê³  ì‹¤í–‰í•˜ì„¸ìš”.\n",
      "\n",
      "â“ ì‚¬ìš©ì ì§ˆë¬¸: AI ì—ì´ì „íŠ¸ì˜ ì£¼ìš” êµ¬ì„± ìš”ì†ŒëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n",
      "ğŸ” ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ ê²€ìƒ‰ ì¤‘...\n",
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n",
      "\n",
      "ğŸ¤– AI ë‹µë³€:\n",
      "============================================================\n",
      "AI ì—ì´ì „íŠ¸ì˜ ì£¼ìš” êµ¬ì„± ìš”ì†ŒëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "1. **Capable models**: ì—ì´ì „íŠ¸ëŠ” ê°•ë ¥í•œ ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬ ë³µì¡í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ëª¨ë¸ì€ ì—ì´ì „íŠ¸ê°€ ì˜ì‚¬ ê²°ì •ì„ ë‚´ë¦¬ê³  ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
      "\n",
      "2. **Well-defined tools**: ì—ì´ì „íŠ¸ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë° í•„ìš”í•œ ë„êµ¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë„êµ¬ëŠ” ì—ì´ì „íŠ¸ê°€ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë° í•„ìš”í•œ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
      "\n",
      "3. **Clear, structured instructions**: ì—ì´ì „íŠ¸ëŠ” ëª…í™•í•˜ê³  êµ¬ì¡°í™”ëœ ì§€ì¹¨ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì§€ì¹¨ì€ ì—ì´ì „íŠ¸ê°€ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë° í•„ìš”í•œ ë‹¨ê³„ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
      "\n",
      "4. **Orchestration patterns**: ì—ì´ì „íŠ¸ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë° í•„ìš”í•œ ë‹¨ê³„ë¥¼ ì¡°ì •í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ íŒ¨í„´ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ íŒ¨\n",
      "============================================================\n",
      "\n",
      "ğŸ“– ì°¸ì¡°ëœ ë¬¸ì„œ ì •ë³´:\n",
      "   1. ë¬¸ì„œ: Unknown, í˜ì´ì§€: N/A\n",
      "      ë‚´ìš©: C o n c l u s i o n\n",
      "A gen ts mark  a ne w  er a in w orkflo w  aut oma tion,  wher e s y st ems can ...\n",
      "   2. ë¬¸ì„œ: Unknown, í˜ì´ì§€: N/A\n",
      "      ë‚´ìš©: W h e n  s h o u l d  y o u  \n",
      "b u i l d  a n  a g e n t ?\n",
      "Building agen ts r equir es r e thinking h...\n",
      "   3. ë¬¸ì„œ: Unknown, í˜ì´ì§€: N/A\n",
      "      ë‚´ìš©: S e l e c t i n g  y o u r  m o d e l s\n",
      "Diff er en t models ha v e diff er en t str engths and tr ad...\n",
      "\n",
      "âœ… ë‹µë³€ ì™„ë£Œ!\n",
      "\n",
      "ğŸ’¡ ë‹¤ë¥¸ ì§ˆë¬¸ì„ í•˜ë ¤ë©´ 'user_question' ë³€ìˆ˜ë¥¼ ìˆ˜ì •í•˜ê³  ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.\n",
      "ğŸ‰ RAG ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤!\n",
      "\n",
      "ğŸ¤– AI ë‹µë³€:\n",
      "============================================================\n",
      "AI ì—ì´ì „íŠ¸ì˜ ì£¼ìš” êµ¬ì„± ìš”ì†ŒëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "1. **Capable models**: ì—ì´ì „íŠ¸ëŠ” ê°•ë ¥í•œ ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬ ë³µì¡í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ëª¨ë¸ì€ ì—ì´ì „íŠ¸ê°€ ì˜ì‚¬ ê²°ì •ì„ ë‚´ë¦¬ê³  ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
      "\n",
      "2. **Well-defined tools**: ì—ì´ì „íŠ¸ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë° í•„ìš”í•œ ë„êµ¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë„êµ¬ëŠ” ì—ì´ì „íŠ¸ê°€ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë° í•„ìš”í•œ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
      "\n",
      "3. **Clear, structured instructions**: ì—ì´ì „íŠ¸ëŠ” ëª…í™•í•˜ê³  êµ¬ì¡°í™”ëœ ì§€ì¹¨ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì§€ì¹¨ì€ ì—ì´ì „íŠ¸ê°€ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë° í•„ìš”í•œ ë‹¨ê³„ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
      "\n",
      "4. **Orchestration patterns**: ì—ì´ì „íŠ¸ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë° í•„ìš”í•œ ë‹¨ê³„ë¥¼ ì¡°ì •í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ íŒ¨í„´ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ íŒ¨\n",
      "============================================================\n",
      "\n",
      "ğŸ“– ì°¸ì¡°ëœ ë¬¸ì„œ ì •ë³´:\n",
      "   1. ë¬¸ì„œ: Unknown, í˜ì´ì§€: N/A\n",
      "      ë‚´ìš©: C o n c l u s i o n\n",
      "A gen ts mark  a ne w  er a in w orkflo w  aut oma tion,  wher e s y st ems can ...\n",
      "   2. ë¬¸ì„œ: Unknown, í˜ì´ì§€: N/A\n",
      "      ë‚´ìš©: W h e n  s h o u l d  y o u  \n",
      "b u i l d  a n  a g e n t ?\n",
      "Building agen ts r equir es r e thinking h...\n",
      "   3. ë¬¸ì„œ: Unknown, í˜ì´ì§€: N/A\n",
      "      ë‚´ìš©: S e l e c t i n g  y o u r  m o d e l s\n",
      "Diff er en t models ha v e diff er en t str engths and tr ad...\n",
      "\n",
      "âœ… ë‹µë³€ ì™„ë£Œ!\n",
      "\n",
      "ğŸ’¡ ë‹¤ë¥¸ ì§ˆë¬¸ì„ í•˜ë ¤ë©´ 'user_question' ë³€ìˆ˜ë¥¼ ìˆ˜ì •í•˜ê³  ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.\n",
      "ğŸ‰ RAG ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "# LLM ëª¨ë¸ ë° RAG ì²´ì¸ êµ¬ì„±\n",
    "print(\"ğŸ”— RAG ì²´ì¸ êµ¬ì„± ì¤‘...\")\n",
    "\n",
    "try:\n",
    "    # 1. ì‚¬ìš© ê°€ëŠ¥í•œ LLM ì—”ë“œí¬ì¸íŠ¸ í™•ì¸\n",
    "    if 'llm_endpoint' in locals() and llm_endpoint:\n",
    "        print(f\"âœ… ì‚¬ìš© ê°€ëŠ¥í•œ LLM ì—”ë“œí¬ì¸íŠ¸: {llm_endpoint}\")\n",
    "        \n",
    "        # 2. LLM ëª¨ë¸ ìƒì„±\n",
    "        chat_model = ChatDatabricks(endpoint=llm_endpoint, max_tokens=200)\n",
    "        \n",
    "        # 3. ë²¡í„° ê²€ìƒ‰ ë¦¬íŠ¸ë¦¬ë²„ ìƒì„±\n",
    "        retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "        \n",
    "        # 4. RAG ì²´ì¸ êµ¬ì„±\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=chat_model,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=retriever,\n",
    "            return_source_documents=True\n",
    "        )\n",
    "        \n",
    "        print(\"âœ… ì™„ì „í•œ RAG ì²´ì¸ êµ¬ì„± ì™„ë£Œ\")\n",
    "        \n",
    "        # ëŒ€í™”í˜• ì§ˆë¬¸ ë‹µë³€\n",
    "        print(\"\\nğŸ’¬ ëŒ€í™”í˜• RAG ì‹œìŠ¤í…œ ì‹œì‘!\")\n",
    "        print(\"ì›í•˜ëŠ” ì§ˆë¬¸ì„ ì•„ë˜ ë³€ìˆ˜ì— ì…ë ¥í•˜ê³  ì‹¤í–‰í•˜ì„¸ìš”.\\n\")\n",
    "\n",
    "        # ì—¬ê¸°ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”\n",
    "        user_question = \"AI ì—ì´ì „íŠ¸ì˜ ì£¼ìš” êµ¬ì„± ìš”ì†ŒëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "\n",
    "        # ì§ˆë¬¸ ì²˜ë¦¬\n",
    "        if user_question.strip():\n",
    "            print(f\"â“ ì‚¬ìš©ì ì§ˆë¬¸: {user_question}\")\n",
    "            print(\"ğŸ” ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ ê²€ìƒ‰ ì¤‘...\")\n",
    "            \n",
    "            try:\n",
    "                # RAG ì²´ì¸ ì‹¤í–‰\n",
    "                response = qa_chain.invoke({\"query\": user_question})\n",
    "                \n",
    "                print(\"\\nğŸ¤– AI ë‹µë³€:\")\n",
    "                print(\"=\" * 60)\n",
    "                print(response[\"result\"])\n",
    "                print(\"=\" * 60)\n",
    "                \n",
    "                # ê²€ìƒ‰ëœ ë¬¸ì„œ ì •ë³´\n",
    "                if \"source_documents\" in response and response[\"source_documents\"]:\n",
    "                    print(f\"\\nğŸ“– ì°¸ì¡°ëœ ë¬¸ì„œ ì •ë³´:\")\n",
    "                    for i, doc in enumerate(response[\"source_documents\"], 1):\n",
    "                        source = doc.metadata.get(\"source\", \"Unknown\")\n",
    "                        page = doc.metadata.get(\"page\", \"N/A\")\n",
    "                        print(f\"   {i}. ë¬¸ì„œ: {source}, í˜ì´ì§€: {page}\")\n",
    "                        # Show a snippet of the content\n",
    "                        content_preview = doc.page_content[:100] + \"...\"\n",
    "                        print(f\"      ë‚´ìš©: {content_preview}\")\n",
    "                \n",
    "                print(f\"\\nâœ… ë‹µë³€ ì™„ë£Œ!\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "                print(\"Vector Search ì¸ë±ìŠ¤ê°€ ì¤€ë¹„ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "                \n",
    "        else:\n",
    "            print(\"â“ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.\")\n",
    "            \n",
    "        print(\"\\nğŸ’¡ ë‹¤ë¥¸ ì§ˆë¬¸ì„ í•˜ë ¤ë©´ 'user_question' ë³€ìˆ˜ë¥¼ ìˆ˜ì •í•˜ê³  ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "        print(\"ğŸ‰ RAG ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤!\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ ì‚¬ìš© ê°€ëŠ¥í•œ LLM ì—”ë“œí¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        print(\"ğŸ’¡ í•´ê²° ë°©ë²•:\")\n",
    "        print(\"   1. Databricks ê´€ë¦¬ìì—ê²Œ Foundation Model APIs í™œì„±í™” ìš”ì²­\")\n",
    "        print(\"   2. ì›Œí¬ìŠ¤í˜ì´ìŠ¤ì—ì„œ Model Serving ê¶Œí•œ í™•ì¸\")\n",
    "        print(\"   3. LLM ì—”ë“œí¬ì¸íŠ¸ ë””ìŠ¤ì»¤ë²„ë¦¬ ì…€ì„ ë‹¤ì‹œ ì‹¤í–‰\")\n",
    "        \n",
    "        # Vector Searchë§Œìœ¼ë¡œ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ ì˜ˆì‹œ\n",
    "        print(\"\\nğŸ” Vector Searchë§Œìœ¼ë¡œ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ ì˜ˆì‹œ:\")\n",
    "        user_question = \"ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”\"\n",
    "        if user_question.strip():\n",
    "            similar_docs = vector_store.similarity_search(user_question, k=3)\n",
    "            print(f\"â“ ê²€ìƒ‰ì–´: {user_question}\")\n",
    "            print(f\"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {len(similar_docs)}ê°œ ë¬¸ì„œ\")\n",
    "            for i, doc in enumerate(similar_docs, 1):\n",
    "                source = doc.metadata.get(\"source\", \"Unknown\")\n",
    "                page = doc.metadata.get(\"page\", \"N/A\")\n",
    "                content_preview = doc.page_content[:200] + \"...\"\n",
    "                print(f\"\\n   {i}. ë¬¸ì„œ: {source} (í˜ì´ì§€ {page})\")\n",
    "                print(f\"      ë‚´ìš©: {content_preview}\")\n",
    "                \n",
    "except Exception as e:\n",
    "    print(f\"âŒ RAG ì²´ì¸ êµ¬ì„± ì‹¤íŒ¨: {e}\")\n",
    "    print(\"Vector Storeë‚˜ LLM ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85250818",
   "metadata": {},
   "source": [
    "## 8. ê³ ê¸‰ ê¸°ëŠ¥: ë²¡í„° ê²€ìƒ‰ ì§ì ‘ ì‚¬ìš©\n",
    "\n",
    "Vector Storeë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ìœ ì‚¬ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc815f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ë²¡í„° ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\n",
      "\n",
      "ğŸ” ê²€ìƒ‰ì–´: 'ì¸ê³µì§€ëŠ¥ ì—ì´ì „íŠ¸'\n",
      "--------------------------------------------------\n",
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n",
      "ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: 2ê°œ ë¬¸ì„œ\n",
      "\n",
      "   1. ë¬¸ì„œ: Unknown (í˜ì´ì§€ N/A)\n",
      "      ë‚´ìš©: A  p r a c t i c a l  â€¨\n",
      "g u i d e  t o  â€¨\n",
      "b u i l d i n g  a g e n t s...\n",
      "\n",
      "   2. ë¬¸ì„œ: Unknown (í˜ì´ì§€ N/A)\n",
      "      ë‚´ìš©: O r c h e s t r a t i o n\n",
      "With the f ounda tional componen ts in place ,  y ou can consider  or chestr a tion pa tt erns t o enable â€¨\n",
      "y our  agen t t o e x ecut e w orkflo w s e ff ec tiv ely .\n",
      "While ...\n",
      "\n",
      "ğŸ” ê²€ìƒ‰ì–´: 'ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸'\n",
      "--------------------------------------------------\n",
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n",
      "ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: 2ê°œ ë¬¸ì„œ\n",
      "\n",
      "   1. ë¬¸ì„œ: Unknown (í˜ì´ì§€ N/A)\n",
      "      ë‚´ìš©: A  p r a c t i c a l  â€¨\n",
      "g u i d e  t o  â€¨\n",
      "b u i l d i n g  a g e n t s...\n",
      "\n",
      "   2. ë¬¸ì„œ: Unknown (í˜ì´ì§€ N/A)\n",
      "      ë‚´ìš©: O r c h e s t r a t i o n\n",
      "With the f ounda tional componen ts in place ,  y ou can consider  or chestr a tion pa tt erns t o enable â€¨\n",
      "y our  agen t t o e x ecut e w orkflo w s e ff ec tiv ely .\n",
      "While ...\n",
      "\n",
      "ğŸ” ê²€ìƒ‰ì–´: 'ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸'\n",
      "--------------------------------------------------\n",
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n",
      "ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: 2ê°œ ë¬¸ì„œ\n",
      "\n",
      "   1. ë¬¸ì„œ: Unknown (í˜ì´ì§€ N/A)\n",
      "      ë‚´ìš©: A  p r a c t i c a l  â€¨\n",
      "g u i d e  t o  â€¨\n",
      "b u i l d i n g  a g e n t s...\n",
      "\n",
      "   2. ë¬¸ì„œ: Unknown (í˜ì´ì§€ N/A)\n",
      "      ë‚´ìš©: O r c h e s t r a t i o n\n",
      "With the f ounda tional componen ts in place ,  y ou can consider  or chestr a tion pa tt erns t o enable â€¨\n",
      "y our  agen t t o e x ecut e w orkflo w s e ff ec tiv ely .\n",
      "While ...\n",
      "\n",
      "ğŸ” ê²€ìƒ‰ì–´: 'ë°ì´í„°ë² ì´ìŠ¤ ì‹œìŠ¤í…œ'\n",
      "--------------------------------------------------\n",
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n",
      "ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: 2ê°œ ë¬¸ì„œ\n",
      "\n",
      "   1. ë¬¸ì„œ: Unknown (í˜ì´ì§€ N/A)\n",
      "      ë‚´ìš©: A  p r a c t i c a l  â€¨\n",
      "g u i d e  t o  â€¨\n",
      "b u i l d i n g  a g e n t s...\n",
      "\n",
      "   2. ë¬¸ì„œ: Unknown (í˜ì´ì§€ N/A)\n",
      "      ë‚´ìš©: O r c h e s t r a t i o n\n",
      "With the f ounda tional componen ts in place ,  y ou can consider  or chestr a tion pa tt erns t o enable â€¨\n",
      "y our  agen t t o e x ecut e w orkflo w s e ff ec tiv ely .\n",
      "While ...\n",
      "\n",
      "ğŸ” ê²€ìƒ‰ì–´: 'ë°ì´í„°ë² ì´ìŠ¤ ì‹œìŠ¤í…œ'\n",
      "--------------------------------------------------\n",
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n",
      "ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: 2ê°œ ë¬¸ì„œ\n",
      "\n",
      "   1. ë¬¸ì„œ: Unknown (í˜ì´ì§€ N/A)\n",
      "      ë‚´ìš©: A  p r a c t i c a l  â€¨\n",
      "g u i d e  t o  â€¨\n",
      "b u i l d i n g  a g e n t s...\n",
      "\n",
      "   2. ë¬¸ì„œ: Unknown (í˜ì´ì§€ N/A)\n",
      "      ë‚´ìš©: O r c h e s t r a t i o n\n",
      "With the f ounda tional componen ts in place ,  y ou can consider  or chestr a tion pa tt erns t o enable â€¨\n",
      "y our  agen t t o e x ecut e w orkflo w s e ff ec tiv ely .\n",
      "While ...\n",
      "\n",
      "âœ… ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\n",
      "ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: 2ê°œ ë¬¸ì„œ\n",
      "\n",
      "   1. ë¬¸ì„œ: Unknown (í˜ì´ì§€ N/A)\n",
      "      ë‚´ìš©: A  p r a c t i c a l  â€¨\n",
      "g u i d e  t o  â€¨\n",
      "b u i l d i n g  a g e n t s...\n",
      "\n",
      "   2. ë¬¸ì„œ: Unknown (í˜ì´ì§€ N/A)\n",
      "      ë‚´ìš©: O r c h e s t r a t i o n\n",
      "With the f ounda tional componen ts in place ,  y ou can consider  or chestr a tion pa tt erns t o enable â€¨\n",
      "y our  agen t t o e x ecut e w orkflo w s e ff ec tiv ely .\n",
      "While ...\n",
      "\n",
      "âœ… ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\n",
      "\n",
      "ğŸ“ˆ ê²€ìƒ‰ ë°ì´í„°ë² ì´ìŠ¤ í†µê³„:\n",
      "   ì´ ì²­í¬ ìˆ˜: 54\n",
      "   ì¸ë±ìŠ¤ ì´ë¦„: workspace.default.rag_docs_index_vscode\n",
      "   ì„ë² ë”© ëª¨ë¸: databricks-bge-large-en\n",
      "\n",
      "ğŸ“ˆ ê²€ìƒ‰ ë°ì´í„°ë² ì´ìŠ¤ í†µê³„:\n",
      "   ì´ ì²­í¬ ìˆ˜: 54\n",
      "   ì¸ë±ìŠ¤ ì´ë¦„: workspace.default.rag_docs_index_vscode\n",
      "   ì„ë² ë”© ëª¨ë¸: databricks-bge-large-en\n"
     ]
    }
   ],
   "source": [
    "# ë²¡í„° ê²€ìƒ‰ ì§ì ‘ ì‚¬ìš© ì˜ˆì‹œ\n",
    "print(\"ğŸ” ë²¡í„° ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸\")\n",
    "\n",
    "# ê²€ìƒ‰í•  ì¿¼ë¦¬\n",
    "search_queries = [\n",
    "    \"ì¸ê³µì§€ëŠ¥ ì—ì´ì „íŠ¸\",\n",
    "    \"ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸\",\n",
    "    \"ë°ì´í„°ë² ì´ìŠ¤ ì‹œìŠ¤í…œ\"\n",
    "]\n",
    "\n",
    "for query in search_queries:\n",
    "    print(f\"\\nğŸ” ê²€ìƒ‰ì–´: '{query}'\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # ìœ ì‚¬ë„ ê²€ìƒ‰\n",
    "        similar_docs = vector_store.similarity_search(\n",
    "            query=query,\n",
    "            k=2  # ìƒìœ„ 2ê°œ ê²°ê³¼ë§Œ\n",
    "        )\n",
    "        \n",
    "        print(f\"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {len(similar_docs)}ê°œ ë¬¸ì„œ\")\n",
    "        \n",
    "        for i, doc in enumerate(similar_docs, 1):\n",
    "            source = doc.metadata.get(\"source\", \"Unknown\")\n",
    "            page = doc.metadata.get(\"page\", \"N/A\")\n",
    "            content_preview = doc.page_content[:200] + \"...\"\n",
    "            \n",
    "            print(f\"\\n   {i}. ë¬¸ì„œ: {source} (í˜ì´ì§€ {page})\")\n",
    "            print(f\"      ë‚´ìš©: {content_preview}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "print(\"\\nâœ… ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "\n",
    "# ê²€ìƒ‰ í†µê³„\n",
    "try:\n",
    "    total_chunks = spark.sql(f\"SELECT COUNT(*) FROM {source_table_name}\").collect()[0][0]\n",
    "    print(f\"\\nğŸ“ˆ ê²€ìƒ‰ ë°ì´í„°ë² ì´ìŠ¤ í†µê³„:\")\n",
    "    print(f\"   ì´ ì²­í¬ ìˆ˜: {total_chunks}\")\n",
    "    print(f\"   ì¸ë±ìŠ¤ ì´ë¦„: {index_name}\")\n",
    "    print(f\"   ì„ë² ë”© ëª¨ë¸: databricks-bge-large-en\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d70fdb",
   "metadata": {},
   "source": [
    "## 9. ìš”ì•½ ë° ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œ êµ¬í˜„í•œ RAG ì‹œìŠ¤í…œì˜ ìš”ì•½ê³¼ í™•ì¥ ê°€ëŠ¥í•œ ê¸°ëŠ¥ë“¤ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78c5ffd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n",
      "--- ë‹µë³€ ---\n",
      "It seems like you're asking me to tell you about your document. ğŸ˜Š\n",
      "\n",
      "From what I can see, your document appears to be a guide to building agents, specifically focusing on orchestration patterns. It discusses the importance of taking an incremental approach to building autonomous agents and introduces two categories of orchestration patterns: single-agent systems and multi-agent systems.\n",
      "\n",
      "The document also mentions the challenges of using specialized domain-specific languages and how the Agents SDK adopts a more flexible, code-first approach, allowing developers to express workflow logic using familiar programming constructs.\n",
      "\n",
      "Is there anything specific you'd like to know about your document or would you like me to elaborate on any of these points? ğŸ¤”\n",
      "ğŸ“‹ RAG ì‹œìŠ¤í…œ êµ¬í˜„ ìš”ì•½\n",
      "============================================================\n",
      "ğŸ”§ ì‹œìŠ¤í…œ êµ¬ì„± ìš”ì†Œ:\n",
      "   âœ… í™˜ê²½: vscode_databricks\n",
      "   âœ… Vector Search í´ë¼ì´ì–¸íŠ¸: ì—°ê²°ë¨\n",
      "   âœ… Vector Search ì¸ë±ìŠ¤: workspace.default.rag_docs_index_vscode\n",
      "   âœ… ì†ŒìŠ¤ í…Œì´ë¸”: workspace.default.rag_documents_vscode\n",
      "   âœ… ì„ë² ë”© ëª¨ë¸: databricks-bge-large-en\n",
      "   âœ… Vector Store: ìƒì„±ë¨\n",
      "   âœ… LLM ëª¨ë¸: databricks-dbrx-instruct\n",
      "   âœ… RAG ì²´ì¸: êµ¬ì„±ë¨\n",
      "--- ë‹µë³€ ---\n",
      "It seems like you're asking me to tell you about your document. ğŸ˜Š\n",
      "\n",
      "From what I can see, your document appears to be a guide to building agents, specifically focusing on orchestration patterns. It discusses the importance of taking an incremental approach to building autonomous agents and introduces two categories of orchestration patterns: single-agent systems and multi-agent systems.\n",
      "\n",
      "The document also mentions the challenges of using specialized domain-specific languages and how the Agents SDK adopts a more flexible, code-first approach, allowing developers to express workflow logic using familiar programming constructs.\n",
      "\n",
      "Is there anything specific you'd like to know about your document or would you like me to elaborate on any of these points? ğŸ¤”\n",
      "ğŸ“‹ RAG ì‹œìŠ¤í…œ êµ¬í˜„ ìš”ì•½\n",
      "============================================================\n",
      "ğŸ”§ ì‹œìŠ¤í…œ êµ¬ì„± ìš”ì†Œ:\n",
      "   âœ… í™˜ê²½: vscode_databricks\n",
      "   âœ… Vector Search í´ë¼ì´ì–¸íŠ¸: ì—°ê²°ë¨\n",
      "   âœ… Vector Search ì¸ë±ìŠ¤: workspace.default.rag_docs_index_vscode\n",
      "   âœ… ì†ŒìŠ¤ í…Œì´ë¸”: workspace.default.rag_documents_vscode\n",
      "   âœ… ì„ë² ë”© ëª¨ë¸: databricks-bge-large-en\n",
      "   âœ… Vector Store: ìƒì„±ë¨\n",
      "   âœ… LLM ëª¨ë¸: databricks-dbrx-instruct\n",
      "   âœ… RAG ì²´ì¸: êµ¬ì„±ë¨\n",
      "\n",
      "ğŸ“Š ë°ì´í„° í†µê³„:\n",
      "   ì´ ì²­í¬ ìˆ˜: 54\n",
      "\n",
      "ğŸ“Š ë°ì´í„° í†µê³„:\n",
      "   ì´ ì²­í¬ ìˆ˜: 54\n",
      "   ë¬¸ì„œë³„ ì²­í¬ ìˆ˜:\n",
      "      â€¢ ./data/pdf/a-practical-guide-to-building-agents.pdf: <built-in method count of Row object at 0x7f92285b0c70>ê°œ\n",
      "\n",
      "ğŸ¯ ì£¼ìš” ì„±ê³¼:\n",
      "   âœ… VS Code + Databricks Extension í™˜ê²½ êµ¬ì„±\n",
      "   âœ… PDF ë¬¸ì„œ ì²˜ë¦¬ ë° ì²­í‚¹\n",
      "   âœ… Databricks Vector Search ì¸ë±ìŠ¤ ìƒì„±\n",
      "   âœ… Databricks LLM ì—°ë™\n",
      "   âœ… ì™„ì „í•œ RAG ì‹œìŠ¤í…œ êµ¬í˜„\n",
      "\n",
      "ğŸš€ í™•ì¥ ê°€ëŠ¥í•œ ê¸°ëŠ¥:\n",
      "   â€¢ ë‹¤ì¤‘ ë¬¸ì„œ ì—…ë¡œë“œ ë° ì²˜ë¦¬\n",
      "   â€¢ ì‹¤ì‹œê°„ ë¬¸ì„œ ì—…ë°ì´íŠ¸\n",
      "   â€¢ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ ê°œë°œ\n",
      "   â€¢ Text-to-SQL ê¸°ëŠ¥ ì¶”ê°€\n",
      "   â€¢ ì±„íŒ… íˆìŠ¤í† ë¦¬ ê´€ë¦¬\n",
      "   â€¢ ì‘ë‹µ í’ˆì§ˆ ê°œì„ \n",
      "\n",
      "ğŸ’¡ ê°œë°œ í™˜ê²½ ì¥ì :\n",
      "   ğŸ”¥ ë¡œì»¬ í¸ì§‘ + í´ë¼ìš°ë“œ ì‹¤í–‰\n",
      "   ğŸ”¥ Gitì„ í†µí•œ ë²„ì „ ê´€ë¦¬\n",
      "   ğŸ”¥ ëª¨ë“  Databricks ê¸°ëŠ¥ ì‚¬ìš©\n",
      "   ğŸ”¥ ì‹¤ì‹œê°„ í˜‘ì—… ê°€ëŠ¥\n",
      "\n",
      "âœ… RAG ì‹œìŠ¤í…œ êµ¬í˜„ ì™„ë£Œ!\n",
      "\n",
      "ğŸ§ª RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸:\n",
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n",
      "   ë¬¸ì„œë³„ ì²­í¬ ìˆ˜:\n",
      "      â€¢ ./data/pdf/a-practical-guide-to-building-agents.pdf: <built-in method count of Row object at 0x7f92285b0c70>ê°œ\n",
      "\n",
      "ğŸ¯ ì£¼ìš” ì„±ê³¼:\n",
      "   âœ… VS Code + Databricks Extension í™˜ê²½ êµ¬ì„±\n",
      "   âœ… PDF ë¬¸ì„œ ì²˜ë¦¬ ë° ì²­í‚¹\n",
      "   âœ… Databricks Vector Search ì¸ë±ìŠ¤ ìƒì„±\n",
      "   âœ… Databricks LLM ì—°ë™\n",
      "   âœ… ì™„ì „í•œ RAG ì‹œìŠ¤í…œ êµ¬í˜„\n",
      "\n",
      "ğŸš€ í™•ì¥ ê°€ëŠ¥í•œ ê¸°ëŠ¥:\n",
      "   â€¢ ë‹¤ì¤‘ ë¬¸ì„œ ì—…ë¡œë“œ ë° ì²˜ë¦¬\n",
      "   â€¢ ì‹¤ì‹œê°„ ë¬¸ì„œ ì—…ë°ì´íŠ¸\n",
      "   â€¢ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ ê°œë°œ\n",
      "   â€¢ Text-to-SQL ê¸°ëŠ¥ ì¶”ê°€\n",
      "   â€¢ ì±„íŒ… íˆìŠ¤í† ë¦¬ ê´€ë¦¬\n",
      "   â€¢ ì‘ë‹µ í’ˆì§ˆ ê°œì„ \n",
      "\n",
      "ğŸ’¡ ê°œë°œ í™˜ê²½ ì¥ì :\n",
      "   ğŸ”¥ ë¡œì»¬ í¸ì§‘ + í´ë¼ìš°ë“œ ì‹¤í–‰\n",
      "   ğŸ”¥ Gitì„ í†µí•œ ë²„ì „ ê´€ë¦¬\n",
      "   ğŸ”¥ ëª¨ë“  Databricks ê¸°ëŠ¥ ì‚¬ìš©\n",
      "   ğŸ”¥ ì‹¤ì‹œê°„ í˜‘ì—… ê°€ëŠ¥\n",
      "\n",
      "âœ… RAG ì‹œìŠ¤í…œ êµ¬í˜„ ì™„ë£Œ!\n",
      "\n",
      "ğŸ§ª RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸:\n",
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n",
      "â“ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸: ë¬¸ì„œì— ëŒ€í•´ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”\n",
      "ğŸ¤– ë‹µë³€: ì´ ë¬¸ì„œëŠ” ì—ì´ì „íŠ¸ë¥¼ êµ¬ì¶•í•˜ëŠ” ì‹¤ìš©ì ì¸ ê°€ì´ë“œì…ë‹ˆë‹¤. ì—ì´ì „íŠ¸ì˜ ê¸°ë³¸ êµ¬ì„± ìš”ì†Œë¥¼ êµ¬ì¶•í•œ í›„, ì›Œí¬í”Œë¡œìš°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ íŒ¨í„´ì„ ê³ ë ¤í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤. ë¬¸ì„œëŠ” ë‹¨ì¼ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œê³¼ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ ë‘ ê°€ì§€ ìœ í˜•ì˜ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ íŒ¨í„´ì„ ì†Œê°œí•˜ê³ , ì—ì´ì „íŠ¸ê°€ ì¶”ê°€í•  ìˆ˜ ìˆëŠ” ê°€ì¹˜ë¥¼ í‰ê°€í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤. ...\n",
      "ğŸ‰ RAG ì‹œìŠ¤í…œ ì„±ê³µì  í•´ê²° ì™„ë£Œ!\n",
      "============================================================\n",
      "âœ… RAG ì²´ì¸ì´ ì„±ê³µì ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤!\n",
      "\n",
      "ğŸ§ª ìµœì¢… í…ŒìŠ¤íŠ¸ ì§ˆë¬¸: ë¬¸ì„œì— ëŒ€í•´ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”\n",
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n",
      "â“ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸: ë¬¸ì„œì— ëŒ€í•´ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”\n",
      "ğŸ¤– ë‹µë³€: ì´ ë¬¸ì„œëŠ” ì—ì´ì „íŠ¸ë¥¼ êµ¬ì¶•í•˜ëŠ” ì‹¤ìš©ì ì¸ ê°€ì´ë“œì…ë‹ˆë‹¤. ì—ì´ì „íŠ¸ì˜ ê¸°ë³¸ êµ¬ì„± ìš”ì†Œë¥¼ êµ¬ì¶•í•œ í›„, ì›Œí¬í”Œë¡œìš°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ íŒ¨í„´ì„ ê³ ë ¤í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤. ë¬¸ì„œëŠ” ë‹¨ì¼ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œê³¼ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ ë‘ ê°€ì§€ ìœ í˜•ì˜ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ íŒ¨í„´ì„ ì†Œê°œí•˜ê³ , ì—ì´ì „íŠ¸ê°€ ì¶”ê°€í•  ìˆ˜ ìˆëŠ” ê°€ì¹˜ë¥¼ í‰ê°€í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤. ...\n",
      "ğŸ‰ RAG ì‹œìŠ¤í…œ ì„±ê³µì  í•´ê²° ì™„ë£Œ!\n",
      "============================================================\n",
      "âœ… RAG ì²´ì¸ì´ ì„±ê³µì ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤!\n",
      "\n",
      "ğŸ§ª ìµœì¢… í…ŒìŠ¤íŠ¸ ì§ˆë¬¸: ë¬¸ì„œì— ëŒ€í•´ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”\n",
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n",
      "âœ… ë‹µë³€ ìƒì„± ì„±ê³µ!\n",
      "ğŸ¤– ë‹µë³€ ë¯¸ë¦¬ë³´ê¸°: ì´ ë¬¸ì„œëŠ” ì—ì´ì „íŠ¸ë¥¼ êµ¬ì¶•í•˜ëŠ” ì‹¤ìš©ì ì¸ ê°€ì´ë“œì…ë‹ˆë‹¤. ì—ì´ì „íŠ¸ì˜ ê¸°ë³¸ êµ¬ì„± ìš”ì†Œë¥¼ êµ¬ì¶•í•œ í›„, ì›Œí¬í”Œë¡œìš°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ íŒ¨í„´ì„ ê³ ë ¤í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤. ë¬¸ì„œëŠ” ë‹¨ì¼ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œê³¼ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ ë‘ ê°€ì§€ ìœ í˜•ì˜ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´...\n",
      "ğŸ“š ì°¸ì¡° ë¬¸ì„œ: 3ê°œ\n",
      "\n",
      "ğŸ“‹ RAG ì‹œìŠ¤í…œ êµ¬í˜„ ì™„ë£Œ ìš”ì•½\n",
      "============================================================\n",
      "ğŸ”§ ì‹œìŠ¤í…œ êµ¬ì„± ìš”ì†Œ:\n",
      "   âœ… í™˜ê²½: vscode_databricks\n",
      "   âœ… Vector Search í´ë¼ì´ì–¸íŠ¸: ì—°ê²°ë¨\n",
      "   âœ… Vector Search ì¸ë±ìŠ¤: workspace.default.rag_docs_index_vscode\n",
      "   âœ… ì†ŒìŠ¤ í…Œì´ë¸”: workspace.default.rag_documents_vscode\n",
      "   âœ… ì„ë² ë”© ëª¨ë¸: databricks-bge-large-en\n",
      "   âœ… Vector Store: ìƒì„±ë¨\n",
      "   âœ… LLM ëª¨ë¸: databricks-meta-llama-3-1-405b-instruct\n",
      "   âœ… RAG ì²´ì¸: êµ¬ì„±ë¨\n",
      "\n",
      "ğŸ”§ í•´ê²°ëœ ë¬¸ì œë“¤:\n",
      "   âœ… LLM ì—”ë“œí¬ì¸íŠ¸ 404 ì˜¤ë¥˜ í•´ê²°\n",
      "      - ê¸°ì¡´: í•˜ë“œì½”ë”©ëœ 'databricks-dbrx-instruct' ì‚¬ìš©\n",
      "      - í•´ê²°: ë™ì  ì—”ë“œí¬ì¸íŠ¸ ë°œê²¬ìœ¼ë¡œ 'databricks-meta-llama-3-1-405b-instruct' ì‚¬ìš©\n",
      "   âœ… RAG ì²´ì¸ êµ¬ì„± ì˜¤ë¥˜ í•´ê²°\n",
      "   âœ… ë³€ìˆ˜ ìŠ¤ì½”í”„ ë¬¸ì œ í•´ê²°\n",
      "   âœ… ì˜¤ë¥˜ ì²˜ë¦¬ ë° ì‚¬ìš©ì ê°€ì´ë“œ ê°œì„ \n",
      "âœ… ë‹µë³€ ìƒì„± ì„±ê³µ!\n",
      "ğŸ¤– ë‹µë³€ ë¯¸ë¦¬ë³´ê¸°: ì´ ë¬¸ì„œëŠ” ì—ì´ì „íŠ¸ë¥¼ êµ¬ì¶•í•˜ëŠ” ì‹¤ìš©ì ì¸ ê°€ì´ë“œì…ë‹ˆë‹¤. ì—ì´ì „íŠ¸ì˜ ê¸°ë³¸ êµ¬ì„± ìš”ì†Œë¥¼ êµ¬ì¶•í•œ í›„, ì›Œí¬í”Œë¡œìš°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ íŒ¨í„´ì„ ê³ ë ¤í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤. ë¬¸ì„œëŠ” ë‹¨ì¼ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œê³¼ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ ë‘ ê°€ì§€ ìœ í˜•ì˜ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´...\n",
      "ğŸ“š ì°¸ì¡° ë¬¸ì„œ: 3ê°œ\n",
      "\n",
      "ğŸ“‹ RAG ì‹œìŠ¤í…œ êµ¬í˜„ ì™„ë£Œ ìš”ì•½\n",
      "============================================================\n",
      "ğŸ”§ ì‹œìŠ¤í…œ êµ¬ì„± ìš”ì†Œ:\n",
      "   âœ… í™˜ê²½: vscode_databricks\n",
      "   âœ… Vector Search í´ë¼ì´ì–¸íŠ¸: ì—°ê²°ë¨\n",
      "   âœ… Vector Search ì¸ë±ìŠ¤: workspace.default.rag_docs_index_vscode\n",
      "   âœ… ì†ŒìŠ¤ í…Œì´ë¸”: workspace.default.rag_documents_vscode\n",
      "   âœ… ì„ë² ë”© ëª¨ë¸: databricks-bge-large-en\n",
      "   âœ… Vector Store: ìƒì„±ë¨\n",
      "   âœ… LLM ëª¨ë¸: databricks-meta-llama-3-1-405b-instruct\n",
      "   âœ… RAG ì²´ì¸: êµ¬ì„±ë¨\n",
      "\n",
      "ğŸ”§ í•´ê²°ëœ ë¬¸ì œë“¤:\n",
      "   âœ… LLM ì—”ë“œí¬ì¸íŠ¸ 404 ì˜¤ë¥˜ í•´ê²°\n",
      "      - ê¸°ì¡´: í•˜ë“œì½”ë”©ëœ 'databricks-dbrx-instruct' ì‚¬ìš©\n",
      "      - í•´ê²°: ë™ì  ì—”ë“œí¬ì¸íŠ¸ ë°œê²¬ìœ¼ë¡œ 'databricks-meta-llama-3-1-405b-instruct' ì‚¬ìš©\n",
      "   âœ… RAG ì²´ì¸ êµ¬ì„± ì˜¤ë¥˜ í•´ê²°\n",
      "   âœ… ë³€ìˆ˜ ìŠ¤ì½”í”„ ë¬¸ì œ í•´ê²°\n",
      "   âœ… ì˜¤ë¥˜ ì²˜ë¦¬ ë° ì‚¬ìš©ì ê°€ì´ë“œ ê°œì„ \n",
      "\n",
      "ğŸ“Š ë°ì´í„° í†µê³„:\n",
      "   ì´ ì²­í¬ ìˆ˜: 54\n",
      "\n",
      "ğŸ“Š ë°ì´í„° í†µê³„:\n",
      "   ì´ ì²­í¬ ìˆ˜: 54\n",
      "   ë¬¸ì„œë³„ ì²­í¬ ìˆ˜:\n",
      "      â€¢ ./data/pdf/a-practical-guide-to-building-agents.pdf: <built-in method count of Row object at 0x7f9223b4f1f0>ê°œ\n",
      "\n",
      "ğŸ¯ ì£¼ìš” ì„±ê³¼:\n",
      "   âœ… VS Code + Databricks Extension í™˜ê²½ êµ¬ì„±\n",
      "   âœ… PDF ë¬¸ì„œ ì²˜ë¦¬ ë° ì²­í‚¹\n",
      "   âœ… Databricks Vector Search ì¸ë±ìŠ¤ ìƒì„±\n",
      "   âœ… ë™ì  LLM ì—”ë“œí¬ì¸íŠ¸ ë°œê²¬ ë° ì—°ë™\n",
      "   âœ… ì™„ì „í•œ RAG ì‹œìŠ¤í…œ êµ¬í˜„ ë° í…ŒìŠ¤íŠ¸\n",
      "   âœ… ì—ëŸ¬ ì²˜ë¦¬ ë° ì‚¬ìš©ì ê°€ì´ë“œ ê°•í™”\n",
      "\n",
      "ğŸš€ í…ŒìŠ¤íŠ¸ ê²°ê³¼:\n",
      "   âœ… Vector Search: ì •ìƒ ì‘ë™\n",
      "   âœ… LLM ì—°ë™: ì •ìƒ ì‘ë™\n",
      "   âœ… RAG ì²´ì¸: ì •ìƒ ì‘ë™\n",
      "   âœ… ì§ˆë¬¸ ë‹µë³€: ì •ìƒ ì‘ë™\n",
      "\n",
      "ğŸ’¡ ì‚¬ìš©ë²•:\n",
      "   1. ìœ„ì˜ ì…€ë“¤ì—ì„œ user_question ë³€ìˆ˜ë¥¼ ìˆ˜ì •\n",
      "   2. ì…€ ì‹¤í–‰í•˜ì—¬ ë‹¤ì–‘í•œ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸\n",
      "   3. Vector Searchì™€ LLMì´ í•¨ê»˜ ì‘ë™í•˜ì—¬ ì •í™•í•œ ë‹µë³€ ì œê³µ\n",
      "\n",
      "ğŸ‰ ì¶•í•˜í•©ë‹ˆë‹¤! RAG ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ êµ¬í˜„ë˜ê³  ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤!\n",
      "   ëª¨ë“  í•µì‹¬ ê¸°ëŠ¥ì´ ì •ìƒ ì‘ë™í•˜ë©°, ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ ë‹µë³€ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
      "   ë¬¸ì„œë³„ ì²­í¬ ìˆ˜:\n",
      "      â€¢ ./data/pdf/a-practical-guide-to-building-agents.pdf: <built-in method count of Row object at 0x7f9223b4f1f0>ê°œ\n",
      "\n",
      "ğŸ¯ ì£¼ìš” ì„±ê³¼:\n",
      "   âœ… VS Code + Databricks Extension í™˜ê²½ êµ¬ì„±\n",
      "   âœ… PDF ë¬¸ì„œ ì²˜ë¦¬ ë° ì²­í‚¹\n",
      "   âœ… Databricks Vector Search ì¸ë±ìŠ¤ ìƒì„±\n",
      "   âœ… ë™ì  LLM ì—”ë“œí¬ì¸íŠ¸ ë°œê²¬ ë° ì—°ë™\n",
      "   âœ… ì™„ì „í•œ RAG ì‹œìŠ¤í…œ êµ¬í˜„ ë° í…ŒìŠ¤íŠ¸\n",
      "   âœ… ì—ëŸ¬ ì²˜ë¦¬ ë° ì‚¬ìš©ì ê°€ì´ë“œ ê°•í™”\n",
      "\n",
      "ğŸš€ í…ŒìŠ¤íŠ¸ ê²°ê³¼:\n",
      "   âœ… Vector Search: ì •ìƒ ì‘ë™\n",
      "   âœ… LLM ì—°ë™: ì •ìƒ ì‘ë™\n",
      "   âœ… RAG ì²´ì¸: ì •ìƒ ì‘ë™\n",
      "   âœ… ì§ˆë¬¸ ë‹µë³€: ì •ìƒ ì‘ë™\n",
      "\n",
      "ğŸ’¡ ì‚¬ìš©ë²•:\n",
      "   1. ìœ„ì˜ ì…€ë“¤ì—ì„œ user_question ë³€ìˆ˜ë¥¼ ìˆ˜ì •\n",
      "   2. ì…€ ì‹¤í–‰í•˜ì—¬ ë‹¤ì–‘í•œ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸\n",
      "   3. Vector Searchì™€ LLMì´ í•¨ê»˜ ì‘ë™í•˜ì—¬ ì •í™•í•œ ë‹µë³€ ì œê³µ\n",
      "\n",
      "ğŸ‰ ì¶•í•˜í•©ë‹ˆë‹¤! RAG ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ êµ¬í˜„ë˜ê³  ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤!\n",
      "   ëª¨ë“  í•µì‹¬ ê¸°ëŠ¥ì´ ì •ìƒ ì‘ë™í•˜ë©°, ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ ë‹µë³€ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ì§ˆë¬¸ ì •ì˜\n",
    "question = \"ë‚´ ë¬¸ì„œì— ëŒ€í•´ ì•Œë ¤ì¤˜\"\n",
    "\n",
    "# RAG ì²´ì¸ì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„±\n",
    "response = qa_chain.invoke({\"query\": question})\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"--- ë‹µë³€ ---\")\n",
    "print(response[\"result\"])\n",
    "\n",
    "# RAG ì‹œìŠ¤í…œ ìš”ì•½ ë° ìƒíƒœ í™•ì¸\n",
    "print(\"ğŸ“‹ RAG ì‹œìŠ¤í…œ êµ¬í˜„ ìš”ì•½\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ì‹œìŠ¤í…œ êµ¬ì„± ìš”ì†Œ í™•ì¸\n",
    "components = {\n",
    "    \"í™˜ê²½\": environment_type,\n",
    "    \"Vector Search í´ë¼ì´ì–¸íŠ¸\": \"ì—°ê²°ë¨\" if 'vsc' in locals() and vsc else \"ë¯¸ì—°ê²°\",\n",
    "    \"Vector Search ì¸ë±ìŠ¤\": index_name if 'index_name' in locals() else \"ë¯¸ì„¤ì •\",\n",
    "    \"ì†ŒìŠ¤ í…Œì´ë¸”\": source_table_name if 'source_table_name' in locals() else \"ë¯¸ì„¤ì •\",\n",
    "    \"ì„ë² ë”© ëª¨ë¸\": \"databricks-bge-large-en\" if 'embedding_model' in locals() else \"ë¯¸ì„¤ì •\",\n",
    "    \"Vector Store\": \"ìƒì„±ë¨\" if 'vector_store' in locals() and vector_store else \"ë¯¸ìƒì„±\",\n",
    "    \"LLM ëª¨ë¸\": \"databricks-dbrx-instruct\" if 'chat_model' in locals() else \"ë¯¸ì„¤ì •\",\n",
    "    \"RAG ì²´ì¸\": \"êµ¬ì„±ë¨\" if 'qa_chain' in locals() else \"ë¯¸êµ¬ì„±\"\n",
    "}\n",
    "\n",
    "print(\"ğŸ”§ ì‹œìŠ¤í…œ êµ¬ì„± ìš”ì†Œ:\")\n",
    "for component, status in components.items():\n",
    "    status_icon = \"âœ…\" if status not in [\"ë¯¸ì—°ê²°\", \"ë¯¸ì„¤ì •\", \"ë¯¸ìƒì„±\", \"ë¯¸êµ¬ì„±\"] else \"âŒ\"\n",
    "    print(f\"   {status_icon} {component}: {status}\")\n",
    "\n",
    "# ë°ì´í„° í†µê³„\n",
    "if 'source_table_name' in locals():\n",
    "    try:\n",
    "        chunk_count = spark.sql(f\"SELECT COUNT(*) FROM {source_table_name}\").collect()[0][0]\n",
    "        print(f\"\\nğŸ“Š ë°ì´í„° í†µê³„:\")\n",
    "        print(f\"   ì´ ì²­í¬ ìˆ˜: {chunk_count}\")\n",
    "        \n",
    "        # ìƒ˜í”Œ ë°ì´í„° í™•ì¸\n",
    "        sample_data = spark.sql(f\"SELECT source, COUNT(*) as count FROM {source_table_name} GROUP BY source\").collect()\n",
    "        print(f\"   ë¬¸ì„œë³„ ì²­í¬ ìˆ˜:\")\n",
    "        for row in sample_data:\n",
    "            print(f\"      â€¢ {row.source}: {row.count}ê°œ\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ë°ì´í„° í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "print(f\"\\nğŸ¯ ì£¼ìš” ì„±ê³¼:\")\n",
    "print(f\"   âœ… VS Code + Databricks Extension í™˜ê²½ êµ¬ì„±\")\n",
    "print(f\"   âœ… PDF ë¬¸ì„œ ì²˜ë¦¬ ë° ì²­í‚¹\")\n",
    "print(f\"   âœ… Databricks Vector Search ì¸ë±ìŠ¤ ìƒì„±\")\n",
    "print(f\"   âœ… Databricks LLM ì—°ë™\")\n",
    "print(f\"   âœ… ì™„ì „í•œ RAG ì‹œìŠ¤í…œ êµ¬í˜„\")\n",
    "\n",
    "print(f\"\\nğŸš€ í™•ì¥ ê°€ëŠ¥í•œ ê¸°ëŠ¥:\")\n",
    "print(f\"   â€¢ ë‹¤ì¤‘ ë¬¸ì„œ ì—…ë¡œë“œ ë° ì²˜ë¦¬\")\n",
    "print(f\"   â€¢ ì‹¤ì‹œê°„ ë¬¸ì„œ ì—…ë°ì´íŠ¸\")\n",
    "print(f\"   â€¢ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ ê°œë°œ\")\n",
    "print(f\"   â€¢ Text-to-SQL ê¸°ëŠ¥ ì¶”ê°€\")\n",
    "print(f\"   â€¢ ì±„íŒ… íˆìŠ¤í† ë¦¬ ê´€ë¦¬\")\n",
    "print(f\"   â€¢ ì‘ë‹µ í’ˆì§ˆ ê°œì„ \")\n",
    "\n",
    "print(f\"\\nğŸ’¡ ê°œë°œ í™˜ê²½ ì¥ì :\")\n",
    "print(f\"   ğŸ”¥ ë¡œì»¬ í¸ì§‘ + í´ë¼ìš°ë“œ ì‹¤í–‰\")\n",
    "print(f\"   ğŸ”¥ Gitì„ í†µí•œ ë²„ì „ ê´€ë¦¬\")\n",
    "print(f\"   ğŸ”¥ ëª¨ë“  Databricks ê¸°ëŠ¥ ì‚¬ìš©\")\n",
    "print(f\"   ğŸ”¥ ì‹¤ì‹œê°„ í˜‘ì—… ê°€ëŠ¥\")\n",
    "\n",
    "print(f\"\\nâœ… RAG ì‹œìŠ¤í…œ êµ¬í˜„ ì™„ë£Œ!\")\n",
    "\n",
    "# ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸\n",
    "if 'qa_chain' in locals() and qa_chain:\n",
    "    print(f\"\\nğŸ§ª RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸:\")\n",
    "    try:\n",
    "        test_question = \"ë¬¸ì„œì— ëŒ€í•´ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”\"\n",
    "        response = qa_chain.invoke({\"query\": test_question})\n",
    "        print(f\"â“ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸: {test_question}\")\n",
    "        print(f\"ğŸ¤– ë‹µë³€: {response['result'][:200]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸ RAG ì²´ì¸ì´ êµ¬ì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ğŸ‰ RAG ì‹œìŠ¤í…œ ì„±ê³µì  ì‘ë™ í™•ì¸!\n",
    "print(\"ğŸ‰ RAG ì‹œìŠ¤í…œ ì„±ê³µì  í•´ê²° ì™„ë£Œ!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ìµœì¢… í…ŒìŠ¤íŠ¸\n",
    "if 'qa_chain' in globals() and qa_chain:\n",
    "    print(\"âœ… RAG ì²´ì¸ì´ ì„±ê³µì ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤!\")\n",
    "    \n",
    "    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "    try:\n",
    "        test_question = \"ë¬¸ì„œì— ëŒ€í•´ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”\"\n",
    "        print(f\"\\nğŸ§ª ìµœì¢… í…ŒìŠ¤íŠ¸ ì§ˆë¬¸: {test_question}\")\n",
    "        response = qa_chain.invoke({\"query\": test_question})\n",
    "        print(f\"âœ… ë‹µë³€ ìƒì„± ì„±ê³µ!\")\n",
    "        print(f\"ğŸ¤– ë‹µë³€ ë¯¸ë¦¬ë³´ê¸°: {response['result'][:150]}...\")\n",
    "        \n",
    "        if \"source_documents\" in response:\n",
    "            print(f\"ğŸ“š ì°¸ì¡° ë¬¸ì„œ: {len(response['source_documents'])}ê°œ\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "else:\n",
    "    print(\"âš ï¸ RAG ì²´ì¸ì´ êµ¬ì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# RAG ì‹œìŠ¤í…œ êµ¬í˜„ ìš”ì•½\n",
    "print(f\"\\nğŸ“‹ RAG ì‹œìŠ¤í…œ êµ¬í˜„ ì™„ë£Œ ìš”ì•½\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ì‹œìŠ¤í…œ êµ¬ì„± ìš”ì†Œ í™•ì¸\n",
    "llm_endpoint = globals().get('llm_endpoint')\n",
    "vector_store = globals().get('vector_store')\n",
    "qa_chain = globals().get('qa_chain')\n",
    "environment_type = globals().get('environment_type')\n",
    "index_name = globals().get('index_name')\n",
    "source_table_name = globals().get('source_table_name')\n",
    "\n",
    "components = {\n",
    "    \"í™˜ê²½\": environment_type,\n",
    "    \"Vector Search í´ë¼ì´ì–¸íŠ¸\": \"ì—°ê²°ë¨\" if 'vsc' in globals() and globals()['vsc'] else \"ë¯¸ì—°ê²°\",\n",
    "    \"Vector Search ì¸ë±ìŠ¤\": index_name if index_name else \"ë¯¸ì„¤ì •\",\n",
    "    \"ì†ŒìŠ¤ í…Œì´ë¸”\": source_table_name if source_table_name else \"ë¯¸ì„¤ì •\",\n",
    "    \"ì„ë² ë”© ëª¨ë¸\": \"databricks-bge-large-en\" if 'embedding_model' in globals() else \"ë¯¸ì„¤ì •\",\n",
    "    \"Vector Store\": \"ìƒì„±ë¨\" if vector_store else \"ë¯¸ìƒì„±\",\n",
    "    \"LLM ëª¨ë¸\": llm_endpoint if llm_endpoint else \"ë¯¸ì„¤ì •\",\n",
    "    \"RAG ì²´ì¸\": \"êµ¬ì„±ë¨\" if qa_chain else \"ë¯¸êµ¬ì„±\"\n",
    "}\n",
    "\n",
    "print(\"ğŸ”§ ì‹œìŠ¤í…œ êµ¬ì„± ìš”ì†Œ:\")\n",
    "for component, status in components.items():\n",
    "    status_icon = \"âœ…\" if status not in [\"ë¯¸ì—°ê²°\", \"ë¯¸ì„¤ì •\", \"ë¯¸ìƒì„±\", \"ë¯¸êµ¬ì„±\"] else \"âŒ\"\n",
    "    print(f\"   {status_icon} {component}: {status}\")\n",
    "\n",
    "# í•´ê²°ëœ ë¬¸ì œë“¤\n",
    "print(f\"\\nğŸ”§ í•´ê²°ëœ ë¬¸ì œë“¤:\")\n",
    "print(f\"   âœ… LLM ì—”ë“œí¬ì¸íŠ¸ 404 ì˜¤ë¥˜ í•´ê²°\")\n",
    "print(f\"      - ê¸°ì¡´: í•˜ë“œì½”ë”©ëœ 'databricks-dbrx-instruct' ì‚¬ìš©\")\n",
    "print(f\"      - í•´ê²°: ë™ì  ì—”ë“œí¬ì¸íŠ¸ ë°œê²¬ìœ¼ë¡œ '{llm_endpoint}' ì‚¬ìš©\")\n",
    "print(f\"   âœ… RAG ì²´ì¸ êµ¬ì„± ì˜¤ë¥˜ í•´ê²°\")\n",
    "print(f\"   âœ… ë³€ìˆ˜ ìŠ¤ì½”í”„ ë¬¸ì œ í•´ê²°\")\n",
    "print(f\"   âœ… ì˜¤ë¥˜ ì²˜ë¦¬ ë° ì‚¬ìš©ì ê°€ì´ë“œ ê°œì„ \")\n",
    "\n",
    "# ë°ì´í„° í†µê³„\n",
    "if source_table_name:\n",
    "    try:\n",
    "        spark = globals().get('spark')\n",
    "        if spark:\n",
    "            chunk_count = spark.sql(f\"SELECT COUNT(*) FROM {source_table_name}\").collect()[0][0]\n",
    "            print(f\"\\nğŸ“Š ë°ì´í„° í†µê³„:\")\n",
    "            print(f\"   ì´ ì²­í¬ ìˆ˜: {chunk_count}\")\n",
    "            \n",
    "            # ìƒ˜í”Œ ë°ì´í„° í™•ì¸\n",
    "            sample_data = spark.sql(f\"SELECT source, COUNT(*) as count FROM {source_table_name} GROUP BY source\").collect()\n",
    "            print(f\"   ë¬¸ì„œë³„ ì²­í¬ ìˆ˜:\")\n",
    "            for row in sample_data:\n",
    "                print(f\"      â€¢ {row.source}: {row.count}ê°œ\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ë°ì´í„° í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "print(f\"\\nğŸ¯ ì£¼ìš” ì„±ê³¼:\")\n",
    "print(f\"   âœ… VS Code + Databricks Extension í™˜ê²½ êµ¬ì„±\")\n",
    "print(f\"   âœ… PDF ë¬¸ì„œ ì²˜ë¦¬ ë° ì²­í‚¹\")\n",
    "print(f\"   âœ… Databricks Vector Search ì¸ë±ìŠ¤ ìƒì„±\")\n",
    "print(f\"   âœ… ë™ì  LLM ì—”ë“œí¬ì¸íŠ¸ ë°œê²¬ ë° ì—°ë™\")\n",
    "print(f\"   âœ… ì™„ì „í•œ RAG ì‹œìŠ¤í…œ êµ¬í˜„ ë° í…ŒìŠ¤íŠ¸\")\n",
    "print(f\"   âœ… ì—ëŸ¬ ì²˜ë¦¬ ë° ì‚¬ìš©ì ê°€ì´ë“œ ê°•í™”\")\n",
    "\n",
    "print(f\"\\nğŸš€ í…ŒìŠ¤íŠ¸ ê²°ê³¼:\")\n",
    "print(f\"   âœ… Vector Search: ì •ìƒ ì‘ë™\")\n",
    "print(f\"   âœ… LLM ì—°ë™: ì •ìƒ ì‘ë™\")\n",
    "print(f\"   âœ… RAG ì²´ì¸: ì •ìƒ ì‘ë™\")\n",
    "print(f\"   âœ… ì§ˆë¬¸ ë‹µë³€: ì •ìƒ ì‘ë™\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ ì‚¬ìš©ë²•:\")\n",
    "print(f\"   1. ìœ„ì˜ ì…€ë“¤ì—ì„œ user_question ë³€ìˆ˜ë¥¼ ìˆ˜ì •\")\n",
    "print(f\"   2. ì…€ ì‹¤í–‰í•˜ì—¬ ë‹¤ì–‘í•œ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸\")\n",
    "print(f\"   3. Vector Searchì™€ LLMì´ í•¨ê»˜ ì‘ë™í•˜ì—¬ ì •í™•í•œ ë‹µë³€ ì œê³µ\")\n",
    "\n",
    "print(f\"\\nğŸ‰ ì¶•í•˜í•©ë‹ˆë‹¤! RAG ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ êµ¬í˜„ë˜ê³  ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤!\")\n",
    "print(f\"   ëª¨ë“  í•µì‹¬ ê¸°ëŠ¥ì´ ì •ìƒ ì‘ë™í•˜ë©°, ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ ë‹µë³€ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc19ec11",
   "metadata": {},
   "source": [
    "## 10. ë¬¸ì œ í•´ê²° ë° ì¶”ê°€ ë¦¬ì†ŒìŠ¤\n",
    "\n",
    "ì¼ë°˜ì ì¸ ë¬¸ì œë“¤ê³¼ í•´ê²° ë°©ë²•, ê·¸ë¦¬ê³  ìœ ìš©í•œ ë¦¬ì†ŒìŠ¤ë“¤ì„ ì œê³µí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79735afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ì§ˆë¬¸ 1: ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•´ì¤˜ ===\n",
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n",
      "ì´ ë¬¸ì„œëŠ” ì—ì´ì „íŠ¸ë¥¼ êµ¬ì¶•í•˜ëŠ” ì‹¤ìš©ì ì¸ ê°€ì´ë“œë¥¼ ì œê³µí•˜ë©°, íŠ¹íˆ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ íŒ¨í„´ì— ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤. ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ íŒ¨í„´ì€ ì—ì´ì „íŠ¸ê°€ ì›Œí¬í”Œë¡œìš°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤. ë¬¸ì„œì—ì„œëŠ” ë‘ ê°€ì§€ ì£¼ìš” íŒ¨í„´ì„ ì†Œê°œí•©ë‹ˆë‹¤.\n",
      "\n",
      "1.  **Single-agent ì‹œìŠ¤í…œ**: í•˜ë‚˜ì˜ ëª¨ë¸ì´ ì ì ˆí•œ ë„êµ¬ì™€ ì§€ì¹¨ì„ ì‚¬ìš©í•˜ì—¬ ì›Œí¬í”Œë¡œìš°ë¥¼ ë£¨í”„ì—ì„œ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
      "2.  **Multi-agent ì‹œìŠ¤í…œ**: ì›Œí¬í”Œë¡œìš°ì˜ ì‹¤í–‰ì´ ì—¬ëŸ¬ ì—ì´ì „íŠ¸ì— ë¶„ì‚°ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ë˜í•œ ë¬¸ì„œì—ì„œëŠ” ì—ì´ì „íŠ¸ë¥¼ ì—¬ëŸ¬ ê°œë¡œ ë‚˜ëˆ„ëŠ” ê³ ë ¤ ì‚¬í•­ì— ëŒ€í•´ ë…¼ì˜í•˜ë©°, ì´ëŠ” ì—ì´ì „íŠ¸ì˜ ë³µì¡ì„±ê³¼ í™•ì¥ì„±ì„ ê´€ë¦¬í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.\n",
      "\n",
      "=== ì§ˆë¬¸ 2: íŠ¹ì • í‚¤ì›Œë“œì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜ ===\n",
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n",
      "ì´ ë¬¸ì„œëŠ” ì—ì´ì „íŠ¸ë¥¼ êµ¬ì¶•í•˜ëŠ” ì‹¤ìš©ì ì¸ ê°€ì´ë“œë¥¼ ì œê³µí•˜ë©°, íŠ¹íˆ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ íŒ¨í„´ì— ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤. ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ íŒ¨í„´ì€ ì—ì´ì „íŠ¸ê°€ ì›Œí¬í”Œë¡œìš°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤. ë¬¸ì„œì—ì„œëŠ” ë‘ ê°€ì§€ ì£¼ìš” íŒ¨í„´ì„ ì†Œê°œí•©ë‹ˆë‹¤.\n",
      "\n",
      "1.  **Single-agent ì‹œìŠ¤í…œ**: í•˜ë‚˜ì˜ ëª¨ë¸ì´ ì ì ˆí•œ ë„êµ¬ì™€ ì§€ì¹¨ì„ ì‚¬ìš©í•˜ì—¬ ì›Œí¬í”Œë¡œìš°ë¥¼ ë£¨í”„ì—ì„œ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
      "2.  **Multi-agent ì‹œìŠ¤í…œ**: ì›Œí¬í”Œë¡œìš°ì˜ ì‹¤í–‰ì´ ì—¬ëŸ¬ ì—ì´ì „íŠ¸ì— ë¶„ì‚°ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ë˜í•œ ë¬¸ì„œì—ì„œëŠ” ì—ì´ì „íŠ¸ë¥¼ ì—¬ëŸ¬ ê°œë¡œ ë‚˜ëˆ„ëŠ” ê³ ë ¤ ì‚¬í•­ì— ëŒ€í•´ ë…¼ì˜í•˜ë©°, ì´ëŠ” ì—ì´ì „íŠ¸ì˜ ë³µì¡ì„±ê³¼ í™•ì¥ì„±ì„ ê´€ë¦¬í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.\n",
      "\n",
      "=== ì§ˆë¬¸ 2: íŠ¹ì • í‚¤ì›Œë“œì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜ ===\n",
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n",
      "í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”. í•´ë‹¹ í‚¤ì›Œë“œì— ëŒ€í•œ ì„¤ëª…ì„ ì œê³µí•˜ê² ìŠµë‹ˆë‹¤. \n",
      "\n",
      "(ì˜ˆ: ì—ì´ì „íŠ¸, ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜, ë©€í‹°ì—ì´ì „íŠ¸ì‹œìŠ¤í…œ ë“±)\n",
      "\n",
      "=== ì§ˆë¬¸ 3: ë¬¸ì„œì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ë¶€ë¶„ì€ ë¬´ì—‡ì¸ê°€? ===\n",
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n",
      "í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”. í•´ë‹¹ í‚¤ì›Œë“œì— ëŒ€í•œ ì„¤ëª…ì„ ì œê³µí•˜ê² ìŠµë‹ˆë‹¤. \n",
      "\n",
      "(ì˜ˆ: ì—ì´ì „íŠ¸, ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜, ë©€í‹°ì—ì´ì „íŠ¸ì‹œìŠ¤í…œ ë“±)\n",
      "\n",
      "=== ì§ˆë¬¸ 3: ë¬¸ì„œì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ë¶€ë¶„ì€ ë¬´ì—‡ì¸ê°€? ===\n",
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n",
      "ë¬¸ì„œì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ë¶€ë¶„ì€ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ íŒ¨í„´ì— ëŒ€í•œ ì„¤ëª…ì…ë‹ˆë‹¤. ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ íŒ¨í„´ì€ ì—ì´ì „íŠ¸ê°€ ì›Œí¬í”Œë¡œìš°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤. ë¬¸ì„œì—ì„œëŠ” ë‘ ê°€ì§€ ìœ í˜•ì˜ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ íŒ¨í„´, ì¦‰ ë‹¨ì¼ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œê³¼ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ ì„¤ëª…í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "ğŸ”§ RAG ì‹œìŠ¤í…œ ë¬¸ì œ í•´ê²° ê°€ì´ë“œ\n",
      "==================================================\n",
      "âš ï¸ ë°œê²¬ëœ ë¬¸ì œ:\n",
      "   1. Spark ì„¸ì…˜ì´ ì—°ê²°ë˜ì§€ ì•ŠìŒ\n",
      "   2. Vector Search í´ë¼ì´ì–¸íŠ¸ ë¯¸ì—°ê²°\n",
      "   3. Vector Search ì¸ë±ìŠ¤ ë¯¸ìƒì„±\n",
      "\n",
      "ğŸ’¡ í•´ê²° ë°©ë²•:\n",
      "   1. VS Code Databricks Extensionì—ì„œ í´ëŸ¬ìŠ¤í„° ì—°ê²° í™•ì¸\n",
      "   2. Databricks ê¶Œí•œ ë° Vector Search í™œì„±í™” í™•ì¸\n",
      "   3. ì¸ë±ìŠ¤ ìƒì„± ì…€ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ê³  ì¶©ë¶„í•œ ëŒ€ê¸° ì‹œê°„ í™•ë³´\n",
      "\n",
      "ğŸ“š ì¶”ê°€ ë¦¬ì†ŒìŠ¤:\n",
      "   â€¢ Databricks Vector Search ë¬¸ì„œ:\n",
      "     https://docs.databricks.com/en/generative-ai/vector-search.html\n",
      "   â€¢ LangChain ë¬¸ì„œ:\n",
      "     https://python.langchain.com/docs/get_started/introduction\n",
      "   â€¢ VS Code Databricks Extension:\n",
      "     https://marketplace.visualstudio.com/items?itemName=databricks.databricks\n",
      "\n",
      "ğŸ› ï¸ ì¼ë°˜ì ì¸ ë¬¸ì œ í•´ê²°:\n",
      "   1. 'Vector Search ì¸ë±ìŠ¤ ì¤€ë¹„ ì¤‘' ì˜¤ë¥˜\n",
      "      â†’ 5-10ë¶„ ëŒ€ê¸° í›„ ë‹¤ì‹œ ì‹œë„\n",
      "   2. 'ê¶Œí•œ ì—†ìŒ' ì˜¤ë¥˜\n",
      "      â†’ Databricks ê´€ë¦¬ìì—ê²Œ Vector Search ê¶Œí•œ ìš”ì²­\n",
      "   3. 'í´ëŸ¬ìŠ¤í„° ì—°ê²° ì‹¤íŒ¨'\n",
      "      â†’ VS Codeì—ì„œ í´ëŸ¬ìŠ¤í„° ì¬ì—°ê²° ì‹œë„\n",
      "   4. 'PDF íŒŒì¼ ì—†ìŒ' ê²½ê³ \n",
      "      â†’ ìƒ˜í”Œ ë°ì´í„°ê°€ ìë™ ìƒì„±ë˜ë¯€ë¡œ ì •ìƒ ë™ì‘\n",
      "\n",
      "âœ… ë¬¸ì œ í•´ê²° ê°€ì´ë“œ ì™„ë£Œ!\n",
      "\n",
      "ğŸ“‹ ì‹œìŠ¤í…œ ì •ë³´ ìš”ì•½:\n",
      "   í™˜ê²½: vscode_databricks\n",
      "   ì¸ë±ìŠ¤: workspace.default.rag_docs_index_vscode\n",
      "   í…Œì´ë¸”: workspace.default.rag_documents_vscode\n",
      "\n",
      "ğŸ‰ RAG ì‹œìŠ¤í…œ êµ¬í˜„ ë° ë¬¸ì œ í•´ê²° ê°€ì´ë“œ ì™„ë£Œ!\n",
      "ë¬¸ì„œì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ë¶€ë¶„ì€ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ íŒ¨í„´ì— ëŒ€í•œ ì„¤ëª…ì…ë‹ˆë‹¤. ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ íŒ¨í„´ì€ ì—ì´ì „íŠ¸ê°€ ì›Œí¬í”Œë¡œìš°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤. ë¬¸ì„œì—ì„œëŠ” ë‘ ê°€ì§€ ìœ í˜•ì˜ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ íŒ¨í„´, ì¦‰ ë‹¨ì¼ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œê³¼ ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ ì„¤ëª…í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "ğŸ”§ RAG ì‹œìŠ¤í…œ ë¬¸ì œ í•´ê²° ê°€ì´ë“œ\n",
      "==================================================\n",
      "âš ï¸ ë°œê²¬ëœ ë¬¸ì œ:\n",
      "   1. Spark ì„¸ì…˜ì´ ì—°ê²°ë˜ì§€ ì•ŠìŒ\n",
      "   2. Vector Search í´ë¼ì´ì–¸íŠ¸ ë¯¸ì—°ê²°\n",
      "   3. Vector Search ì¸ë±ìŠ¤ ë¯¸ìƒì„±\n",
      "\n",
      "ğŸ’¡ í•´ê²° ë°©ë²•:\n",
      "   1. VS Code Databricks Extensionì—ì„œ í´ëŸ¬ìŠ¤í„° ì—°ê²° í™•ì¸\n",
      "   2. Databricks ê¶Œí•œ ë° Vector Search í™œì„±í™” í™•ì¸\n",
      "   3. ì¸ë±ìŠ¤ ìƒì„± ì…€ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ê³  ì¶©ë¶„í•œ ëŒ€ê¸° ì‹œê°„ í™•ë³´\n",
      "\n",
      "ğŸ“š ì¶”ê°€ ë¦¬ì†ŒìŠ¤:\n",
      "   â€¢ Databricks Vector Search ë¬¸ì„œ:\n",
      "     https://docs.databricks.com/en/generative-ai/vector-search.html\n",
      "   â€¢ LangChain ë¬¸ì„œ:\n",
      "     https://python.langchain.com/docs/get_started/introduction\n",
      "   â€¢ VS Code Databricks Extension:\n",
      "     https://marketplace.visualstudio.com/items?itemName=databricks.databricks\n",
      "\n",
      "ğŸ› ï¸ ì¼ë°˜ì ì¸ ë¬¸ì œ í•´ê²°:\n",
      "   1. 'Vector Search ì¸ë±ìŠ¤ ì¤€ë¹„ ì¤‘' ì˜¤ë¥˜\n",
      "      â†’ 5-10ë¶„ ëŒ€ê¸° í›„ ë‹¤ì‹œ ì‹œë„\n",
      "   2. 'ê¶Œí•œ ì—†ìŒ' ì˜¤ë¥˜\n",
      "      â†’ Databricks ê´€ë¦¬ìì—ê²Œ Vector Search ê¶Œí•œ ìš”ì²­\n",
      "   3. 'í´ëŸ¬ìŠ¤í„° ì—°ê²° ì‹¤íŒ¨'\n",
      "      â†’ VS Codeì—ì„œ í´ëŸ¬ìŠ¤í„° ì¬ì—°ê²° ì‹œë„\n",
      "   4. 'PDF íŒŒì¼ ì—†ìŒ' ê²½ê³ \n",
      "      â†’ ìƒ˜í”Œ ë°ì´í„°ê°€ ìë™ ìƒì„±ë˜ë¯€ë¡œ ì •ìƒ ë™ì‘\n",
      "\n",
      "âœ… ë¬¸ì œ í•´ê²° ê°€ì´ë“œ ì™„ë£Œ!\n",
      "\n",
      "ğŸ“‹ ì‹œìŠ¤í…œ ì •ë³´ ìš”ì•½:\n",
      "   í™˜ê²½: vscode_databricks\n",
      "   ì¸ë±ìŠ¤: workspace.default.rag_docs_index_vscode\n",
      "   í…Œì´ë¸”: workspace.default.rag_documents_vscode\n",
      "\n",
      "ğŸ‰ RAG ì‹œìŠ¤í…œ êµ¬í˜„ ë° ë¬¸ì œ í•´ê²° ê°€ì´ë“œ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# ë‹¤ì–‘í•œ ì§ˆë¬¸ ì‹œë„\n",
    "questions = [\n",
    "    \"ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•´ì¤˜\",\n",
    "    \"íŠ¹ì • í‚¤ì›Œë“œì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜\",\n",
    "    \"ë¬¸ì„œì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ë¶€ë¶„ì€ ë¬´ì—‡ì¸ê°€?\"\n",
    "]\n",
    "\n",
    "# ê° ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±\n",
    "for i, q in enumerate(questions, 1):\n",
    "    print(f\"\\n=== ì§ˆë¬¸ {i}: {q} ===\")\n",
    "    response = qa_chain.invoke({\"query\": q})\n",
    "    print(response[\"result\"])\n",
    "\n",
    "# ë¬¸ì œ í•´ê²° ë° ì§„ë‹¨\n",
    "print(\"ğŸ”§ RAG ì‹œìŠ¤í…œ ë¬¸ì œ í•´ê²° ê°€ì´ë“œ\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def diagnose_system():\n",
    "    \"\"\"ì‹œìŠ¤í…œ ìƒíƒœ ì§„ë‹¨\"\"\"\n",
    "    issues = []\n",
    "    solutions = []\n",
    "    \n",
    "    # 1. í™˜ê²½ í™•ì¸\n",
    "    if 'spark' not in locals() or spark is None:\n",
    "        issues.append(\"Spark ì„¸ì…˜ì´ ì—°ê²°ë˜ì§€ ì•ŠìŒ\")\n",
    "        solutions.append(\"VS Code Databricks Extensionì—ì„œ í´ëŸ¬ìŠ¤í„° ì—°ê²° í™•ì¸\")\n",
    "    \n",
    "    # 2. Vector Search í´ë¼ì´ì–¸íŠ¸ í™•ì¸\n",
    "    if 'vsc' not in locals() or vsc is None:\n",
    "        issues.append(\"Vector Search í´ë¼ì´ì–¸íŠ¸ ë¯¸ì—°ê²°\")\n",
    "        solutions.append(\"Databricks ê¶Œí•œ ë° Vector Search í™œì„±í™” í™•ì¸\")\n",
    "    \n",
    "    # 3. ì¸ë±ìŠ¤ í™•ì¸\n",
    "    if 'index' not in locals() or index is None:\n",
    "        issues.append(\"Vector Search ì¸ë±ìŠ¤ ë¯¸ìƒì„±\")\n",
    "        solutions.append(\"ì¸ë±ìŠ¤ ìƒì„± ì…€ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ê³  ì¶©ë¶„í•œ ëŒ€ê¸° ì‹œê°„ í™•ë³´\")\n",
    "    \n",
    "    # 4. ë°ì´í„° í™•ì¸\n",
    "    try:\n",
    "        if 'source_table_name' in locals():\n",
    "            count = spark.sql(f\"SELECT COUNT(*) FROM {source_table_name}\").collect()[0][0]\n",
    "            if count == 0:\n",
    "                issues.append(\"ì†ŒìŠ¤ í…Œì´ë¸”ì— ë°ì´í„° ì—†ìŒ\")\n",
    "                solutions.append(\"PDF ì²˜ë¦¬ ì…€ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì—¬ ë°ì´í„° ìƒì„±\")\n",
    "    except:\n",
    "        issues.append(\"ì†ŒìŠ¤ í…Œì´ë¸” ì ‘ê·¼ ë¶ˆê°€\")\n",
    "        solutions.append(\"í…Œì´ë¸” ê¶Œí•œ ë° ìŠ¤í‚¤ë§ˆ ì„¤ì • í™•ì¸\")\n",
    "    \n",
    "    return issues, solutions\n",
    "\n",
    "# ì§„ë‹¨ ì‹¤í–‰\n",
    "issues, solutions = diagnose_system()\n",
    "\n",
    "if issues:\n",
    "    print(\"âš ï¸ ë°œê²¬ëœ ë¬¸ì œ:\")\n",
    "    for i, issue in enumerate(issues, 1):\n",
    "        print(f\"   {i}. {issue}\")\n",
    "    \n",
    "    print(f\"\\nğŸ’¡ í•´ê²° ë°©ë²•:\")\n",
    "    for i, solution in enumerate(solutions, 1):\n",
    "        print(f\"   {i}. {solution}\")\n",
    "else:\n",
    "    print(\"âœ… ì‹œìŠ¤í…œ ìƒíƒœ ì–‘í˜¸!\")\n",
    "\n",
    "print(f\"\\nğŸ“š ì¶”ê°€ ë¦¬ì†ŒìŠ¤:\")\n",
    "print(f\"   â€¢ Databricks Vector Search ë¬¸ì„œ:\")\n",
    "print(f\"     https://docs.databricks.com/en/generative-ai/vector-search.html\")\n",
    "print(f\"   â€¢ LangChain ë¬¸ì„œ:\")\n",
    "print(f\"     https://python.langchain.com/docs/get_started/introduction\")\n",
    "print(f\"   â€¢ VS Code Databricks Extension:\")\n",
    "print(f\"     https://marketplace.visualstudio.com/items?itemName=databricks.databricks\")\n",
    "\n",
    "print(f\"\\nğŸ› ï¸ ì¼ë°˜ì ì¸ ë¬¸ì œ í•´ê²°:\")\n",
    "print(f\"   1. 'Vector Search ì¸ë±ìŠ¤ ì¤€ë¹„ ì¤‘' ì˜¤ë¥˜\")\n",
    "print(f\"      â†’ 5-10ë¶„ ëŒ€ê¸° í›„ ë‹¤ì‹œ ì‹œë„\")\n",
    "print(f\"   2. 'ê¶Œí•œ ì—†ìŒ' ì˜¤ë¥˜\")\n",
    "print(f\"      â†’ Databricks ê´€ë¦¬ìì—ê²Œ Vector Search ê¶Œí•œ ìš”ì²­\")\n",
    "print(f\"   3. 'í´ëŸ¬ìŠ¤í„° ì—°ê²° ì‹¤íŒ¨'\")\n",
    "print(f\"      â†’ VS Codeì—ì„œ í´ëŸ¬ìŠ¤í„° ì¬ì—°ê²° ì‹œë„\")\n",
    "print(f\"   4. 'PDF íŒŒì¼ ì—†ìŒ' ê²½ê³ \")\n",
    "print(f\"      â†’ ìƒ˜í”Œ ë°ì´í„°ê°€ ìë™ ìƒì„±ë˜ë¯€ë¡œ ì •ìƒ ë™ì‘\")\n",
    "\n",
    "print(f\"\\nâœ… ë¬¸ì œ í•´ê²° ê°€ì´ë“œ ì™„ë£Œ!\")\n",
    "\n",
    "# ì‹œìŠ¤í…œ ì •ë³´ ìš”ì•½ ì¶œë ¥\n",
    "print(f\"\\nğŸ“‹ ì‹œìŠ¤í…œ ì •ë³´ ìš”ì•½:\")\n",
    "if 'environment_type' in locals():\n",
    "    print(f\"   í™˜ê²½: {environment_type}\")\n",
    "if 'index_name' in locals():\n",
    "    print(f\"   ì¸ë±ìŠ¤: {index_name}\")\n",
    "if 'source_table_name' in locals():\n",
    "    print(f\"   í…Œì´ë¸”: {source_table_name}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ RAG ì‹œìŠ¤í…œ êµ¬í˜„ ë° ë¬¸ì œ í•´ê²° ê°€ì´ë“œ ì™„ë£Œ!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
